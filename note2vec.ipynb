{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproductive\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "NOTE_DATA_DIR = '/local/XW/DATA/MIMIC/noteevents_by_sid/'\n",
    "ICD_FPATH = 'data/subject_diag_icds.txt'\n",
    "PK_FPATH = 'data/diag_processed_data.pk' # './processed_data_small.pk'\n",
    "MODEL_PATH = './models/'\n",
    "LOG_PATH = './logs/'\n",
    "# constants\n",
    "N_LABELS = 50\n",
    "K_ICDS_TOKEEP = N_LABELS - 1 # predict only on top K frequent icd codes\n",
    "N_SUBJECTS = 41886\n",
    "# word2vec configurations\n",
    "GLOVE_DIR = '/local/XW/DATA/glove.6B/'\n",
    "MAX_SEQ_LEN = 1000 # max length of input sequence (pad/truncate to fix length)\n",
    "MAX_NB_WORDS = 20000 # top 20k most freq words\n",
    "EMBEDDING_DIM = 100\n",
    "# learning configurations\n",
    "VALIDATION_SPLIT = 0.2\n",
    "N_EPOCHS = 20\n",
    "SZ_BATCH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pickled data\n",
    "pk_data = pk.load(open(PK_FPATH, 'rb'))\n",
    "embedding_matrix = pk_data['embedding_matrix']\n",
    "X_train, Y_train = pk_data['X_train'], pk_data['Y_train']\n",
    "X_val, Y_val = pk_data['X_val'], pk_data['Y_val']\n",
    "nb_words = MAX_NB_WORDS # forgot to pickle this number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "11730\n",
      "(36916, 1000) (36916, 50)\n"
     ]
    }
   ],
   "source": [
    "# found one row that is ALL 0 (strange?)\n",
    "print np.min( np.sum(Y_train, axis=1) ), np.min( np.sum(Y_val, axis=1) )\n",
    "print np.argmin( np.sum(Y_train, axis=1) )\n",
    "Y_train[11730]\n",
    "Y_train = np.delete(Y_train, 11730, axis=0)\n",
    "X_train = np.delete(X_train, 11730, axis=0)\n",
    "print X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify sample weight, and use larger batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36916,)\n"
     ]
    }
   ],
   "source": [
    "Y_train_noother = Y_train[::-1]\n",
    "inv_freq = 1e6*Y_train_noother.sum(axis=0)**(-1.5)\n",
    "sample_weight = (inv_freq * Y_train_noother).sum(axis=1)\n",
    "print sample_weight.shape\n",
    "sample_weight\n",
    "# y_n_poslabels = Y_train_noother.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** this metrics is the continus relaxation of what we really want, so the acc output during training is not precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multlabel_prec(y_true, y_pred):\n",
    "    y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return K.mean(tp/(sum_pred+1e-10)) # to avoid NaN precision\n",
    "    \n",
    "def multlabel_recall(y_true, y_pred):\n",
    "    y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return K.mean(tp/(sum_true+1e-10)) \n",
    "\n",
    "def multlabel_F1(y_true, y_pred):\n",
    "    y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return 2*K.mean(tp/(sum_true+sum_pred+1e-10))\n",
    "\n",
    "def multlabel_acc(y_true, y_pred):\n",
    "    y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    intersect = y_true * y_pred\n",
    "    intersect = K.sum(intersect, axis=-1)\n",
    "    union = K.clip(y_true+y_pred, 0, 1)\n",
    "    union = K.sum(union, axis=-1)\n",
    "    return K.mean(intersect/(union+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    print 'evaluation on training set:'\n",
    "    print model.evaluate(X_train, Y_train, batch_size=128)\n",
    "    print 'evaluation on validation set:'\n",
    "    print model.evaluate(X_val, Y_val, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wraps up operations on models\n",
    "def compile_fit_evaluate(model, quick_test=False, print_summary=True,\n",
    "                         save_log=True, save_model=True, del_model=False):\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=[multlabel_prec, multlabel_recall, multlabel_F1, multlabel_acc])\n",
    "    if print_summary:\n",
    "        print model.summary()\n",
    "        \n",
    "    if quick_test: # use tiny data for quick test\n",
    "        print '(quick test mode)'\n",
    "        model.fit(X_train[:100], Y_train[:100], nb_epoch=1)\n",
    "        return  \n",
    "    \n",
    "    _callbacks = [EarlyStopping(monitor='val_loss', patience=2)] #[RelaxAccHistory()]\n",
    "    if save_log:\n",
    "        logdir = os.path.join( LOG_PATH, time.strftime('%m%d')+'_'+str(model.name) )\n",
    "        if not os.path.exists(logdir):\n",
    "            os.makedirs(logdir)\n",
    "        _callbacks.append(TensorBoard(log_dir=logdir))\n",
    "        print 'run \"tensorboard --logdir=%s\" to launch tensorboard'%logdir\n",
    "    \n",
    "    model.fit( X_train, Y_train, \n",
    "              validation_data=(X_val, Y_val), \n",
    "              nb_epoch=N_EPOCHS, batch_size=SZ_BATCH, \n",
    "              sample_weight = sample_weight, \n",
    "              callbacks=_callbacks )\n",
    "    \n",
    "    print 'evaluating model...'\n",
    "    evaluate_model(model)\n",
    "    \n",
    "    if save_model: \n",
    "        model_fpath = os.path.join( MODEL_PATH, time.strftime('%m%d')+'_%s.h5'% str(model.name) )\n",
    "        model.save(model_fpath)\n",
    "    \n",
    "    if del_model:\n",
    "        del model # delete the model to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ''' ***NOTE***\n",
    "# To load models from file, we have to modify metrics.py at: \n",
    "# `/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras` \n",
    "# to add the `multlabel_XXX` function, otherwise throws exception ! \n",
    "\n",
    "# cf issue: https://github.com/fchollet/keras/issues/3911\n",
    "# '''\n",
    "# m = load_model(os.path.sep.join([MODEL_PATH, 'model_1conv1d.h5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model: 2 conv layers and 2 FC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_7 (Embedding)          (None, 1000, 100)     0           embedding_input_7[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_11 (Convolution1D) (None, 996, 128)      64128       embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_11 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_12 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_12 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 4992)          0           maxpooling1d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 4992)          0           flatten_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 500)           2496500     dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 500)           0           dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 50)            25050       dropout_11[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 2667726\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1119_model_2conv1d_2FC\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 669s - loss: 6.9946 - multlabel_prec: 0.2326 - multlabel_recall: 0.1248 - multlabel_F1: 0.1398 - multlabel_acc: 0.1044 - val_loss: 0.2403 - val_multlabel_prec: 0.3458 - val_multlabel_recall: 0.1655 - val_multlabel_F1: 0.1968 - val_multlabel_acc: 0.1474\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 547s - loss: 6.1531 - multlabel_prec: 0.2916 - multlabel_recall: 0.1715 - multlabel_F1: 0.1918 - multlabel_acc: 0.1452 - val_loss: 0.2331 - val_multlabel_prec: 0.3496 - val_multlabel_recall: 0.1833 - val_multlabel_F1: 0.2149 - val_multlabel_acc: 0.1632\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 513s - loss: 5.9559 - multlabel_prec: 0.3263 - multlabel_recall: 0.1902 - multlabel_F1: 0.2156 - multlabel_acc: 0.1625 - val_loss: 0.2326 - val_multlabel_prec: 0.2979 - val_multlabel_recall: 0.1740 - val_multlabel_F1: 0.1981 - val_multlabel_acc: 0.1516\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 516s - loss: 5.8228 - multlabel_prec: 0.3502 - multlabel_recall: 0.2016 - multlabel_F1: 0.2304 - multlabel_acc: 0.1735 - val_loss: 0.2278 - val_multlabel_prec: 0.3183 - val_multlabel_recall: 0.1914 - val_multlabel_F1: 0.2168 - val_multlabel_acc: 0.1648\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 515s - loss: 5.7164 - multlabel_prec: 0.3631 - multlabel_recall: 0.2068 - multlabel_F1: 0.2376 - multlabel_acc: 0.1785 - val_loss: 0.2287 - val_multlabel_prec: 0.3492 - val_multlabel_recall: 0.2009 - val_multlabel_F1: 0.2299 - val_multlabel_acc: 0.1736\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 514s - loss: 5.6325 - multlabel_prec: 0.3792 - multlabel_recall: 0.2140 - multlabel_F1: 0.2471 - multlabel_acc: 0.1855 - val_loss: 0.2366 - val_multlabel_prec: 0.3449 - val_multlabel_recall: 0.2003 - val_multlabel_F1: 0.2287 - val_multlabel_acc: 0.1706\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 511s - loss: 5.5698 - multlabel_prec: 0.3915 - multlabel_recall: 0.2201 - multlabel_F1: 0.2546 - multlabel_acc: 0.1908 - val_loss: 0.2272 - val_multlabel_prec: 0.3830 - val_multlabel_recall: 0.2297 - val_multlabel_F1: 0.2578 - val_multlabel_acc: 0.1940\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 520s - loss: 5.5085 - multlabel_prec: 0.4053 - multlabel_recall: 0.2272 - multlabel_F1: 0.2631 - multlabel_acc: 0.1968 - val_loss: 0.2304 - val_multlabel_prec: 0.4385 - val_multlabel_recall: 0.2372 - val_multlabel_F1: 0.2790 - val_multlabel_acc: 0.2075\n",
      "Epoch 9/20\n",
      "36916/36916 [==============================] - 496s - loss: 5.4479 - multlabel_prec: 0.4117 - multlabel_recall: 0.2298 - multlabel_F1: 0.2666 - multlabel_acc: 0.1996 - val_loss: 0.2321 - val_multlabel_prec: 0.4161 - val_multlabel_recall: 0.2477 - val_multlabel_F1: 0.2812 - val_multlabel_acc: 0.2101\n",
      "Epoch 10/20\n",
      "36916/36916 [==============================] - 496s - loss: 5.3907 - multlabel_prec: 0.4240 - multlabel_recall: 0.2375 - multlabel_F1: 0.2754 - multlabel_acc: 0.2067 - val_loss: 0.2291 - val_multlabel_prec: 0.4069 - val_multlabel_recall: 0.2335 - val_multlabel_F1: 0.2676 - val_multlabel_acc: 0.2001\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 202s   \n",
      "[0.20533039242994722, 0.45327223640878589, 0.25449295542663558, 0.29507185777562295, 0.22182246740079545]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 50s    \n",
      "[0.22912284545701328, 0.40686062603191098, 0.23352429316276099, 0.26763908724082691, 0.20010353464167818]\n"
     ]
    }
   ],
   "source": [
    "model_2conv1d_2FC = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_2conv1d_2FC')\n",
    "compile_fit_evaluate(model_2conv1d_2FC, flag_quick_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract embedding vector, and use SVM to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_input_7:0\", shape=(?, 1000), dtype=int32)\n",
      "Tensor(\"Relu_15:0\", shape=(?, 500), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print model_2conv1d_2FC.layers[0].input\n",
    "print model_2conv1d_2FC.layers[7].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "get_embedvec = K.function([model_2conv1d_2FC.layers[0].input, K.learning_phase()],\n",
    "                                  [model_2conv1d_2FC.layers[7].output])\n",
    "embedvec = lambda X: get_embedvec([X,0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 500)\n"
     ]
    }
   ],
   "source": [
    "# output in test mode = 0\n",
    "layer_output = embedvec(X_train[:10])\n",
    "print layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_embedvec(X):\n",
    "    BATCH_SZ = 128\n",
    "    embedded = []\n",
    "    for i in tqdm(xrange(0, X.shape[0], BATCH_SZ)):\n",
    "        x_batch = X[i:min(i+BATCH_SZ, X.shape[0])]\n",
    "        embedveci = embedvec(x_batch)\n",
    "        embedded.append(embedveci)\n",
    "    return np.vstack(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [03:43<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36916, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xembed_train = to_embedvec(X_train)\n",
    "print Xembed_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:53<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xembed_val = to_embedvecedvec(X_val)\n",
    "print Xembed_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilabel_evaluate(y_pred, y_true=Y_val):\n",
    "    y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "    tp = np.sum(y_true * y_pred, axis=-1) \n",
    "    sum_true = np.sum(y_true, axis=-1)\n",
    "    sum_pred = np.sum(y_pred, axis=-1)\n",
    "    union = np.sum(np.clip(y_true+y_pred, 0, 1), axis=-1)\n",
    "    print 'precision =', np.mean(tp/(sum_pred+1e-10))\n",
    "    print 'recall = ', np.mean(tp/(sum_true+1e-10))\n",
    "    print 'F1 = ', 2*np.mean(tp/(sum_true+sum_pred+1e-10))\n",
    "    print 'acc = ', np.mean(tp/(union+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [49:49<00:00, 55.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "[6557, 2955, 4408, 3886, 4165, 3979, 5597, 4060, 5141, 1509, 1502, 4272, 5689, 5523, 4434, 5904, 4437, 5646, 5089, 3257, 1506, 3581, 4412, 3627, 6208, 5112, 3402, 3360, 3155, 4566, 4587, 3683, 1519, 3817, 5082, 4642, 3108, 3850, 2912, 3297, 5426, 3361, 803, 3801, 3872, 5761, 4437, 4002, 1511, 8399]\n",
      "precision = 0.216178695678\n",
      "recall =  0.773221777101\n",
      "F1 =  0.310358096711\n",
      "acc =  0.207232309888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "              'alpha': [1, 1e-1, 3e-1, 1e-2, 3e-2, 1e-3, 3e-3, 1e-4],\n",
    "              'n_iter': [10, 50, 200]}\n",
    "\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "    sgd =  SGDClassifier(loss='hinge', penalty='l2', random_state=1, class_weight='balanced')\n",
    "    clf = GridSearchCV(sgd, parameters, n_jobs=-1)\n",
    "    clf.fit(Xembed_train, Y_train[:,i]) \n",
    "    clfs.append(clf)\n",
    "\n",
    "preds = [clfs[i].predict(Xembed_val) for i in xrange(N_LABELS)]    \n",
    "pred_svm = np.vstack(preds).T\n",
    "print pred_svm.shape\n",
    "print map(int, pred_svm.sum(axis=0))\n",
    "multilabel_evaluate(y_pred=pred_svm, y_true=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:34<00:00,  5.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "[5727, 2743, 3909, 3443, 3934, 3653, 5096, 3669, 4665, 1522, 1518, 3676, 4428, 4431, 4042, 4023, 3755, 4248, 3932, 2726, 1523, 3002, 3545, 3041, 3907, 3812, 2792, 2939, 2718, 3821, 3583, 2994, 1521, 3022, 3682, 3431, 2486, 2700, 1963, 2760, 3935, 2873, 796, 3105, 3086, 3839, 3322, 3160, 1520, 8182]\n",
      "precision = 0.229993005192\n",
      "recall =  0.703589020873\n",
      "F1 =  0.320225607346\n",
      "acc =  0.215284325998\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "for alpha in [1e-1, 1e-2, 1e-3]:\n",
    "    print '=='*4, ' alpha=%f' % alpha, '=='*4 \n",
    "    for i in tqdm(range(N_LABELS)):\n",
    "        clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                       class_weight='balanced',\n",
    "                       alpha=alpha, n_iter=200, random_state=1)\n",
    "        clf.fit(Xembed_train, Y_train[:,i]) \n",
    "        clfs.append(clf)\n",
    "    preds = [clfs[i].predict(Xembed_val) for i in xrange(N_LABELS)]    \n",
    "    pred_svm_dp = np.vstack(preds).T\n",
    "    print pred_svm_dp.shape\n",
    "    print map(int, pred_svm_dp.sum(axis=0))\n",
    "    multilabel_evaluate(y_pred=pred_svm_dp,y_true=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:42<00:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "[5911, 2817, 3869, 3491, 3977, 3697, 5271, 3739, 4877, 1525, 1516, 4133, 4953, 4859, 4223, 4862, 4150, 4999, 4543, 2860, 1525, 3191, 3932, 3190, 4733, 4395, 3024, 3006, 2759, 4059, 4066, 3380, 1529, 3368, 4253, 4132, 2695, 3179, 2258, 2921, 4660, 3083, 806, 3433, 3434, 4488, 3800, 3552, 1525, 8254]\n",
      "precision = 0.225381778819\n",
      "recall =  0.735914801374\n",
      "F1 =  0.317281640609\n",
      "acc =  0.212802657313\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1,C=0.2)\n",
    "    clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                   class_weight='balanced',\n",
    "                   alpha=1e-2, n_iter=200, random_state=1)\n",
    "    clf.fit(Xembed_train, Y_train[:,i]) \n",
    "    clfs.append(clf)\n",
    "preds = [clfs[i].predict(Xembed_val) for i in xrange(N_LABELS)]    \n",
    "pred_svm_dp = np.vstack(preds).T\n",
    "print pred_svm_dp.shape\n",
    "print map(int, pred_svm_dp.sum(axis=0))\n",
    "multilabel_evaluate(y_pred=pred_svm_dp,y_true=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:59<00:00,  6.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "[6557, 2955, 4408, 3886, 4165, 3979, 5597, 4060, 5141, 1509, 1502, 4272, 5689, 5523, 4434, 5904, 4437, 5646, 5089, 3257, 1506, 3581, 4412, 3627, 6208, 5112, 3402, 3360, 3155, 4566, 4587, 3683, 1519, 3817, 5082, 4642, 3108, 3850, 2912, 3297, 5426, 3361, 803, 3801, 3872, 5761, 4437, 4002, 1511, 8399]\n",
      "precision = 0.216178695678\n",
      "recall =  0.773221777101\n",
      "F1 =  0.310358096711\n",
      "acc =  0.207232309888\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1,C=0.2)\n",
    "    clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                   class_weight='balanced',\n",
    "                   alpha=1e-1, n_iter=200, random_state=1)\n",
    "    clf.fit(Xembed_train, Y_train[:,i]) \n",
    "    clfs.append(clf)\n",
    "preds = [clfs[i].predict(Xembed_val) for i in xrange(N_LABELS)]    \n",
    "pred_svm_dp = np.vstack(preds).T\n",
    "print pred_svm_dp.shape\n",
    "print map(int, pred_svm_dp.sum(axis=0))\n",
    "multilabel_evaluate(y_pred=pred_svm_dp,y_true=Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag_quick_test = 0 # set to False/0 to run on whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 1000, 100)     0           embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 996, 128)      64128       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25472)         0           maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 25472)         0           flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            1273650     dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1337778\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1119_model_1conv1d_dropout\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 419s - loss: 0.2733 - multlabel_prec: 0.2390 - multlabel_recall: 0.1370 - multlabel_F1: 0.1523 - multlabel_acc: 0.1158 - val_loss: 0.2389 - val_multlabel_prec: 0.2616 - val_multlabel_recall: 0.1546 - val_multlabel_F1: 0.1711 - val_multlabel_acc: 0.1316\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 420s - loss: 0.2292 - multlabel_prec: 0.3255 - multlabel_recall: 0.1907 - multlabel_F1: 0.2146 - multlabel_acc: 0.1640 - val_loss: 0.2340 - val_multlabel_prec: 0.2961 - val_multlabel_recall: 0.1840 - val_multlabel_F1: 0.2037 - val_multlabel_acc: 0.1550\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 421s - loss: 0.2187 - multlabel_prec: 0.3703 - multlabel_recall: 0.2107 - multlabel_F1: 0.2406 - multlabel_acc: 0.1838 - val_loss: 0.2342 - val_multlabel_prec: 0.3238 - val_multlabel_recall: 0.1800 - val_multlabel_F1: 0.2090 - val_multlabel_acc: 0.1577\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 499s - loss: 0.2121 - multlabel_prec: 0.4017 - multlabel_recall: 0.2281 - multlabel_F1: 0.2613 - multlabel_acc: 0.2004 - val_loss: 0.2420 - val_multlabel_prec: 0.3318 - val_multlabel_recall: 0.1860 - val_multlabel_F1: 0.2125 - val_multlabel_acc: 0.1616\n",
      "Epoch 5/20\n",
      "21120/36916 [================>.............] - ETA: 206s - loss: 0.2058 - multlabel_prec: 0.4314 - multlabel_recall: 0.2455 - multlabel_F1: 0.2811 - multlabel_acc: 0.2162"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a36d1521237c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         ], \n\u001b[1;32m     11\u001b[0m         name='model_1conv1d_dropout')\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcompile_fit_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1conv1d_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_quick_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9fef4acfb1ab>\u001b[0m in \u001b[0;36mcompile_fit_evaluate\u001b[0;34m(model, quick_test, print_summary, save_log, save_model, del_model)\u001b[0m\n\u001b[1;32m     25\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSZ_BATCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m               callbacks=_callbacks )\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'evaluating model...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_1conv1d_dropout = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQ_LEN, trainable=False # keep the embeddings fixed\n",
    "             ),# embedding layer\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.2),\n",
    "            Dense(N_LABELS, activation='sigmoid') \n",
    "        ], \n",
    "        name='model_1conv1d_dropout')\n",
    "compile_fit_evaluate(model_1conv1d_dropout, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 1000, 100)     0           embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 996, 128)      64128       embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 4992)          0           maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4992)          0           flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 50)            249650      dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 395826\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1119_model_2conv1d_dropout\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "  128/36916 [..............................] - ETA: 654s - loss: 0.6972 - multlabel_prec: 0.1025 - multlabel_recall: 0.4451 - multlabel_F1: 0.1559 - multlabel_acc: 0.0903"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-49d8d38ea72b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             Dense(N_LABELS, activation='sigmoid') ],\n\u001b[1;32m     12\u001b[0m         name = 'model_2conv1d_dropout')\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcompile_fit_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2conv1d_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_quick_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9fef4acfb1ab>\u001b[0m in \u001b[0;36mcompile_fit_evaluate\u001b[0;34m(model, quick_test, print_summary, save_log, save_model, del_model)\u001b[0m\n\u001b[1;32m     25\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSZ_BATCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m               callbacks=_callbacks )\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'evaluating model...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2 conv1d layers\n",
    "model_2conv1d_dropout = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.2),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_2conv1d_dropout')\n",
    "compile_fit_evaluate(model_2conv1d_dropout, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 1000, 100)     0           embedding_input_5[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_7 (Convolution1D)  (None, 996, 128)      64128       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_7 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_8 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_9 (Convolution1D)  (None, 35, 128)       82048       maxpooling1d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_9 (MaxPooling1D)    (None, 7, 128)        0           convolution1d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 896)           0           maxpooling1d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 896)           0           flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 50)            44850       dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 273074\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1119_model_3conv1d_dropout\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      " 1920/36916 [>.............................] - ETA: 500s - loss: 0.3870 - multlabel_prec: 0.1681 - multlabel_recall: nan - multlabel_F1: nan - multlabel_acc: nan"
     ]
    }
   ],
   "source": [
    "model_3conv1d_dropout =Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_3conv1d_dropout')\n",
    "\n",
    "compile_fit_evaluate(model_3conv1d_dropout, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 1000, 100)     0           embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 996, 128)      64128       embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25472)         0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 50)            1273650     flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1337778\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1018_model_1conv1d\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 411s - loss: 0.2759 - multlabel_prec: 0.8881 - multlabel_recall: 0.3695 - multlabel_F1: 0.4585 - multlabel_acc: 0.3352 - val_loss: 0.2409 - val_multlabel_prec: 0.8696 - val_multlabel_recall: 0.4040 - val_multlabel_F1: 0.4912 - val_multlabel_acc: 0.3668\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 396s - loss: 0.2259 - multlabel_prec: 0.8921 - multlabel_recall: 0.4152 - multlabel_F1: 0.5062 - multlabel_acc: 0.3810 - val_loss: 0.2394 - val_multlabel_prec: 0.9037 - val_multlabel_recall: 0.4022 - val_multlabel_F1: 0.4931 - val_multlabel_acc: 0.3695\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 395s - loss: 0.2112 - multlabel_prec: 0.8930 - multlabel_recall: 0.4426 - multlabel_F1: 0.5331 - multlabel_acc: 0.4064 - val_loss: 0.2397 - val_multlabel_prec: 0.8614 - val_multlabel_recall: 0.4257 - val_multlabel_F1: 0.5098 - val_multlabel_acc: 0.3826\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 397s - loss: 0.2002 - multlabel_prec: 0.8876 - multlabel_recall: 0.4718 - multlabel_F1: 0.5595 - multlabel_acc: 0.4323 - val_loss: 0.2504 - val_multlabel_prec: 0.7782 - val_multlabel_recall: 0.4479 - val_multlabel_F1: 0.5116 - val_multlabel_acc: 0.3800\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 395s - loss: 0.1915 - multlabel_prec: 0.8847 - multlabel_recall: 0.5019 - multlabel_F1: 0.5851 - multlabel_acc: 0.4576 - val_loss: 0.2820 - val_multlabel_prec: 0.8317 - val_multlabel_recall: 0.4299 - val_multlabel_F1: 0.5132 - val_multlabel_acc: 0.3837\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 167s   \n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 41s    \n"
     ]
    }
   ],
   "source": [
    "# with only 1 conv1d layer\n",
    "model_1conv1d = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQ_LEN, trainable=False # keep the embeddings fixed\n",
    "             ),# embedding layer\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dense(N_LABELS, activation='sigmoid') \n",
    "        ], \n",
    "        name='model_1conv1d')\n",
    "compile_fit_evaluate(model_1conv1d, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 1000, 100)     0           embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 996, 128)      64128       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 4992)          0           maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            249650      flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 395826\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1018_model_2conv1d\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 483s - loss: 0.2609 - multlabel_prec: 0.8899 - multlabel_recall: 0.3632 - multlabel_F1: 0.4512 - multlabel_acc: 0.3288 - val_loss: 0.2407 - val_multlabel_prec: 0.9373 - val_multlabel_recall: 0.3667 - val_multlabel_F1: 0.4632 - val_multlabel_acc: 0.3447\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 481s - loss: 0.2328 - multlabel_prec: 0.8906 - multlabel_recall: 0.4031 - multlabel_F1: 0.4926 - multlabel_acc: 0.3679 - val_loss: 0.2400 - val_multlabel_prec: 0.8563 - val_multlabel_recall: 0.4343 - val_multlabel_F1: 0.5122 - val_multlabel_acc: 0.3845\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 481s - loss: 0.2232 - multlabel_prec: 0.8850 - multlabel_recall: 0.4227 - multlabel_F1: 0.5139 - multlabel_acc: 0.3872 - val_loss: 0.2274 - val_multlabel_prec: 0.8861 - val_multlabel_recall: 0.4286 - val_multlabel_F1: 0.5134 - val_multlabel_acc: 0.3879\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 485s - loss: 0.2161 - multlabel_prec: 0.8836 - multlabel_recall: 0.4362 - multlabel_F1: 0.5273 - multlabel_acc: 0.3999 - val_loss: 0.2323 - val_multlabel_prec: 0.9132 - val_multlabel_recall: 0.4046 - val_multlabel_F1: 0.4955 - val_multlabel_acc: 0.3713\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 481s - loss: 0.2101 - multlabel_prec: 0.8821 - multlabel_recall: 0.4485 - multlabel_F1: 0.5394 - multlabel_acc: 0.4112 - val_loss: 0.2254 - val_multlabel_prec: 0.8509 - val_multlabel_recall: 0.4458 - val_multlabel_F1: 0.5273 - val_multlabel_acc: 0.3991\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 486s - loss: 0.2041 - multlabel_prec: 0.8799 - multlabel_recall: 0.4610 - multlabel_F1: 0.5514 - multlabel_acc: 0.4227 - val_loss: 0.2277 - val_multlabel_prec: 0.8616 - val_multlabel_recall: 0.4397 - val_multlabel_F1: 0.5236 - val_multlabel_acc: 0.3951\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 487s - loss: 0.1979 - multlabel_prec: 0.8808 - multlabel_recall: 0.4743 - multlabel_F1: 0.5643 - multlabel_acc: 0.4355 - val_loss: 0.2294 - val_multlabel_prec: 0.8216 - val_multlabel_recall: 0.4561 - val_multlabel_F1: 0.5339 - val_multlabel_acc: 0.4024\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 480s - loss: 0.1918 - multlabel_prec: 0.8784 - multlabel_recall: 0.4906 - multlabel_F1: 0.5785 - multlabel_acc: 0.4499 - val_loss: 0.2303 - val_multlabel_prec: 0.8223 - val_multlabel_recall: 0.4581 - val_multlabel_F1: 0.5359 - val_multlabel_acc: 0.4045\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 198s   \n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 49s    \n"
     ]
    }
   ],
   "source": [
    "# 2 conv1d layers\n",
    "model_2conv1d = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_2conv1d')\n",
    "compile_fit_evaluate(model_2conv1d, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 1000, 100)     0           embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 996, 128)      64128       embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 35, 128)       82048       maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_6 (MaxPooling1D)    (None, 7, 128)        0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 896)           0           maxpooling1d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 50)            44850       flatten_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 273074\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1018_model_3conv1d\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 499s - loss: 0.2685 - multlabel_prec: 0.8960 - multlabel_recall: 0.3453 - multlabel_F1: 0.4337 - multlabel_acc: 0.3126 - val_loss: 0.2651 - val_multlabel_prec: 0.7968 - val_multlabel_recall: 0.3965 - val_multlabel_F1: 0.4757 - val_multlabel_acc: 0.3459\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 498s - loss: 0.2406 - multlabel_prec: 0.8924 - multlabel_recall: 0.3875 - multlabel_F1: 0.4763 - multlabel_acc: 0.3531 - val_loss: 0.2548 - val_multlabel_prec: 0.7682 - val_multlabel_recall: 0.4217 - val_multlabel_F1: 0.4896 - val_multlabel_acc: 0.3569\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 501s - loss: 0.2315 - multlabel_prec: 0.8869 - multlabel_recall: 0.4092 - multlabel_F1: 0.4984 - multlabel_acc: 0.3730 - val_loss: 0.2301 - val_multlabel_prec: 0.8751 - val_multlabel_recall: 0.4165 - val_multlabel_F1: 0.4993 - val_multlabel_acc: 0.3741\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 496s - loss: 0.2253 - multlabel_prec: 0.8806 - multlabel_recall: 0.4228 - multlabel_F1: 0.5125 - multlabel_acc: 0.3854 - val_loss: 0.2358 - val_multlabel_prec: 0.9062 - val_multlabel_recall: 0.4043 - val_multlabel_F1: 0.5013 - val_multlabel_acc: 0.3767\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 497s - loss: 0.2205 - multlabel_prec: 0.8753 - multlabel_recall: 0.4352 - multlabel_F1: 0.5254 - multlabel_acc: 0.3971 - val_loss: 0.2283 - val_multlabel_prec: 0.9061 - val_multlabel_recall: 0.4116 - val_multlabel_F1: 0.5088 - val_multlabel_acc: 0.3838\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 496s - loss: 0.2167 - multlabel_prec: 0.8728 - multlabel_recall: 0.4426 - multlabel_F1: 0.5332 - multlabel_acc: 0.4041 - val_loss: 0.2278 - val_multlabel_prec: 0.8923 - val_multlabel_recall: 0.4215 - val_multlabel_F1: 0.5178 - val_multlabel_acc: 0.3912\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 496s - loss: 0.2129 - multlabel_prec: 0.8713 - multlabel_recall: 0.4496 - multlabel_F1: 0.5406 - multlabel_acc: 0.4112 - val_loss: 0.2283 - val_multlabel_prec: 0.8692 - val_multlabel_recall: 0.4263 - val_multlabel_F1: 0.5193 - val_multlabel_acc: 0.3920\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 497s - loss: 0.2093 - multlabel_prec: 0.8713 - multlabel_recall: 0.4556 - multlabel_F1: 0.5466 - multlabel_acc: 0.4168 - val_loss: 0.2246 - val_multlabel_prec: 0.8242 - val_multlabel_recall: 0.4658 - val_multlabel_F1: 0.5429 - val_multlabel_acc: 0.4114\n",
      "Epoch 9/20\n",
      "36916/36916 [==============================] - 496s - loss: 0.2056 - multlabel_prec: 0.8707 - multlabel_recall: 0.4629 - multlabel_F1: 0.5541 - multlabel_acc: 0.4242 - val_loss: 0.2296 - val_multlabel_prec: 0.8808 - val_multlabel_recall: 0.4303 - val_multlabel_F1: 0.5201 - val_multlabel_acc: 0.3931\n",
      "Epoch 10/20\n",
      "36916/36916 [==============================] - 501s - loss: 0.2015 - multlabel_prec: 0.8698 - multlabel_recall: 0.4725 - multlabel_F1: 0.5631 - multlabel_acc: 0.4329 - val_loss: 0.2233 - val_multlabel_prec: 0.8249 - val_multlabel_recall: 0.4619 - val_multlabel_F1: 0.5382 - val_multlabel_acc: 0.4069\n",
      "Epoch 11/20\n",
      "36916/36916 [==============================] - 496s - loss: 0.1971 - multlabel_prec: 0.8705 - multlabel_recall: 0.4818 - multlabel_F1: 0.5720 - multlabel_acc: 0.4417 - val_loss: 0.2295 - val_multlabel_prec: 0.7916 - val_multlabel_recall: 0.4760 - val_multlabel_F1: 0.5423 - val_multlabel_acc: 0.4092\n",
      "Epoch 12/20\n",
      "36916/36916 [==============================] - 497s - loss: 0.1929 - multlabel_prec: 0.8694 - multlabel_recall: 0.4938 - multlabel_F1: 0.5825 - multlabel_acc: 0.4524 - val_loss: 0.2301 - val_multlabel_prec: 0.8055 - val_multlabel_recall: 0.4711 - val_multlabel_F1: 0.5393 - val_multlabel_acc: 0.4076\n",
      "Epoch 13/20\n",
      "36916/36916 [==============================] - 498s - loss: 0.1885 - multlabel_prec: 0.8703 - multlabel_recall: 0.5054 - multlabel_F1: 0.5931 - multlabel_acc: 0.4635 - val_loss: 0.2361 - val_multlabel_prec: 0.8286 - val_multlabel_recall: 0.4563 - val_multlabel_F1: 0.5316 - val_multlabel_acc: 0.4014\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 204s   \n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 51s    \n"
     ]
    }
   ],
   "source": [
    "# 3 conv1d layers \n",
    "model_3conv1d =Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_3conv1d')\n",
    "\n",
    "compile_fit_evaluate(model_3conv1d, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 1000, 100)     0           embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 1000, 100, 1)  0           embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 996, 96, 8)    208         reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 99, 9, 8)      0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 7128)          0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 50)            356450      flatten_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 356658\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1018_model_1conv2d\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 771s - loss: 0.4867 - multlabel_prec: 0.7838 - multlabel_recall: 0.3370 - multlabel_F1: 0.4070 - multlabel_acc: 0.2841 - val_loss: 0.2843 - val_multlabel_prec: 0.8587 - val_multlabel_recall: 0.3420 - val_multlabel_F1: 0.4336 - val_multlabel_acc: 0.3086\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 770s - loss: 0.2663 - multlabel_prec: 0.9096 - multlabel_recall: 0.3325 - multlabel_F1: 0.4324 - multlabel_acc: 0.3107 - val_loss: 0.2708 - val_multlabel_prec: 0.9581 - val_multlabel_recall: 0.3194 - val_multlabel_F1: 0.4245 - val_multlabel_acc: 0.3073\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 772s - loss: 0.2548 - multlabel_prec: 0.8967 - multlabel_recall: 0.3571 - multlabel_F1: 0.4522 - multlabel_acc: 0.3294 - val_loss: 0.2594 - val_multlabel_prec: 0.9160 - val_multlabel_recall: 0.3672 - val_multlabel_F1: 0.4587 - val_multlabel_acc: 0.3392\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 769s - loss: 0.2485 - multlabel_prec: 0.8919 - multlabel_recall: 0.3715 - multlabel_F1: 0.4636 - multlabel_acc: 0.3405 - val_loss: 0.2562 - val_multlabel_prec: 0.8928 - val_multlabel_recall: 0.3657 - val_multlabel_F1: 0.4593 - val_multlabel_acc: 0.3390\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 769s - loss: 0.2428 - multlabel_prec: 0.8895 - multlabel_recall: 0.3817 - multlabel_F1: 0.4721 - multlabel_acc: 0.3485 - val_loss: 0.2591 - val_multlabel_prec: 0.9017 - val_multlabel_recall: 0.3712 - val_multlabel_F1: 0.4617 - val_multlabel_acc: 0.3412\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 770s - loss: 0.2378 - multlabel_prec: 0.8888 - multlabel_recall: 0.3901 - multlabel_F1: 0.4794 - multlabel_acc: 0.3556 - val_loss: 0.2618 - val_multlabel_prec: 0.8763 - val_multlabel_recall: 0.3814 - val_multlabel_F1: 0.4670 - val_multlabel_acc: 0.3455\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 773s - loss: 0.2331 - multlabel_prec: 0.8873 - multlabel_recall: 0.3984 - multlabel_F1: 0.4867 - multlabel_acc: 0.3622 - val_loss: 0.2592 - val_multlabel_prec: 0.7388 - val_multlabel_recall: 0.4189 - val_multlabel_F1: 0.4817 - val_multlabel_acc: 0.3482\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 287s   \n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 71s    \n"
     ]
    }
   ],
   "source": [
    "# 2d conv models\n",
    "'''for 2d conv, the nb_filters cann't be too big: \n",
    "   128*MAX_SEQ_LEN*EMBEDDING_DIM is too much memory\n",
    "   nb_filter = 64 is fine for 1 conv2d layer\n",
    "'''\n",
    "model_1conv2d = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQ_LEN, trainable=False),\n",
    "            Reshape( (MAX_SEQ_LEN, EMBEDDING_DIM, 1) ), # **need to manually reshape and add a channel**\n",
    "            Conv2D(8, 5, 5, activation='relu' ), # , input_shape=(MAX_SEQ_LEN, EMBEDDING_DIM, 1)\n",
    "            MaxPooling2D((10,10)),# need to downsample heavily to reduce parameters... \n",
    "            Flatten(),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_1conv2d')\n",
    "# model_1conv2d.summary()\n",
    "compile_fit_evaluate(model_1conv2d, flag_quick_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 1000, 100)     0           embedding_input_5[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 1000, 100, 1)  0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 996, 96, 32)   832         reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 199, 19, 32)   0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 195, 15, 8)    6408        maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 97, 7, 8)      0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 5432)          0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 50)            271650      flatten_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 278890\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1018_model_2conv2d\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 1783s - loss: 0.2922 - multlabel_prec: 0.9106 - multlabel_recall: 0.3186 - multlabel_F1: 0.4160 - multlabel_acc: 0.2962 - val_loss: 0.2810 - val_multlabel_prec: 0.9706 - val_multlabel_recall: 0.3051 - val_multlabel_F1: 0.4141 - val_multlabel_acc: 0.2983\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 1772s - loss: 0.2763 - multlabel_prec: 0.9489 - multlabel_recall: 0.3125 - multlabel_F1: 0.4174 - multlabel_acc: 0.2991 - val_loss: 0.2751 - val_multlabel_prec: 0.9691 - val_multlabel_recall: 0.3090 - val_multlabel_F1: 0.4165 - val_multlabel_acc: 0.3004\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 1770s - loss: 0.2647 - multlabel_prec: 0.9167 - multlabel_recall: 0.3308 - multlabel_F1: 0.4317 - multlabel_acc: 0.3105 - val_loss: 0.2602 - val_multlabel_prec: 0.8452 - val_multlabel_recall: 0.3736 - val_multlabel_F1: 0.4577 - val_multlabel_acc: 0.3329\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 1769s - loss: 0.2555 - multlabel_prec: 0.9019 - multlabel_recall: 0.3501 - multlabel_F1: 0.4451 - multlabel_acc: 0.3235 - val_loss: 0.2541 - val_multlabel_prec: 0.9276 - val_multlabel_recall: 0.3394 - val_multlabel_F1: 0.4419 - val_multlabel_acc: 0.3220\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 1765s - loss: 0.2535 - multlabel_prec: 0.8959 - multlabel_recall: 0.3625 - multlabel_F1: 0.4547 - multlabel_acc: 0.3325 - val_loss: 0.2519 - val_multlabel_prec: 0.8611 - val_multlabel_recall: 0.3830 - val_multlabel_F1: 0.4679 - val_multlabel_acc: 0.3450\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 1769s - loss: 0.2520 - multlabel_prec: 0.8941 - multlabel_recall: 0.3674 - multlabel_F1: 0.4582 - multlabel_acc: 0.3358 - val_loss: 0.2519 - val_multlabel_prec: 0.9239 - val_multlabel_recall: 0.3668 - val_multlabel_F1: 0.4534 - val_multlabel_acc: 0.3351\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 1763s - loss: 0.2475 - multlabel_prec: 0.8921 - multlabel_recall: 0.3719 - multlabel_F1: 0.4619 - multlabel_acc: 0.3393 - val_loss: 0.2491 - val_multlabel_prec: 0.9058 - val_multlabel_recall: 0.3745 - val_multlabel_F1: 0.4633 - val_multlabel_acc: 0.3431\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 1766s - loss: 0.2455 - multlabel_prec: 0.8922 - multlabel_recall: 0.3738 - multlabel_F1: 0.4636 - multlabel_acc: 0.3408 - val_loss: 0.2478 - val_multlabel_prec: 0.8774 - val_multlabel_recall: 0.3785 - val_multlabel_F1: 0.4688 - val_multlabel_acc: 0.3455\n",
      "Epoch 9/20\n",
      "36916/36916 [==============================] - 1765s - loss: 0.2459 - multlabel_prec: 0.8913 - multlabel_recall: 0.3774 - multlabel_F1: 0.4670 - multlabel_acc: 0.3439 - val_loss: 0.2468 - val_multlabel_prec: 0.8284 - val_multlabel_recall: 0.4050 - val_multlabel_F1: 0.4833 - val_multlabel_acc: 0.3557\n",
      "Epoch 10/20\n",
      "36916/36916 [==============================] - 1765s - loss: 0.2423 - multlabel_prec: 0.8917 - multlabel_recall: 0.3807 - multlabel_F1: 0.4701 - multlabel_acc: 0.3466 - val_loss: 0.2448 - val_multlabel_prec: 0.9168 - val_multlabel_recall: 0.3674 - val_multlabel_F1: 0.4625 - val_multlabel_acc: 0.3419\n",
      "Epoch 11/20\n",
      "36916/36916 [==============================] - 1766s - loss: 0.2453 - multlabel_prec: 0.8884 - multlabel_recall: 0.3833 - multlabel_F1: 0.4722 - multlabel_acc: 0.3484 - val_loss: 0.2442 - val_multlabel_prec: 0.8746 - val_multlabel_recall: 0.3867 - val_multlabel_F1: 0.4746 - val_multlabel_acc: 0.3507\n",
      "Epoch 12/20\n",
      "36916/36916 [==============================] - 1767s - loss: 0.2401 - multlabel_prec: 0.8914 - multlabel_recall: 0.3857 - multlabel_F1: 0.4750 - multlabel_acc: 0.3515 - val_loss: 0.2448 - val_multlabel_prec: 0.8278 - val_multlabel_recall: 0.3937 - val_multlabel_F1: 0.4784 - val_multlabel_acc: 0.3499\n",
      "Epoch 13/20\n",
      "36916/36916 [==============================] - 1762s - loss: 0.2436 - multlabel_prec: 0.8879 - multlabel_recall: 0.3883 - multlabel_F1: 0.4766 - multlabel_acc: 0.3528 - val_loss: 0.2439 - val_multlabel_prec: 0.8294 - val_multlabel_recall: 0.3980 - val_multlabel_F1: 0.4802 - val_multlabel_acc: 0.3518\n",
      "Epoch 14/20\n",
      "36916/36916 [==============================] - 1761s - loss: 0.2383 - multlabel_prec: 0.8890 - multlabel_recall: 0.3899 - multlabel_F1: 0.4788 - multlabel_acc: 0.3547 - val_loss: 0.2498 - val_multlabel_prec: 0.8948 - val_multlabel_recall: 0.3886 - val_multlabel_F1: 0.4719 - val_multlabel_acc: 0.3499\n",
      "Epoch 15/20\n",
      "36916/36916 [==============================] - 1763s - loss: 0.2384 - multlabel_prec: 0.8878 - multlabel_recall: 0.3931 - multlabel_F1: 0.4812 - multlabel_acc: 0.3571 - val_loss: 0.2526 - val_multlabel_prec: 0.7634 - val_multlabel_recall: 0.4414 - val_multlabel_F1: 0.4996 - val_multlabel_acc: 0.3680\n",
      "Epoch 16/20\n",
      "36916/36916 [==============================] - 1763s - loss: 0.2373 - multlabel_prec: 0.8861 - multlabel_recall: 0.3943 - multlabel_F1: 0.4827 - multlabel_acc: 0.3584 - val_loss: 0.2483 - val_multlabel_prec: 0.8862 - val_multlabel_recall: 0.3805 - val_multlabel_F1: 0.4720 - val_multlabel_acc: 0.3489\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 564s   \n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 139s   \n"
     ]
    }
   ],
   "source": [
    "model_2conv2d = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQ_LEN, trainable=False),\n",
    "            Reshape( (MAX_SEQ_LEN, EMBEDDING_DIM, 1) ), # **need to manually reshape and add a channel**\n",
    "            Conv2D(32, 5, 5, activation='relu' ), # , input_shape=(MAX_SEQ_LEN, EMBEDDING_DIM, 1)\n",
    "            MaxPooling2D((5,5)),\n",
    "            Conv2D(8, 5, 5, activation='relu' ), \n",
    "            MaxPooling2D((2,2)),\n",
    "            Flatten(),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_2conv2d')\n",
    "compile_fit_evaluate(model_2conv2d, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_6 (Embedding)          (None, 1000, 100)     0           embedding_input_6[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)              (None, 1000, 100, 1)  0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 996, 96, 64)   1664        reshape_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 199, 19, 64)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 195, 15, 32)   51232       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 97, 7, 32)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 93, 3, 8)      6408        maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 46, 1, 8)      0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 368)           0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 50)            18450       flatten_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 77754\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_3conv2d = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQ_LEN, trainable=False),\n",
    "            Reshape( (MAX_SEQ_LEN, EMBEDDING_DIM, 1) ), # **need to manually reshape and add a channel**\n",
    "            Conv2D(64, 5, 5, activation='relu' ), # , input_shape=(MAX_SEQ_LEN, EMBEDDING_DIM, 1)\n",
    "            MaxPooling2D((5,5)),\n",
    "            Conv2D(32, 5, 5, activation='relu' ), \n",
    "            MaxPooling2D((2,2)),\n",
    "            Conv2D(8, 5, 5, activation='relu' ), \n",
    "            MaxPooling2D((2,2)),\n",
    "            Flatten(),\n",
    "            Dense(N_LABELS, activation='softmax') ],\n",
    "        name='model_3conv2d')\n",
    "print model_3conv2d.summary()\n",
    "# maybe this is too slow to compute? estimated time: 100 * 30 * (N_EPOCH+1) ~= 9hours ...\n",
    "# compile_fit_evaluate(model_3conv2d, flag_quick_test) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

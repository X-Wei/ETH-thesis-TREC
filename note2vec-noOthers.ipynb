{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In this notebook: run the model with the last label (\"others\") removed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproductive\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "NOTE_DATA_DIR = '/local/XW/DATA/MIMIC/noteevents_by_sid/'\n",
    "ICD_FPATH = 'data/subject_diag_icds.txt'\n",
    "PK_FPATH = 'data/diag_processed_data.pk' # './processed_data_small.pk'\n",
    "MODEL_PATH = './models/'\n",
    "LOG_PATH = './logs/'\n",
    "# constants\n",
    "N_LABELS = 49 # *** <-- remove last \"others\" label ***\n",
    "K_ICDS_TOKEEP = N_LABELS - 1 # predict only on top K frequent icd codes\n",
    "N_SUBJECTS = 41886\n",
    "# word2vec configurations\n",
    "GLOVE_DIR = '/local/XW/DATA/glove.6B/'\n",
    "MAX_SEQ_LEN = 1000 # max length of input sequence (pad/truncate to fix length)\n",
    "MAX_NB_WORDS = 20000 # top 20k most freq words\n",
    "EMBEDDING_DIM = 100\n",
    "# learning configurations\n",
    "VALIDATION_SPLIT = 0.2\n",
    "N_EPOCHS = 20\n",
    "SZ_BATCH = 512 # large batch size ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pickled data\n",
    "pk_data = pk.load(open(PK_FPATH, 'rb'))\n",
    "embedding_matrix = pk_data['embedding_matrix']\n",
    "X_train, Y_train = pk_data['X_train'], pk_data['Y_train']\n",
    "X_val, Y_val = pk_data['X_val'], pk_data['Y_val']\n",
    "nb_words = MAX_NB_WORDS # forgot to pickle this number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "11730\n",
      "(36916, 1000) (36916, 50)\n"
     ]
    }
   ],
   "source": [
    "# found one row that is ALL 0) (strange?)\n",
    "print np.min( np.sum(Y_train, axis=1) ), np.min( np.sum(Y_val, axis=1) )\n",
    "print np.argmin( np.sum(Y_train, axis=1) )\n",
    "Y_train[11730]\n",
    "Y_train = np.delete(Y_train, 11730, axis=0)\n",
    "X_train = np.delete(X_train, 11730, axis=0)\n",
    "print X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36916, 49) (9229, 49)\n"
     ]
    }
   ],
   "source": [
    "# *** remove last column of Y_train and Y_val ***\n",
    "Y_train = Y_train[:,:-1]\n",
    "Y_val = Y_val[:, :-1]\n",
    "print Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_n_poslabels = Y_train.sum(axis=1) # this can be used as sample weights: more sample the ones with more 1s..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22.627417  ,   5.19615242,   5.19615242, ...,   5.19615242,\n",
       "         5.19615242,   1.        ])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_n_poslabels**(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.60232587,   1.25496374,   1.36692973,   1.43641759,\n",
       "         2.06435057,   2.15704779,   2.22239335,   2.62282387,\n",
       "         3.22839241,   3.24966444,   3.437979  ,   3.64780256,\n",
       "         3.67914395,   4.02508074,   4.86485374,   5.02411415,\n",
       "         5.28468609,   6.04044627,   6.46337026,   6.71336902,\n",
       "         6.64585067,   7.05709269,   7.24824906,   7.81638511,\n",
       "         8.71124363,   9.04224537,   8.78927112,   9.1492535 ,\n",
       "         9.52807083,   9.70417161,   9.52165102,   9.59916762,\n",
       "         9.85850607,  10.18691224,  10.94959546,  11.01470692,\n",
       "        12.10316638,  12.54696038,  12.52666333,  12.40602183,\n",
       "        12.59794352,  12.9325765 ,  13.2377194 ,  14.10470332,\n",
       "        15.02935251,  15.02935251,  15.08443868,  15.75776903,  15.63965989])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_freq = 1e6*Y_train.sum(axis=0)**(-1.5)\n",
    "inv_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_weight = (inv_freq * Y_train).sum(axis=1) # + (inv_freq * Y_train).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50.89430951,  25.72348956,  16.54614951, ...,  13.33349412,\n",
       "        13.33349412,   1.25496374])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** this metrics is the continus relaxation of what we really want, so the acc output during training is not precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multlabel_prec(y_true, y_pred):\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return K.mean(tp/(sum_pred+1e-10)) # to avoid NaN precision\n",
    "    \n",
    "def multlabel_recall(y_true, y_pred):\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return K.mean(tp/(sum_true+1e-10)) \n",
    "\n",
    "def multlabel_F1(y_true, y_pred):\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return 2*K.mean(tp/(sum_true+sum_pred+1e-10))\n",
    "\n",
    "def multlabel_acc(y_true, y_pred):\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    intersect = y_true * y_pred\n",
    "    intersect = K.sum(intersect, axis=-1)\n",
    "    union = K.clip(y_true+y_pred, 0, 1)\n",
    "    union = K.sum(union, axis=-1)\n",
    "    return K.mean(intersect/(union+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    print 'evaluation on training set:'\n",
    "    print model.evaluate(X_train, Y_train, batch_size=128)\n",
    "    print 'evaluation on validation set:'\n",
    "    print model.evaluate(X_val, Y_val, batch_size=128)\n",
    "\n",
    "# wraps up operations on models\n",
    "def compile_fit_evaluate(model, quick_test=False, print_summary=True,\n",
    "                         save_log=True, save_model=True, del_model=False):\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=[multlabel_prec, multlabel_recall, multlabel_F1, multlabel_acc])\n",
    "    if print_summary:\n",
    "        print model.summary()\n",
    "        \n",
    "    if quick_test: # use tiny data for quick test\n",
    "        print '(quick test mode)'\n",
    "        model.fit(X_train[:100], Y_train[:100], nb_epoch=1)\n",
    "        return  \n",
    "    \n",
    "    _callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "    if save_log:\n",
    "        logdir = os.path.join( LOG_PATH, time.strftime('%m%d')+'_'+str(model.name) )\n",
    "        if not os.path.exists(logdir):\n",
    "            os.makedirs(logdir)\n",
    "        _callbacks.append(TensorBoard(log_dir=logdir))\n",
    "        print 'run \"tensorboard --logdir=%s\" to launch tensorboard'%logdir\n",
    "    \n",
    "    model.fit( X_train, Y_train, \n",
    "              validation_data=(X_val, Y_val),\n",
    "              nb_epoch=N_EPOCHS, batch_size=SZ_BATCH,\n",
    "              sample_weight = sample_weight,\n",
    "              callbacks=_callbacks )\n",
    "    \n",
    "    print 'evaluating model...'\n",
    "    evaluate_model(model)\n",
    "    \n",
    "    if save_model: \n",
    "        model_fpath = os.path.join( MODEL_PATH, '%s.h5'% str(model.name) )\n",
    "        model.save(model_fpath)\n",
    "    \n",
    "    if del_model:\n",
    "        del model # delete the model to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ''' ***NOTE***\n",
    "# To load models from file, we have to modify metrics.py at: \n",
    "# `/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras` \n",
    "# to add the `multlabel_XXX` function, otherwise throws exception ! \n",
    "\n",
    "# cf issue: https://github.com/fchollet/keras/issues/3911\n",
    "# '''\n",
    "# m = load_model(os.path.sep.join([MODEL_PATH, 'model_1conv1d.h5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag_quick_test = 0 # set to False/0 to run on whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_38 (Embedding)         (None, 1000, 100)     0           embedding_input_38[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_74 (Convolution1D) (None, 996, 128)      64128       embedding_38[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_74 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_74[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)             (None, 25472)         0           maxpooling1d_74[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)             (None, 25472)         0           flatten_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_50 (Dense)                 (None, 500)           12736500    dropout_50[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)             (None, 500)           0           dense_50[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_51 (Dense)                 (None, 49)            24549       dropout_51[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 12825177\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1105_model_1conv1d_2FC\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 503s - loss: 12.6680 - multlabel_prec: 0.2552 - multlabel_recall: 0.1338 - multlabel_F1: 0.1485 - multlabel_acc: 0.1021 - val_loss: 0.2645 - val_multlabel_prec: 0.2120 - val_multlabel_recall: 0.1405 - val_multlabel_F1: 0.1441 - val_multlabel_acc: 0.1112\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 531s - loss: 10.0049 - multlabel_prec: 0.3209 - multlabel_recall: 0.1874 - multlabel_F1: 0.2030 - multlabel_acc: 0.1473 - val_loss: 0.2683 - val_multlabel_prec: 0.3178 - val_multlabel_recall: 0.2224 - val_multlabel_F1: 0.2305 - val_multlabel_acc: 0.1680\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 515s - loss: 9.5214 - multlabel_prec: 0.3538 - multlabel_recall: 0.2145 - multlabel_F1: 0.2322 - multlabel_acc: 0.1693 - val_loss: 0.2590 - val_multlabel_prec: 0.3062 - val_multlabel_recall: 0.1679 - val_multlabel_F1: 0.1920 - val_multlabel_acc: 0.1436\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 485s - loss: 9.1640 - multlabel_prec: 0.3816 - multlabel_recall: 0.2322 - multlabel_F1: 0.2528 - multlabel_acc: 0.1854 - val_loss: 0.2612 - val_multlabel_prec: 0.3853 - val_multlabel_recall: 0.2438 - val_multlabel_F1: 0.2651 - val_multlabel_acc: 0.1932\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 492s - loss: 8.8353 - multlabel_prec: 0.4027 - multlabel_recall: 0.2486 - multlabel_F1: 0.2714 - multlabel_acc: 0.1994 - val_loss: 0.2483 - val_multlabel_prec: 0.4180 - val_multlabel_recall: 0.2588 - val_multlabel_F1: 0.2839 - val_multlabel_acc: 0.2091\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 503s - loss: 8.5561 - multlabel_prec: 0.4215 - multlabel_recall: 0.2665 - multlabel_F1: 0.2899 - multlabel_acc: 0.2134 - val_loss: 0.2653 - val_multlabel_prec: 0.4075 - val_multlabel_recall: 0.2517 - val_multlabel_F1: 0.2808 - val_multlabel_acc: 0.2056\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 549s - loss: 8.2558 - multlabel_prec: 0.4367 - multlabel_recall: 0.2839 - multlabel_F1: 0.3078 - multlabel_acc: 0.2275 - val_loss: 0.2554 - val_multlabel_prec: 0.3483 - val_multlabel_recall: 0.2308 - val_multlabel_F1: 0.2409 - val_multlabel_acc: 0.1789\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 499s - loss: 7.9941 - multlabel_prec: 0.4525 - multlabel_recall: 0.3051 - multlabel_F1: 0.3275 - multlabel_acc: 0.2424 - val_loss: 0.2617 - val_multlabel_prec: 0.3767 - val_multlabel_recall: 0.2852 - val_multlabel_F1: 0.2875 - val_multlabel_acc: 0.2077\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 234s   \n",
      "[0.2090398124137102, 0.5067191730406887, 0.36884432002903644, 0.38687012209537319, 0.28984704284629736]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 61s    \n",
      "[0.26174921527148093, 0.37670013241034722, 0.28520501304168794, 0.2874741631244474, 0.20774749957645866]\n"
     ]
    }
   ],
   "source": [
    "model_1conv1d_2FC = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQ_LEN, trainable=False # keep the embeddings fixed\n",
    "             ),# embedding layer\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') \n",
    "        ], \n",
    "        name='model_1conv1d_2FC')\n",
    "compile_fit_evaluate(model_1conv1d_2FC, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_39 (Embedding)         (None, 1000, 100)     0           embedding_input_39[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_75 (Convolution1D) (None, 996, 128)      64128       embedding_39[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_75 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_75[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_76 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_75[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_76 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_76[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)             (None, 4992)          0           maxpooling1d_76[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)             (None, 4992)          0           flatten_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_52 (Dense)                 (None, 49)            244657      dropout_52[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 390833\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1105_model_2conv1d_dropout\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 535s - loss: 11.2071 - multlabel_prec: 0.1939 - multlabel_recall: 0.0992 - multlabel_F1: 0.1091 - multlabel_acc: 0.0787 - val_loss: 0.3819 - val_multlabel_prec: 0.3293 - val_multlabel_recall: 0.2867 - val_multlabel_F1: 0.2752 - val_multlabel_acc: 0.1930\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 495s - loss: 9.8038 - multlabel_prec: 0.2856 - multlabel_recall: 0.1792 - multlabel_F1: 0.1880 - multlabel_acc: 0.1395 - val_loss: 0.2711 - val_multlabel_prec: 0.2035 - val_multlabel_recall: 0.1763 - val_multlabel_F1: 0.1666 - val_multlabel_acc: 0.1221\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 498s - loss: 9.5048 - multlabel_prec: 0.3001 - multlabel_recall: 0.1944 - multlabel_F1: 0.2049 - multlabel_acc: 0.1530 - val_loss: 0.2478 - val_multlabel_prec: 0.2064 - val_multlabel_recall: 0.1603 - val_multlabel_F1: 0.1596 - val_multlabel_acc: 0.1235\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 489s - loss: 9.3056 - multlabel_prec: 0.3302 - multlabel_recall: 0.2110 - multlabel_F1: 0.2257 - multlabel_acc: 0.1686 - val_loss: 0.2513 - val_multlabel_prec: 0.3275 - val_multlabel_recall: 0.2124 - val_multlabel_F1: 0.2238 - val_multlabel_acc: 0.1671\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 491s - loss: 9.1368 - multlabel_prec: 0.3562 - multlabel_recall: 0.2242 - multlabel_F1: 0.2422 - multlabel_acc: 0.1804 - val_loss: 0.2869 - val_multlabel_prec: 0.3184 - val_multlabel_recall: 0.2202 - val_multlabel_F1: 0.2347 - val_multlabel_acc: 0.1717\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 514s - loss: 9.0218 - multlabel_prec: 0.3788 - multlabel_recall: 0.2351 - multlabel_F1: 0.2555 - multlabel_acc: 0.1903 - val_loss: 0.2476 - val_multlabel_prec: 0.4008 - val_multlabel_recall: 0.2516 - val_multlabel_F1: 0.2788 - val_multlabel_acc: 0.2057\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 518s - loss: 8.8708 - multlabel_prec: 0.3921 - multlabel_recall: 0.2406 - multlabel_F1: 0.2631 - multlabel_acc: 0.1958 - val_loss: 0.2401 - val_multlabel_prec: 0.3096 - val_multlabel_recall: 0.2191 - val_multlabel_F1: 0.2202 - val_multlabel_acc: 0.1645\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 530s - loss: 8.7517 - multlabel_prec: 0.4103 - multlabel_recall: 0.2491 - multlabel_F1: 0.2733 - multlabel_acc: 0.2029 - val_loss: 0.2380 - val_multlabel_prec: 0.3476 - val_multlabel_recall: 0.2237 - val_multlabel_F1: 0.2426 - val_multlabel_acc: 0.1826\n",
      "Epoch 9/20\n",
      "36916/36916 [==============================] - 514s - loss: 8.6283 - multlabel_prec: 0.4147 - multlabel_recall: 0.2568 - multlabel_F1: 0.2804 - multlabel_acc: 0.2090 - val_loss: 0.2360 - val_multlabel_prec: 0.3021 - val_multlabel_recall: 0.1846 - val_multlabel_F1: 0.2008 - val_multlabel_acc: 0.1535\n",
      "Epoch 10/20\n",
      "36916/36916 [==============================] - 509s - loss: 8.5282 - multlabel_prec: 0.4222 - multlabel_recall: 0.2605 - multlabel_F1: 0.2854 - multlabel_acc: 0.2129 - val_loss: 0.2379 - val_multlabel_prec: 0.3469 - val_multlabel_recall: 0.2089 - val_multlabel_F1: 0.2298 - val_multlabel_acc: 0.1705\n",
      "Epoch 11/20\n",
      "36916/36916 [==============================] - 530s - loss: 8.3782 - multlabel_prec: 0.4300 - multlabel_recall: 0.2674 - multlabel_F1: 0.2931 - multlabel_acc: 0.2190 - val_loss: 0.2399 - val_multlabel_prec: 0.4535 - val_multlabel_recall: 0.2580 - val_multlabel_F1: 0.2897 - val_multlabel_acc: 0.2139\n",
      "Epoch 12/20\n",
      "36916/36916 [==============================] - 502s - loss: 8.2626 - multlabel_prec: 0.4393 - multlabel_recall: 0.2746 - multlabel_F1: 0.3004 - multlabel_acc: 0.2242 - val_loss: 0.2382 - val_multlabel_prec: 0.3884 - val_multlabel_recall: 0.2331 - val_multlabel_F1: 0.2594 - val_multlabel_acc: 0.1927\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 206s   \n",
      "[0.21640681930637939, 0.44313070878446237, 0.25989500716004088, 0.29329345545074847, 0.22069470034620592]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 53s    \n",
      "[0.23824262965189208, 0.38837868921068797, 0.23311696272363175, 0.2594194787061283, 0.19267090051633226]\n"
     ]
    }
   ],
   "source": [
    "# 2 conv1d layers\n",
    "model_2conv1d_dropout = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_2conv1d_dropout')\n",
    "compile_fit_evaluate(model_2conv1d_dropout, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_40 (Embedding)         (None, 1000, 100)     0           embedding_input_40[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_77 (Convolution1D) (None, 996, 128)      64128       embedding_40[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_77 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_77[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_78 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_77[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_78 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_78[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)             (None, 4992)          0           maxpooling1d_78[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 4992)          0           flatten_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_53 (Dense)                 (None, 500)           2496500     dropout_53[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)             (None, 500)           0           dense_53[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_54 (Dense)                 (None, 49)            24549       dropout_54[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 2667225\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1105_model_2conv1d_2FC\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 556s - loss: 11.8179 - multlabel_prec: 0.2250 - multlabel_recall: 0.1236 - multlabel_F1: 0.1319 - multlabel_acc: 0.0907 - val_loss: 0.2646 - val_multlabel_prec: 0.3908 - val_multlabel_recall: 0.1511 - val_multlabel_F1: 0.1913 - val_multlabel_acc: 0.1381\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 503s - loss: 10.0756 - multlabel_prec: 0.2947 - multlabel_recall: 0.1690 - multlabel_F1: 0.1823 - multlabel_acc: 0.1326 - val_loss: 0.2648 - val_multlabel_prec: 0.3850 - val_multlabel_recall: 0.2404 - val_multlabel_F1: 0.2661 - val_multlabel_acc: 0.1872\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 523s - loss: 9.7614 - multlabel_prec: 0.3062 - multlabel_recall: 0.1908 - multlabel_F1: 0.2028 - multlabel_acc: 0.1493 - val_loss: 0.2723 - val_multlabel_prec: 0.3302 - val_multlabel_recall: 0.2293 - val_multlabel_F1: 0.2393 - val_multlabel_acc: 0.1788\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 534s - loss: 9.5283 - multlabel_prec: 0.3174 - multlabel_recall: 0.2043 - multlabel_F1: 0.2175 - multlabel_acc: 0.1613 - val_loss: 0.2611 - val_multlabel_prec: 0.3031 - val_multlabel_recall: 0.1942 - val_multlabel_F1: 0.2070 - val_multlabel_acc: 0.1552\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 533s - loss: 9.3537 - multlabel_prec: 0.3425 - multlabel_recall: 0.2173 - multlabel_F1: 0.2339 - multlabel_acc: 0.1735 - val_loss: 0.2443 - val_multlabel_prec: 0.2265 - val_multlabel_recall: 0.1609 - val_multlabel_F1: 0.1698 - val_multlabel_acc: 0.1325\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 534s - loss: 9.2205 - multlabel_prec: 0.3594 - multlabel_recall: 0.2276 - multlabel_F1: 0.2464 - multlabel_acc: 0.1827 - val_loss: 0.2520 - val_multlabel_prec: 0.4256 - val_multlabel_recall: 0.2445 - val_multlabel_F1: 0.2692 - val_multlabel_acc: 0.1990\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 534s - loss: 9.0831 - multlabel_prec: 0.3869 - multlabel_recall: 0.2396 - multlabel_F1: 0.2618 - multlabel_acc: 0.1940 - val_loss: 0.2399 - val_multlabel_prec: 0.4837 - val_multlabel_recall: 0.2485 - val_multlabel_F1: 0.2921 - val_multlabel_acc: 0.2131\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 540s - loss: 8.9920 - multlabel_prec: 0.3919 - multlabel_recall: 0.2426 - multlabel_F1: 0.2656 - multlabel_acc: 0.1971 - val_loss: 0.2498 - val_multlabel_prec: 0.3335 - val_multlabel_recall: 0.2431 - val_multlabel_F1: 0.2466 - val_multlabel_acc: 0.1838\n",
      "Epoch 9/20\n",
      "36916/36916 [==============================] - 535s - loss: 8.8831 - multlabel_prec: 0.4028 - multlabel_recall: 0.2507 - multlabel_F1: 0.2745 - multlabel_acc: 0.2036 - val_loss: 0.2445 - val_multlabel_prec: 0.3658 - val_multlabel_recall: 0.2314 - val_multlabel_F1: 0.2533 - val_multlabel_acc: 0.1893\n",
      "Epoch 10/20\n",
      "36916/36916 [==============================] - 535s - loss: 8.8001 - multlabel_prec: 0.4057 - multlabel_recall: 0.2528 - multlabel_F1: 0.2771 - multlabel_acc: 0.2053 - val_loss: 0.2714 - val_multlabel_prec: 0.3619 - val_multlabel_recall: 0.2818 - val_multlabel_F1: 0.2884 - val_multlabel_acc: 0.2104\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 223s   \n",
      "[0.25945908789296801, 0.39022617951569932, 0.29870761998594358, 0.30968908647349574, 0.22714227793831288]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 55s    \n",
      "[0.27135880497646608, 0.36190128041600234, 0.28180368399165384, 0.2884152426545547, 0.21040231019810693]\n"
     ]
    }
   ],
   "source": [
    "# 2 conv1d layers\n",
    "model_2conv1d_2FC = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_2conv1d_2FC')\n",
    "compile_fit_evaluate(model_2conv1d_2FC, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_41 (Embedding)         (None, 1000, 100)     0           embedding_input_41[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_79 (Convolution1D) (None, 996, 128)      64128       embedding_41[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_79 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_79[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_80 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_79[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_80 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_80[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_81 (Convolution1D) (None, 35, 128)       82048       maxpooling1d_80[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_81 (MaxPooling1D)   (None, 7, 128)        0           convolution1d_81[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)             (None, 896)           0           maxpooling1d_81[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)             (None, 896)           0           flatten_41[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 49)            43953       dropout_55[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 272177\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1105_model_3conv1d_dropout\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 546s - loss: 11.3981 - multlabel_prec: 0.1894 - multlabel_recall: 0.0823 - multlabel_F1: 0.0947 - multlabel_acc: 0.0651 - val_loss: 0.3480 - val_multlabel_prec: 0.0780 - val_multlabel_recall: 0.1614 - val_multlabel_F1: 0.1025 - val_multlabel_acc: 0.0777\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 543s - loss: 10.0427 - multlabel_prec: 0.2779 - multlabel_recall: 0.1491 - multlabel_F1: 0.1617 - multlabel_acc: 0.1189 - val_loss: 0.2623 - val_multlabel_prec: 0.4519 - val_multlabel_recall: 0.1637 - val_multlabel_F1: 0.2096 - val_multlabel_acc: 0.1528\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 544s - loss: 9.7419 - multlabel_prec: 0.2909 - multlabel_recall: 0.1703 - multlabel_F1: 0.1819 - multlabel_acc: 0.1354 - val_loss: 0.2915 - val_multlabel_prec: 0.1955 - val_multlabel_recall: 0.1976 - val_multlabel_F1: 0.1627 - val_multlabel_acc: 0.1223\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 545s - loss: 9.5483 - multlabel_prec: 0.2943 - multlabel_recall: 0.1893 - multlabel_F1: 0.1997 - multlabel_acc: 0.1493 - val_loss: 0.2540 - val_multlabel_prec: 0.1786 - val_multlabel_recall: 0.1218 - val_multlabel_F1: 0.1319 - val_multlabel_acc: 0.1044\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 548s - loss: 9.4234 - multlabel_prec: 0.3053 - multlabel_recall: 0.1998 - multlabel_F1: 0.2118 - multlabel_acc: 0.1588 - val_loss: 0.2795 - val_multlabel_prec: 0.3203 - val_multlabel_recall: 0.2662 - val_multlabel_F1: 0.2566 - val_multlabel_acc: 0.1881\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 542s - loss: 9.3007 - multlabel_prec: 0.3276 - multlabel_recall: 0.2127 - multlabel_F1: 0.2269 - multlabel_acc: 0.1695 - val_loss: 0.2679 - val_multlabel_prec: 0.4103 - val_multlabel_recall: 0.2377 - val_multlabel_F1: 0.2748 - val_multlabel_acc: 0.1956\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 544s - loss: 9.1958 - multlabel_prec: 0.3535 - multlabel_recall: 0.2228 - multlabel_F1: 0.2409 - multlabel_acc: 0.1796 - val_loss: 0.2667 - val_multlabel_prec: 0.2926 - val_multlabel_recall: 0.1993 - val_multlabel_F1: 0.2098 - val_multlabel_acc: 0.1550\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 225s   \n",
      "[0.26335181512874234, 0.30238101150493785, 0.20531950842095475, 0.21733085748491598, 0.161562520635646]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 56s    \n",
      "[0.26667326125593327, 0.29256725936937544, 0.19927778212146313, 0.20979261739642277, 0.15503314441165425]\n"
     ]
    }
   ],
   "source": [
    "model_3conv1d_dropout =Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_3conv1d_dropout')\n",
    "\n",
    "compile_fit_evaluate(model_3conv1d_dropout, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_42 (Embedding)         (None, 1000, 100)     0           embedding_input_42[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_82 (Convolution1D) (None, 996, 128)      64128       embedding_42[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_82 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_82[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_83 (Convolution1D) (None, 195, 64)       41024       maxpooling1d_82[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_83 (MaxPooling1D)   (None, 65, 64)        0           convolution1d_83[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_84 (Convolution1D) (None, 61, 32)        10272       maxpooling1d_83[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_84 (MaxPooling1D)   (None, 30, 32)        0           convolution1d_84[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)             (None, 960)           0           maxpooling1d_84[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)             (None, 960)           0           flatten_42[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 500)           480500      dropout_56[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)             (None, 500)           0           dense_56[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 49)            24549       dropout_57[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 620473\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1105_model_3conv1d_2FC\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 495s - loss: 11.8343 - multlabel_prec: 0.2007 - multlabel_recall: 0.0883 - multlabel_F1: 0.1022 - multlabel_acc: 0.0706 - val_loss: 0.3342 - val_multlabel_prec: 0.4236 - val_multlabel_recall: 0.1491 - val_multlabel_F1: 0.1908 - val_multlabel_acc: 0.1389\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 493s - loss: 10.5678 - multlabel_prec: 0.2434 - multlabel_recall: 0.1212 - multlabel_F1: 0.1360 - multlabel_acc: 0.0994 - val_loss: 0.2688 - val_multlabel_prec: 0.4674 - val_multlabel_recall: 0.1948 - val_multlabel_F1: 0.2348 - val_multlabel_acc: 0.1743\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 499s - loss: 9.9236 - multlabel_prec: 0.2931 - multlabel_recall: 0.1632 - multlabel_F1: 0.1776 - multlabel_acc: 0.1303 - val_loss: 0.2598 - val_multlabel_prec: 0.2189 - val_multlabel_recall: 0.1946 - val_multlabel_F1: 0.1835 - val_multlabel_acc: 0.1367\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 491s - loss: 9.6815 - multlabel_prec: 0.2938 - multlabel_recall: 0.1840 - multlabel_F1: 0.1951 - multlabel_acc: 0.1450 - val_loss: 0.2768 - val_multlabel_prec: 0.2989 - val_multlabel_recall: 0.2109 - val_multlabel_F1: 0.2210 - val_multlabel_acc: 0.1658\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 491s - loss: 9.5346 - multlabel_prec: 0.2979 - multlabel_recall: 0.1908 - multlabel_F1: 0.2033 - multlabel_acc: 0.1521 - val_loss: 0.2848 - val_multlabel_prec: 0.3212 - val_multlabel_recall: 0.2050 - val_multlabel_F1: 0.2237 - val_multlabel_acc: 0.1623\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 492s - loss: 9.4292 - multlabel_prec: 0.3000 - multlabel_recall: 0.1984 - multlabel_F1: 0.2108 - multlabel_acc: 0.1583 - val_loss: 0.2436 - val_multlabel_prec: 0.3520 - val_multlabel_recall: 0.2361 - val_multlabel_F1: 0.2392 - val_multlabel_acc: 0.1781\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 492s - loss: 9.3537 - multlabel_prec: 0.3191 - multlabel_recall: 0.2084 - multlabel_F1: 0.2229 - multlabel_acc: 0.1670 - val_loss: 0.2486 - val_multlabel_prec: 0.4079 - val_multlabel_recall: 0.2812 - val_multlabel_F1: 0.2944 - val_multlabel_acc: 0.2152\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 492s - loss: 9.2679 - multlabel_prec: 0.3437 - multlabel_recall: 0.2177 - multlabel_F1: 0.2353 - multlabel_acc: 0.1753 - val_loss: 0.2427 - val_multlabel_prec: 0.3671 - val_multlabel_recall: 0.2165 - val_multlabel_F1: 0.2388 - val_multlabel_acc: 0.1816\n",
      "Epoch 9/20\n",
      "36916/36916 [==============================] - 493s - loss: 9.1960 - multlabel_prec: 0.3605 - multlabel_recall: 0.2264 - multlabel_F1: 0.2460 - multlabel_acc: 0.1831 - val_loss: 0.2803 - val_multlabel_prec: 0.3614 - val_multlabel_recall: 0.2754 - val_multlabel_F1: 0.2876 - val_multlabel_acc: 0.2069\n",
      "Epoch 10/20\n",
      "36916/36916 [==============================] - 492s - loss: 9.1243 - multlabel_prec: 0.3785 - multlabel_recall: 0.2346 - multlabel_F1: 0.2565 - multlabel_acc: 0.1902 - val_loss: 0.2391 - val_multlabel_prec: 0.3515 - val_multlabel_recall: 0.2224 - val_multlabel_F1: 0.2422 - val_multlabel_acc: 0.1827\n",
      "Epoch 11/20\n",
      "36916/36916 [==============================] - 500s - loss: 9.0797 - multlabel_prec: 0.3856 - multlabel_recall: 0.2379 - multlabel_F1: 0.2610 - multlabel_acc: 0.1938 - val_loss: 0.2541 - val_multlabel_prec: 0.4166 - val_multlabel_recall: 0.3091 - val_multlabel_F1: 0.3128 - val_multlabel_acc: 0.2286\n",
      "Epoch 12/20\n",
      "36916/36916 [==============================] - 495s - loss: 9.0237 - multlabel_prec: 0.3892 - multlabel_recall: 0.2406 - multlabel_F1: 0.2642 - multlabel_acc: 0.1959 - val_loss: 0.2423 - val_multlabel_prec: 0.3740 - val_multlabel_recall: 0.2566 - val_multlabel_F1: 0.2700 - val_multlabel_acc: 0.2003\n",
      "Epoch 13/20\n",
      "36916/36916 [==============================] - 494s - loss: 8.9756 - multlabel_prec: 0.3950 - multlabel_recall: 0.2440 - multlabel_F1: 0.2682 - multlabel_acc: 0.1987 - val_loss: 0.2506 - val_multlabel_prec: 0.3567 - val_multlabel_recall: 0.2179 - val_multlabel_F1: 0.2392 - val_multlabel_acc: 0.1796\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 206s   \n",
      "[0.24513103660756735, 0.3721293304468728, 0.2245424781573892, 0.24803919831700749, 0.18585177648944526]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 51s    \n",
      "[0.25057602469441126, 0.35668171087948158, 0.21794183847091481, 0.23922911585539802, 0.17960315979415745]\n"
     ]
    }
   ],
   "source": [
    "model_3conv1d_2FC =Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(64, 5, activation='relu'),\n",
    "            MaxPooling1D(3),\n",
    "            Conv1D(32, 5, activation='relu'),\n",
    "            MaxPooling1D(2),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_3conv1d_2FC')\n",
    "\n",
    "compile_fit_evaluate(model_3conv1d_2FC, flag_quick_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

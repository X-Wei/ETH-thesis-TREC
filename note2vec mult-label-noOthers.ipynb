{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In this notebook: run the model with the last label (\"others\") removed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproductive\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "NOTE_DATA_DIR = '/local/XW/DATA/MIMIC/noteevents_by_sid/'\n",
    "ICD_FPATH = 'data/subject_diag_icds.txt'\n",
    "PK_FPATH = 'data/diag_processed_data.pk' # './processed_data_small.pk'\n",
    "MODEL_PATH = './models/'\n",
    "LOG_PATH = './logs/'\n",
    "# constants\n",
    "N_LABELS = 49 # *** <-- remove last \"others\" label ***\n",
    "K_ICDS_TOKEEP = N_LABELS - 1 # predict only on top K frequent icd codes\n",
    "N_SUBJECTS = 41886\n",
    "# word2vec configurations\n",
    "GLOVE_DIR = '/local/XW/DATA/glove.6B/'\n",
    "MAX_SEQ_LEN = 1000 # max length of input sequence (pad/truncate to fix length)\n",
    "MAX_NB_WORDS = 20000 # top 20k most freq words\n",
    "EMBEDDING_DIM = 100\n",
    "# learning configurations\n",
    "VALIDATION_SPLIT = 0.2\n",
    "N_EPOCHS = 20\n",
    "SZ_BATCH = 512 # large batch size ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pickled data\n",
    "pk_data = pk.load(open(PK_FPATH, 'rb'))\n",
    "embedding_matrix = pk_data['embedding_matrix']\n",
    "X_train, Y_train = pk_data['X_train'], pk_data['Y_train']\n",
    "X_val, Y_val = pk_data['X_val'], pk_data['Y_val']\n",
    "nb_words = MAX_NB_WORDS # forgot to pickle this number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "11730\n",
      "(36916, 1000) (36916, 50)\n"
     ]
    }
   ],
   "source": [
    "# found one row that is ALL 0) (strange?)\n",
    "print np.min( np.sum(Y_train, axis=1) ), np.min( np.sum(Y_val, axis=1) )\n",
    "print np.argmin( np.sum(Y_train, axis=1) )\n",
    "Y_train[11730]\n",
    "Y_train = np.delete(Y_train, 11730, axis=0)\n",
    "X_train = np.delete(X_train, 11730, axis=0)\n",
    "print X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36916, 49) (9229, 49)\n"
     ]
    }
   ],
   "source": [
    "# *** remove last column of Y_train and Y_val ***\n",
    "Y_train = Y_train[:,:-1]\n",
    "Y_val = Y_val[:, :-1]\n",
    "print Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_n_poslabels = Y_train.sum(axis=1) # this can be used as sample weights: more sample the ones with more 1s..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22.627417  ,   5.19615242,   5.19615242, ...,   5.19615242,\n",
       "         5.19615242,   1.        ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_n_poslabels**(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71321589,  1.16346713,  1.23167878,  1.27307447,  1.62127108,\n",
       "        1.66944908,  1.70299728,  1.90186383,  2.18435998,  2.19394471,\n",
       "        2.27790433,  2.36966825,  2.38322212,  2.53036437,  2.87108814,\n",
       "        2.93341156,  3.03398058,  3.31674959,  3.46981263,  3.55871886,\n",
       "        3.53481796,  3.67917586,  3.74531835,  3.93855849,  4.23370025,\n",
       "        4.34027778,  4.25894378,  4.37445319,  4.49438202,  4.54959054,\n",
       "        4.49236298,  4.51671183,  4.59770115,  4.69924812,  4.93096647,\n",
       "        4.95049505,  5.27148129,  5.39956803,  5.39374326,  5.35905681,\n",
       "        5.41418517,  5.50964187,  5.5959709 ,  5.83771162,  6.09013398,\n",
       "        6.09013398,  6.10500611,  6.28535512,  6.25390869])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_freq = 10000*Y_train.sum(axis=0)**(-1)\n",
    "inv_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_weight = (inv_freq * Y_train).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** this metrics is the continus relaxation of what we really want, so the acc output during training is not precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multlabel_prec(y_true, y_pred):\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return K.mean(tp/(sum_pred+1e-10)) # to avoid NaN precision\n",
    "    \n",
    "def multlabel_recall(y_true, y_pred):\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return K.mean(tp/(sum_true+1e-10)) \n",
    "\n",
    "def multlabel_F1(y_true, y_pred):\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    tp = K.sum(y_true * y_pred, axis =-1)\n",
    "    sum_true = K.sum(y_true, axis=-1)\n",
    "    sum_pred = K.sum(y_pred, axis=-1)\n",
    "    return 2*K.mean(tp/(sum_true+sum_pred+1e-10))\n",
    "\n",
    "def multlabel_acc(y_true, y_pred):\n",
    "    y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "    intersect = y_true * y_pred\n",
    "    intersect = K.sum(intersect, axis=-1)\n",
    "    union = K.clip(y_true+y_pred, 0, 1)\n",
    "    union = K.sum(union, axis=-1)\n",
    "    return K.mean(intersect/(union+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    print 'evaluation on training set:'\n",
    "    print model.evaluate(X_train, Y_train, batch_size=128)\n",
    "    print 'evaluation on validation set:'\n",
    "    print model.evaluate(X_val, Y_val, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wraps up operations on models\n",
    "def compile_fit_evaluate(model, quick_test=False, print_summary=True,\n",
    "                         save_log=True, save_model=True, del_model=False):\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=[multlabel_prec, multlabel_recall, multlabel_F1, multlabel_acc])\n",
    "    if print_summary:\n",
    "        print model.summary()\n",
    "        \n",
    "    if quick_test: # use tiny data for quick test\n",
    "        print '(quick test mode)'\n",
    "        model.fit(X_train[:100], Y_train[:100], nb_epoch=1)\n",
    "        return  \n",
    "    \n",
    "    _callbacks = [EarlyStopping(monitor='val_loss', patience=2)] #[RelaxAccHistory()]\n",
    "    if save_log:\n",
    "        logdir = os.path.join( LOG_PATH, time.strftime('%m%d')+'_'+str(model.name) )\n",
    "        if not os.path.exists(logdir):\n",
    "            os.makedirs(logdir)\n",
    "        _callbacks.append(TensorBoard(log_dir=logdir))\n",
    "        print 'run \"tensorboard --logdir=%s\" to launch tensorboard'%logdir\n",
    "    \n",
    "    model.fit( X_train, Y_train, \n",
    "              validation_data=(X_val, Y_val),\n",
    "              nb_epoch=N_EPOCHS, batch_size=SZ_BATCH,\n",
    "              sample_weight = sample_weight,\n",
    "              callbacks=_callbacks )\n",
    "    \n",
    "    print 'evaluating model...'\n",
    "    evaluate_model(model)\n",
    "    \n",
    "    if save_model: \n",
    "        model_fpath = os.path.join( MODEL_PATH, '%s.h5'% str(model.name) )\n",
    "        model.save(model_fpath)\n",
    "    \n",
    "    if del_model:\n",
    "        del model # delete the model to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ''' ***NOTE***\n",
    "# To load models from file, we have to modify metrics.py at: \n",
    "# `/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras` \n",
    "# to add the `multlabel_XXX` function, otherwise throws exception ! \n",
    "\n",
    "# cf issue: https://github.com/fchollet/keras/issues/3911\n",
    "# '''\n",
    "# m = load_model(os.path.sep.join([MODEL_PATH, 'model_1conv1d.h5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag_quick_test = 0 # set to False/0 to run on whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_24 (Embedding)         (None, 1000, 100)     0           embedding_input_24[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_43 (Convolution1D) (None, 996, 128)      64128       embedding_24[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_43 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)             (None, 25472)         0           maxpooling1d_43[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 25472)         0           flatten_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 49)            1248177     dropout_29[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1312305\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1103_model_1conv1d_dropout\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 484s - loss: 7.1783 - multlabel_prec: 0.1982 - multlabel_recall: 0.1119 - multlabel_F1: 0.1213 - multlabel_acc: 0.0862 - val_loss: 0.2828 - val_multlabel_prec: 0.2551 - val_multlabel_recall: 0.1845 - val_multlabel_F1: 0.1729 - val_multlabel_acc: 0.1294\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 472s - loss: 4.9690 - multlabel_prec: 0.3286 - multlabel_recall: 0.2031 - multlabel_F1: 0.2178 - multlabel_acc: 0.1617 - val_loss: 0.2634 - val_multlabel_prec: 0.3713 - val_multlabel_recall: 0.2211 - val_multlabel_F1: 0.2448 - val_multlabel_acc: 0.1772\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 468s - loss: 4.5472 - multlabel_prec: 0.4055 - multlabel_recall: 0.2384 - multlabel_F1: 0.2628 - multlabel_acc: 0.1954 - val_loss: 0.2506 - val_multlabel_prec: 0.3835 - val_multlabel_recall: 0.2186 - val_multlabel_F1: 0.2439 - val_multlabel_acc: 0.1806\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 469s - loss: 4.0832 - multlabel_prec: 0.4489 - multlabel_recall: 0.2772 - multlabel_F1: 0.3035 - multlabel_acc: 0.2281 - val_loss: 0.2537 - val_multlabel_prec: 0.3884 - val_multlabel_recall: 0.2232 - val_multlabel_F1: 0.2503 - val_multlabel_acc: 0.1844\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 472s - loss: 3.6481 - multlabel_prec: 0.4921 - multlabel_recall: 0.3291 - multlabel_F1: 0.3547 - multlabel_acc: 0.2717 - val_loss: 0.2746 - val_multlabel_prec: 0.3916 - val_multlabel_recall: 0.2848 - val_multlabel_F1: 0.2986 - val_multlabel_acc: 0.2110\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 467s - loss: 3.2509 - multlabel_prec: 0.5257 - multlabel_recall: 0.3756 - multlabel_F1: 0.3997 - multlabel_acc: 0.3122 - val_loss: 0.2734 - val_multlabel_prec: 0.3772 - val_multlabel_recall: 0.2420 - val_multlabel_F1: 0.2568 - val_multlabel_acc: 0.1875\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 179s   \n",
      "[0.16812808449186448, 0.57320003172909273, 0.36184999229835912, 0.40277260337830212, 0.31812861452628116]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 44s    \n",
      "[0.27340978918451181, 0.37715666948851273, 0.24203383858315747, 0.25678576259710428, 0.18750032772221173]\n"
     ]
    }
   ],
   "source": [
    "model_1conv1d_dropout = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQ_LEN, trainable=False # keep the embeddings fixed\n",
    "             ),# embedding layer\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.2),\n",
    "            Dense(N_LABELS, activation='sigmoid') \n",
    "        ], \n",
    "        name='model_1conv1d_dropout')\n",
    "compile_fit_evaluate(model_1conv1d_dropout, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_25 (Embedding)         (None, 1000, 100)     0           embedding_input_25[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_44 (Convolution1D) (None, 996, 128)      64128       embedding_25[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_44 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_45 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_44[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_45 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)             (None, 4992)          0           maxpooling1d_45[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 4992)          0           flatten_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 49)            244657      dropout_30[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 390833\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1103_model_2conv1d_dropout\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 553s - loss: 5.7511 - multlabel_prec: 0.2228 - multlabel_recall: 0.1123 - multlabel_F1: 0.1234 - multlabel_acc: 0.0886 - val_loss: 0.2805 - val_multlabel_prec: 0.3467 - val_multlabel_recall: 0.2063 - val_multlabel_F1: 0.2301 - val_multlabel_acc: 0.1645\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 555s - loss: 5.0741 - multlabel_prec: 0.3134 - multlabel_recall: 0.1826 - multlabel_F1: 0.1969 - multlabel_acc: 0.1459 - val_loss: 0.2703 - val_multlabel_prec: 0.4026 - val_multlabel_recall: 0.2201 - val_multlabel_F1: 0.2469 - val_multlabel_acc: 0.1839\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 553s - loss: 4.9041 - multlabel_prec: 0.3282 - multlabel_recall: 0.2014 - multlabel_F1: 0.2181 - multlabel_acc: 0.1628 - val_loss: 0.2608 - val_multlabel_prec: 0.2859 - val_multlabel_recall: 0.2299 - val_multlabel_F1: 0.2315 - val_multlabel_acc: 0.1718\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 553s - loss: 4.8089 - multlabel_prec: 0.3516 - multlabel_recall: 0.2184 - multlabel_F1: 0.2371 - multlabel_acc: 0.1770 - val_loss: 0.2518 - val_multlabel_prec: 0.3128 - val_multlabel_recall: 0.2357 - val_multlabel_F1: 0.2396 - val_multlabel_acc: 0.1789\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 555s - loss: 4.7272 - multlabel_prec: 0.3793 - multlabel_recall: 0.2306 - multlabel_F1: 0.2533 - multlabel_acc: 0.1887 - val_loss: 0.2406 - val_multlabel_prec: 0.3172 - val_multlabel_recall: 0.2045 - val_multlabel_F1: 0.2142 - val_multlabel_acc: 0.1608\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 551s - loss: 4.6603 - multlabel_prec: 0.3980 - multlabel_recall: 0.2401 - multlabel_F1: 0.2649 - multlabel_acc: 0.1977 - val_loss: 0.2409 - val_multlabel_prec: 0.3382 - val_multlabel_recall: 0.2051 - val_multlabel_F1: 0.2303 - val_multlabel_acc: 0.1739\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 558s - loss: 4.6017 - multlabel_prec: 0.4070 - multlabel_recall: 0.2447 - multlabel_F1: 0.2708 - multlabel_acc: 0.2020 - val_loss: 0.2493 - val_multlabel_prec: 0.3748 - val_multlabel_recall: 0.2525 - val_multlabel_F1: 0.2675 - val_multlabel_acc: 0.1988\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 556s - loss: 4.5307 - multlabel_prec: 0.4188 - multlabel_recall: 0.2538 - multlabel_F1: 0.2804 - multlabel_acc: 0.2093 - val_loss: 0.2540 - val_multlabel_prec: 0.4350 - val_multlabel_recall: 0.2600 - val_multlabel_F1: 0.2940 - val_multlabel_acc: 0.2167\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 209s   \n",
      "[0.24294213086176131, 0.46819657545872995, 0.27799499773400516, 0.31654428838973109, 0.23471647217790642]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 52s    \n",
      "[0.25404116949870792, 0.43497481297627727, 0.26003405533311996, 0.2940242096906055, 0.21674659957844666]\n"
     ]
    }
   ],
   "source": [
    "# 2 conv1d layers\n",
    "model_2conv1d_dropout = Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_2conv1d_dropout')\n",
    "compile_fit_evaluate(model_2conv1d_dropout, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_26 (Embedding)         (None, 1000, 100)     0           embedding_input_26[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_46 (Convolution1D) (None, 996, 128)      64128       embedding_26[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_46 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_47 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_46[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_47 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_47[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_48 (Convolution1D) (None, 35, 128)       82048       maxpooling1d_47[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_48 (MaxPooling1D)   (None, 7, 128)        0           convolution1d_48[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)             (None, 896)           0           maxpooling1d_48[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 896)           0           flatten_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 49)            43953       dropout_31[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 272177\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1103_model_3conv1d_dropout\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 577s - loss: 5.9344 - multlabel_prec: 0.2096 - multlabel_recall: 0.0945 - multlabel_F1: 0.1085 - multlabel_acc: 0.0750 - val_loss: 0.2721 - val_multlabel_prec: 0.0805 - val_multlabel_recall: 0.0704 - val_multlabel_F1: 0.0709 - val_multlabel_acc: 0.0579\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 572s - loss: 5.1966 - multlabel_prec: 0.3002 - multlabel_recall: 0.1576 - multlabel_F1: 0.1734 - multlabel_acc: 0.1275 - val_loss: 0.2884 - val_multlabel_prec: 0.1243 - val_multlabel_recall: 0.1349 - val_multlabel_F1: 0.1178 - val_multlabel_acc: 0.0953\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 575s - loss: 5.0705 - multlabel_prec: 0.3088 - multlabel_recall: 0.1706 - multlabel_F1: 0.1856 - multlabel_acc: 0.1380 - val_loss: 0.2530 - val_multlabel_prec: 0.4138 - val_multlabel_recall: 0.2097 - val_multlabel_F1: 0.2420 - val_multlabel_acc: 0.1797\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 575s - loss: 4.9562 - multlabel_prec: 0.3191 - multlabel_recall: 0.1943 - multlabel_F1: 0.2096 - multlabel_acc: 0.1570 - val_loss: 0.2933 - val_multlabel_prec: 0.3504 - val_multlabel_recall: 0.2019 - val_multlabel_F1: 0.2290 - val_multlabel_acc: 0.1717\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 571s - loss: 4.8801 - multlabel_prec: 0.3272 - multlabel_recall: 0.2070 - multlabel_F1: 0.2229 - multlabel_acc: 0.1670 - val_loss: 0.2623 - val_multlabel_prec: 0.4138 - val_multlabel_recall: 0.2677 - val_multlabel_F1: 0.2934 - val_multlabel_acc: 0.2145\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 570s - loss: 4.8241 - multlabel_prec: 0.3432 - multlabel_recall: 0.2180 - multlabel_F1: 0.2357 - multlabel_acc: 0.1764 - val_loss: 0.2621 - val_multlabel_prec: 0.4643 - val_multlabel_recall: 0.2699 - val_multlabel_F1: 0.3088 - val_multlabel_acc: 0.2251\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 215s   \n",
      "[0.25876228231845871, 0.4726123552705242, 0.27456424350353087, 0.31441836934692102, 0.22938291588510565]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 53s    \n",
      "[0.2621289272907173, 0.46427708113422139, 0.26990088042865168, 0.30876608642264403, 0.22505089593793914]\n"
     ]
    }
   ],
   "source": [
    "model_3conv1d_dropout =Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_3conv1d_dropout')\n",
    "\n",
    "compile_fit_evaluate(model_3conv1d_dropout, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_27 (Embedding)         (None, 1000, 100)     0           embedding_input_27[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_49 (Convolution1D) (None, 996, 128)      64128       embedding_27[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_49 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_49[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_50 (Convolution1D) (None, 195, 64)       41024       maxpooling1d_49[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_50 (MaxPooling1D)   (None, 65, 64)        0           convolution1d_50[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_51 (Convolution1D) (None, 61, 32)        10272       maxpooling1d_50[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_51 (MaxPooling1D)   (None, 30, 32)        0           convolution1d_51[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)             (None, 960)           0           maxpooling1d_51[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 960)           0           flatten_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 500)           480500      dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 500)           0           dense_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 49)            24549       dropout_33[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 620473\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1103_model_3conv1d_2FC\" to launch tensorboard\n",
      "Train on 36916 samples, validate on 9229 samples\n",
      "Epoch 1/20\n",
      "36916/36916 [==============================] - 521s - loss: 6.0408 - multlabel_prec: 0.1986 - multlabel_recall: 0.0897 - multlabel_F1: 0.1028 - multlabel_acc: 0.0712 - val_loss: 0.2813 - val_multlabel_prec: 0.0585 - val_multlabel_recall: 0.0610 - val_multlabel_F1: 0.0581 - val_multlabel_acc: 0.0502\n",
      "Epoch 2/20\n",
      "36916/36916 [==============================] - 519s - loss: 5.4283 - multlabel_prec: 0.2576 - multlabel_recall: 0.1280 - multlabel_F1: 0.1440 - multlabel_acc: 0.1049 - val_loss: 0.2589 - val_multlabel_prec: 0.3631 - val_multlabel_recall: 0.1581 - val_multlabel_F1: 0.1877 - val_multlabel_acc: 0.1401\n",
      "Epoch 3/20\n",
      "36916/36916 [==============================] - 520s - loss: 5.1274 - multlabel_prec: 0.3065 - multlabel_recall: 0.1683 - multlabel_F1: 0.1847 - multlabel_acc: 0.1361 - val_loss: 0.2804 - val_multlabel_prec: 0.2540 - val_multlabel_recall: 0.2141 - val_multlabel_F1: 0.2046 - val_multlabel_acc: 0.1519\n",
      "Epoch 4/20\n",
      "36916/36916 [==============================] - 517s - loss: 5.0177 - multlabel_prec: 0.3035 - multlabel_recall: 0.1882 - multlabel_F1: 0.2017 - multlabel_acc: 0.1496 - val_loss: 0.2567 - val_multlabel_prec: 0.4564 - val_multlabel_recall: 0.2503 - val_multlabel_F1: 0.2841 - val_multlabel_acc: 0.2106\n",
      "Epoch 5/20\n",
      "36916/36916 [==============================] - 517s - loss: 4.9389 - multlabel_prec: 0.3099 - multlabel_recall: 0.1945 - multlabel_F1: 0.2093 - multlabel_acc: 0.1561 - val_loss: 0.2483 - val_multlabel_prec: 0.2672 - val_multlabel_recall: 0.1977 - val_multlabel_F1: 0.1956 - val_multlabel_acc: 0.1460\n",
      "Epoch 6/20\n",
      "36916/36916 [==============================] - 519s - loss: 4.8867 - multlabel_prec: 0.3177 - multlabel_recall: 0.2034 - multlabel_F1: 0.2196 - multlabel_acc: 0.1645 - val_loss: 0.2459 - val_multlabel_prec: 0.2395 - val_multlabel_recall: 0.1645 - val_multlabel_F1: 0.1710 - val_multlabel_acc: 0.1311\n",
      "Epoch 7/20\n",
      "36916/36916 [==============================] - 521s - loss: 4.8461 - multlabel_prec: 0.3332 - multlabel_recall: 0.2117 - multlabel_F1: 0.2295 - multlabel_acc: 0.1714 - val_loss: 0.2451 - val_multlabel_prec: 0.2657 - val_multlabel_recall: 0.1733 - val_multlabel_F1: 0.1906 - val_multlabel_acc: 0.1456\n",
      "Epoch 8/20\n",
      "36916/36916 [==============================] - 520s - loss: 4.8071 - multlabel_prec: 0.3512 - multlabel_recall: 0.2189 - multlabel_F1: 0.2399 - multlabel_acc: 0.1786 - val_loss: 0.2529 - val_multlabel_prec: 0.3526 - val_multlabel_recall: 0.2389 - val_multlabel_F1: 0.2459 - val_multlabel_acc: 0.1821\n",
      "Epoch 9/20\n",
      "36916/36916 [==============================] - 519s - loss: 4.7644 - multlabel_prec: 0.3610 - multlabel_recall: 0.2243 - multlabel_F1: 0.2464 - multlabel_acc: 0.1834 - val_loss: 0.2441 - val_multlabel_prec: 0.4372 - val_multlabel_recall: 0.2604 - val_multlabel_F1: 0.2848 - val_multlabel_acc: 0.2099\n",
      "Epoch 10/20\n",
      "36916/36916 [==============================] - 519s - loss: 4.7388 - multlabel_prec: 0.3762 - multlabel_recall: 0.2297 - multlabel_F1: 0.2537 - multlabel_acc: 0.1888 - val_loss: 0.2342 - val_multlabel_prec: 0.3540 - val_multlabel_recall: 0.2273 - val_multlabel_F1: 0.2424 - val_multlabel_acc: 0.1808\n",
      "Epoch 11/20\n",
      "36916/36916 [==============================] - 520s - loss: 4.7082 - multlabel_prec: 0.3895 - multlabel_recall: 0.2361 - multlabel_F1: 0.2619 - multlabel_acc: 0.1946 - val_loss: 0.2418 - val_multlabel_prec: 0.4032 - val_multlabel_recall: 0.2550 - val_multlabel_F1: 0.2711 - val_multlabel_acc: 0.1995\n",
      "Epoch 12/20\n",
      "36916/36916 [==============================] - 519s - loss: 4.6837 - multlabel_prec: 0.3982 - multlabel_recall: 0.2411 - multlabel_F1: 0.2676 - multlabel_acc: 0.1987 - val_loss: 0.2489 - val_multlabel_prec: 0.3130 - val_multlabel_recall: 0.1970 - val_multlabel_F1: 0.2135 - val_multlabel_acc: 0.1615\n",
      "Epoch 13/20\n",
      "36916/36916 [==============================] - 518s - loss: 4.6628 - multlabel_prec: 0.4009 - multlabel_recall: 0.2421 - multlabel_F1: 0.2699 - multlabel_acc: 0.2005 - val_loss: 0.2422 - val_multlabel_prec: 0.4677 - val_multlabel_recall: 0.2900 - val_multlabel_F1: 0.3206 - val_multlabel_acc: 0.2360\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "36916/36916 [==============================] - 196s   \n",
      "[0.23637512948831044, 0.48028466552705856, 0.29897289534330185, 0.33043187376168659, 0.24437697938157904]\n",
      "evaluation on validation set:\n",
      "9229/9229 [==============================] - 49s    \n",
      "[0.24220631893949035, 0.46772273677130899, 0.29004361376736298, 0.32063387823732614, 0.23596955198374403]\n"
     ]
    }
   ],
   "source": [
    "model_3conv1d_2FC =Sequential(\n",
    "        [ Embedding(input_dim=nb_words+1,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_matrix],input_length=MAX_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(64, 5, activation='relu'),\n",
    "            MaxPooling1D(3),\n",
    "            Conv1D(32, 5, activation='relu'),\n",
    "            MaxPooling1D(2),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_3conv1d_2FC')\n",
    "\n",
    "compile_fit_evaluate(model_3conv1d_2FC, flag_quick_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

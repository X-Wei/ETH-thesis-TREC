{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOTE_DATA_DIR = '/local/XW/DATA/MIMIC/noteevents_by_sid/'\n",
    "UMLS_DATA_DIR = '/local/XW/DATA/MIMIC/UMLS_by_sid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [ [{...}],\n",
      "    [{...}, {...}, {...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}, {...}],\n",
      "    [{...}, {...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}, {...}],\n",
      "    [{...}, {...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}]],\n",
      "  [ [{...}, {...}],\n",
      "    [{...}, {...}, {...}, {...}, {...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}, {...}],\n",
      "    [ {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...}],\n",
      "    [{...}],\n",
      "    [ {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...},\n",
      "      {...}],\n",
      "    [{...}, {...}, {...}],\n",
      "    [{...}, {...}, {...}, {...}, {...}, {...}, {...}, {...}, {...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}, {...}, {...}, {...}, {...}, {...}, {...}, {...}],\n",
      "    [{...}, {...}, {...}],\n",
      "    [{...}, {...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}, {...}, {...}, {...}, {...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}],\n",
      "    [{...}]]]\n",
      "[{u'cui': 'C0559473',\n",
      "  u'end': 125,\n",
      "  u'ngram': u'maternal history',\n",
      "  u'preferred': 1,\n",
      "  u'semtypes': set([u'T033']),\n",
      "  u'similarity': 1.0,\n",
      "  u'start': 109,\n",
      "  u'term': u'maternal history'}]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "in UMLS_DATA_DIR, each .pk file contains a list, each element in list corresponds to a noteevent\n",
    "\n",
    "each noteevent is represented as a list of lists of dicts (one list per sentence?), \n",
    "the concepts are stored in the dicts\n",
    "\n",
    "CUI: The Concept Unique Identifier\n",
    "semtype: Semantic Type - One of the broad categories \n",
    "\n",
    "see: https://www.nlm.nih.gov/research/umls/new_users/online_learning/glossary.html\n",
    "'''\n",
    "# example:\n",
    "with open(os.path.join(UMLS_DATA_DIR, '2.pk')) as f:\n",
    "    example = pk.load(f)\n",
    "    pprint(example,indent=2, depth=3)\n",
    "    pprint(example[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46146"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(UMLS_DATA_DIR))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=== multiply cui and semtype ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46146/46146 [2:39:02<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_cui_semtype_pair = set()\n",
    "for fn in tqdm(os.listdir(UMLS_DATA_DIR)[:]):\n",
    "    fpath = os.path.join(UMLS_DATA_DIR, fn)\n",
    "    with open(fpath) as f:\n",
    "        concepts_per_sid = pk.load(f)\n",
    "        for concepts_per_note in concepts_per_sid:\n",
    "            for concept_per_sentence in concepts_per_note:\n",
    "                for concept in concept_per_sentence:\n",
    "                    for st in concept['semtypes']:\n",
    "                        unique_cui_semtype_pair.add((st,concept['cui']))\n",
    "print len(unique_cui_semtype_pair)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46146/46146 [1:29:50<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59790\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_concepts = set()\n",
    "unique_semtypes = set()\n",
    "for fn in tqdm(os.listdir(UMLS_DATA_DIR)[:]):\n",
    "    fpath = os.path.join(UMLS_DATA_DIR, fn)\n",
    "    with open(fpath) as f:\n",
    "        concepts_per_sid = pk.load(f)\n",
    "        for concepts_per_note in concepts_per_sid:\n",
    "            for concept_per_sentence in concepts_per_note:\n",
    "                for concept in concept_per_sentence:\n",
    "                    unique_concepts.add( concept['cui'] ) # CUI = Concept Unique Identifiers\n",
    "                    unique_semtypes.update(concept['semtypes'])\n",
    "print len(unique_concepts)\n",
    "print len(unique_semtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0 \n",
    "concept2id = {}\n",
    "for c in unique_concepts:\n",
    "    concept2id[c] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46146/46146 [1:21:29<00:00,  9.44it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "sids = []\n",
    "i = 0\n",
    "for fn in tqdm(os.listdir(UMLS_DATA_DIR)[:]):\n",
    "    x = set()\n",
    "    sid = int(fn[:-3])\n",
    "    sids.append(sid); i+=1\n",
    "    fpath = os.path.join(UMLS_DATA_DIR, fn)\n",
    "    with open(fpath) as f:\n",
    "        concepts_per_sid = pk.load(f)\n",
    "        for concepts_per_note in concepts_per_sid:\n",
    "            for concept_per_sentence in concepts_per_note:\n",
    "                for concept in concept_per_sentence:\n",
    "                    cui = concept['cui']\n",
    "                    x.add(concept2id[cui])\n",
    "    X.append(list(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46146, 59790)\n",
      "[    2     3     4 ..., 99992 99995 99999]\n"
     ]
    }
   ],
   "source": [
    "# turn X into sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "data, rows, cols = [], [], []\n",
    "for r in xrange(len(X)):\n",
    "    for c in X[r]:\n",
    "        rows.append(r)\n",
    "        cols.append(c)\n",
    "        data.append(1.0)\n",
    "X = csr_matrix((data, (rows, cols)))\n",
    "print X.shape\n",
    "sids = np.array(sids)\n",
    "print sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86.0, 1242.0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].sum(), X[1].sum() # 1st and 2nd row, corresponds to sid=2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle X's rows (sids are to be shuffled too)\n",
    "shuffle_index = np.arange(X.shape[0])\n",
    "np.random.shuffle(shuffle_index)\n",
    "X = X[shuffle_index]\n",
    "sids = sids[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sid2rowidx = {} # map sid(int) to the row index in the (shuffled) raw feature matrix X\n",
    "for sid,rowidx in zip(sids, range(len(sids))):\n",
    "    sid2rowidx[sid] = rowidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86.0, 1242.0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[sid2rowidx[2]].sum(), X[sid2rowidx[3]].sum() # check the mapping is correct..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUT_FILENAME = './data/umls_raw_features.pk'\n",
    "data_to_pickle ={\n",
    "    'X_raw': X,\n",
    "    'unique_concepts': unique_concepts,\n",
    "    'unique_semtypes': unique_semtypes,\n",
    "    'concept2id': concept2id,\n",
    "    'sid2rowidx': sid2rowidx \n",
    "}\n",
    "with open(OUT_FILENAME,'wb') as f:\n",
    "    pk.dump(data_to_pickle, f, pk.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46146"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sid2rowidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are some toy code for training/getting deep patient feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproductive\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X[:100].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENCODING_DIM = 500\n",
    "INPUT_DIM = X.shape[-1]\n",
    "NOISE_PORTION = 0.5 # randomly mask protion\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SZ = 128\n",
    "NB_EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_raw = Input(shape=(INPUT_DIM,))\n",
    "# for final dpvec, should I take the activations before relu ???\n",
    "hiddenlayer = Dense(ENCODING_DIM, activation='relu')\n",
    "outputlayer = Dense(INPUT_DIM, activation='sigmoid')\n",
    "\n",
    "encoded = hiddenlayer(input_raw)\n",
    "\n",
    "decoded = outputlayer(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_raw, output=decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(X, X, nb_epoch=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded2 = hiddenlayer(decoded)\n",
    "decode2 =outputlayer(encoded2)\n",
    "encoded3 = hiddenlayer(decode2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = Model(input=input_raw, output=encoded3)\n",
    "# X_encoded = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dpvec = encoder.predict(X) # deep patient feature vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dpvec.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "PK_FPATH = 'data/processed_data_sidhid.pk'\n",
    "MODEL_FPATH = './models/1124_model_2embed_2conv1d_2FC.h5' # path of best trained model \n",
    "# constants\n",
    "N_LABELS = 50\n",
    "N_SIDHID = 58328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pickled data\n",
    "pk_data = pk.load(open(PK_FPATH, 'rb'))\n",
    "X_train, Y_train = pk_data['X_train'], pk_data['Y_train']\n",
    "X_val, Y_val = pk_data['X_val'], pk_data['Y_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load best model: 2 embedding layers, 2 conv layers and 2 FC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ***NOTE***\n",
    "# To load models from file, we have to modify metrics.py at: \n",
    "# `/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/` \n",
    "# to add the custom metric function, otherwise `load_model` throws exception ! \n",
    "# cf issue: https://github.com/fchollet/keras/issues/3911\n",
    "from keras.models import load_model\n",
    "model = load_model(MODEL_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 1000, 200)     0           main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)          (None, 1000, 200)     0           main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 996, 128)      128128      embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 996, 128)      128128      embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 996, 128)      0           convolution1d_4[0][0]            \n",
      "                                                                   convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 199, 128)      0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 4992)          0           maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4992)          0           flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 500)           2496500     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 500)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 50)            25050       dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2859854\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract embedding vector, and use SVM to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"main_input_1:0\", shape=(?, 1000), dtype=int32)\n",
      "Tensor(\"Relu_7:0\", shape=(?, 500), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print model.layers[0].input\n",
    "print model.layers[11].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use K.function to construct a model that outputs embedding vector\n",
    "from keras import backend as K\n",
    "get_embedvec = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                                  [model.layers[11].output])\n",
    "embedvec = lambda X: get_embedvec([X,0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 500)\n"
     ]
    }
   ],
   "source": [
    "# output in test mode = 0\n",
    "layer_output = embedvec(X_train[:10])\n",
    "print layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_embedvec(X):\n",
    "    BATCH_SZ = 128\n",
    "    embedded = []\n",
    "    for i in tqdm(xrange(0, X.shape[0], BATCH_SZ)):\n",
    "        x_batch = X[i:min(i+BATCH_SZ, X.shape[0])]\n",
    "        embedveci = embedvec(x_batch)\n",
    "        embedded.append(embedveci)\n",
    "    return np.vstack(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [16:46<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46663, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xembed_train = to_embedvec(X_train)\n",
    "print Xembed_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [04:14<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11665, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xembed_val = to_embedvec(X_val)\n",
    "print Xembed_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilabel_evaluate(y_pred, y_true=Y_val):\n",
    "    y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "    tp = np.sum(y_true * y_pred, axis=-1) \n",
    "    sum_true = np.sum(y_true, axis=-1)\n",
    "    sum_pred = np.sum(y_pred, axis=-1)\n",
    "    union = np.sum(np.clip(y_true+y_pred, 0, 1), axis=-1)\n",
    "    print 'precision =', np.mean(tp/(sum_pred+1e-10))\n",
    "    print 'recall = ', np.mean(tp/(sum_true+1e-10))\n",
    "    print 'F1 = ', 2*np.mean(tp/(sum_true+sum_pred+1e-10))\n",
    "    print 'acc = ', np.mean(tp/(union+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [1:59:34<00:00, 130.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11665, 50)\n",
      "[8156, 3626, 4116, 3338, 5974, 7801, 9148, 2789, 5914, 7374, 2083, 3, 0, 6504, 5911, 3544, 7386, 3984, 2913, 2301, 2868, 2817, 2607, 21, 3413, 10611, 4317, 7362, 3841, 1923, 3673, 1922, 5737, 2849, 7128, 2815, 3792, 4, 1867, 1497, 2577, 2445, 4341, 5908, 1909, 2230, 3842, 3, 5706, 11513]\n",
      "precision = 0.197625869081\n",
      "recall =  0.660431292459\n",
      "F1 =  0.290633777991\n",
      "acc =  0.180832980669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "              'alpha': [1, 1e-1, 3e-1, 1e-2, 3e-2, 1e-3, 3e-3, 1e-4, 3e-4],\n",
    "              'n_iter': [10, 50, 200]}\n",
    "clfs = []\n",
    "for i in tqdm(xrange(N_LABELS)):\n",
    "    sgd =  SGDClassifier(loss='hinge', penalty='l2', random_state=1, class_weight='balanced')\n",
    "    clf = GridSearchCV(sgd, parameters, n_jobs=-1)\n",
    "    clf.fit(Xembed_train, Y_train[:,i]) \n",
    "    clfs.append(clf)\n",
    "\n",
    "preds = [clfs[i].predict(Xembed_val) for i in xrange(N_LABELS)]    \n",
    "pred_svm = np.vstack(preds).T\n",
    "print pred_svm.shape\n",
    "print map(int, pred_svm.sum(axis=0))\n",
    "multilabel_evaluate(y_pred=pred_svm, y_true=Y_val)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

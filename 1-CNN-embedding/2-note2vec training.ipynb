{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproducible\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, Merge\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.callbacks import Callback, EarlyStopping, TensorBoard\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "PK_FPATH = './data/processed_data_sidhid.pk'\n",
    "MODEL_PATH = './models/'\n",
    "LOG_PATH = './logs/'\n",
    "# constants\n",
    "N_LABELS = 50\n",
    "N_SIDHID = 58328\n",
    "EMBEDDING_DIM = 200\n",
    "# learning configurations\n",
    "VALIDATION_SPLIT = 0.2\n",
    "N_EPOCHS = 20\n",
    "SZ_BATCH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46663, 1000) (46663, 50)\n",
      "(11665, 1000) (11665, 50)\n"
     ]
    }
   ],
   "source": [
    "pk_data = pk.load(open(PK_FPATH, 'rb'))\n",
    "# print pk_data.keys()\n",
    "\n",
    "embedding_w2v = pk_data['embedding_w2v']\n",
    "embedding_glove = pk_data['embedding_glove']\n",
    "\n",
    "X_train, Y_train = pk_data['X_train'], pk_data['Y_train']\n",
    "X_val, Y_val = pk_data['X_val'], pk_data['Y_val']\n",
    "\n",
    "INPUT_SEQ_LEN = X_train.shape[1]\n",
    "EMBEDDING_INPUT_DIM = embedding_w2v.shape[0]\n",
    "\n",
    "print X_train.shape, Y_train.shape\n",
    "print X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify sample weight, and use larger batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46663,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 12.01673109,  17.46144513,   0.1048649 , ...,  15.49525083,\n",
       "        14.95808575,  43.77665432])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_freq = 1e6*Y_train.sum(axis=0)**(-1.5)\n",
    "sample_weight = (inv_freq * Y_train).sum(axis=1)\n",
    "print sample_weight.shape\n",
    "sample_weight\n",
    "# y_n_poslabels = Y_train_noother.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def multlabel_prec(y_true, y_pred):\n",
    "        y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "        y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "        tp = K.sum(y_true * y_pred, axis =-1)\n",
    "        sum_true = K.sum(y_true, axis=-1)\n",
    "        sum_pred = K.sum(y_pred, axis=-1)\n",
    "        return K.mean(tp/(sum_pred+1e-10)) # to avoid NaN precision\n",
    "\n",
    "    def multlabel_recall(y_true, y_pred):\n",
    "        y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "        y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "        tp = K.sum(y_true * y_pred, axis =-1)\n",
    "        sum_true = K.sum(y_true, axis=-1)\n",
    "        sum_pred = K.sum(y_pred, axis=-1)\n",
    "        return K.mean(tp/(sum_true+1e-10)) \n",
    "\n",
    "    def multlabel_F1(y_true, y_pred):\n",
    "        y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "        y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "        tp = K.sum(y_true * y_pred, axis =-1)\n",
    "        sum_true = K.sum(y_true, axis=-1)\n",
    "        sum_pred = K.sum(y_pred, axis=-1)\n",
    "        return 2*K.mean(tp/(sum_true+sum_pred+1e-10))\n",
    "\n",
    "    def multlabel_acc(y_true, y_pred):\n",
    "        y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "        y_pred = K.round(K.clip(y_pred, 0, 1)) # turn to 0/1 \n",
    "        intersect = y_true * y_pred\n",
    "        intersect = K.sum(intersect, axis=-1)\n",
    "        union = K.clip(y_true+y_pred, 0, 1)\n",
    "        union = K.sum(union, axis=-1)\n",
    "        return K.mean(intersect/(union+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    print 'evaluation on training set:'\n",
    "    print model.evaluate(X_train, Y_train, batch_size=128)\n",
    "    print 'evaluation on validation set:'\n",
    "    print model.evaluate(X_val, Y_val, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wraps up operations on models\n",
    "def compile_fit_evaluate(model, quick_test=False, print_summary=True,\n",
    "                         save_log=True, save_model=True, del_model=False):\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=[multlabel_prec, multlabel_recall, multlabel_F1, multlabel_acc])\n",
    "    if print_summary:\n",
    "        print model.summary()\n",
    "        \n",
    "    if quick_test: # use tiny data for quick testing\n",
    "        print '(quick test mode)'\n",
    "        model.fit(X_train[:100], Y_train[:100], nb_epoch=1)\n",
    "        return  \n",
    "    \n",
    "    _callbacks = [EarlyStopping(monitor='val_loss', patience=2)] \n",
    "    if save_log:\n",
    "        logdir = os.path.join( LOG_PATH, time.strftime('%m%d')+'_'+str(model.name) )\n",
    "        if not os.path.exists(logdir):\n",
    "            os.makedirs(logdir)\n",
    "        _callbacks.append(TensorBoard(log_dir=logdir))\n",
    "        print 'run \"tensorboard --logdir=%s\" to launch tensorboard'%logdir\n",
    "    \n",
    "    model.fit( X_train, Y_train, \n",
    "              validation_data=(X_val, Y_val), \n",
    "              nb_epoch=N_EPOCHS, batch_size=SZ_BATCH, \n",
    "              sample_weight = sample_weight, \n",
    "              callbacks=_callbacks )\n",
    "    \n",
    "    print 'evaluating model...'\n",
    "    evaluate_model(model)\n",
    "    \n",
    "    if save_model: \n",
    "        model_fpath = os.path.join( MODEL_PATH, time.strftime('%m%d')+'_%s.h5'% str(model.name) )\n",
    "        model.save(model_fpath)\n",
    "    \n",
    "    if del_model:\n",
    "        del model # delete the model to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ''' ***NOTE***\n",
    "# To load models from file, we have to modify metrics.py at: \n",
    "# `/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras` \n",
    "# to add the `multlabel_XXX` function, otherwise throws exception ! \n",
    "\n",
    "# cf issue: https://github.com/fchollet/keras/issues/3911\n",
    "# '''\n",
    "# m = load_model(os.path.sep.join([MODEL_PATH, 'model_1conv1d.h5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model: 2 conv layers and 2 FC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag_quick_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1000, 200)     0           main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1000, 200)     0           main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 996, 128)      128128      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 996, 128)      128128      embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 996, 128)      0           convolution1d_1[0][0]            \n",
      "                                                                   convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 199, 128)      0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 4992)          0           maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4992)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 500)           2496500     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 500)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            25050       dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2859854\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1129_model_2embed_2conv1d_2FC\" to launch tensorboard\n",
      "Train on 46663 samples, validate on 11665 samples\n",
      "Epoch 1/20\n",
      "46663/46663 [==============================] - 1194s - loss: 7.5026 - multlabel_prec: 0.1557 - multlabel_recall: 0.0923 - multlabel_F1: 0.0968 - multlabel_acc: 0.0695 - val_loss: 0.2975 - val_multlabel_prec: 0.0022 - val_multlabel_recall: 3.5536e-04 - val_multlabel_F1: 5.9424e-04 - val_multlabel_acc: 3.5536e-04\n",
      "Epoch 2/20\n",
      "46663/46663 [==============================] - 1173s - loss: 6.3624 - multlabel_prec: 0.2181 - multlabel_recall: 0.1539 - multlabel_F1: 0.1585 - multlabel_acc: 0.1214 - val_loss: 0.2774 - val_multlabel_prec: 0.0896 - val_multlabel_recall: 0.0281 - val_multlabel_F1: 0.0404 - val_multlabel_acc: 0.0267\n",
      "Epoch 3/20\n",
      "46663/46663 [==============================] - 1172s - loss: 6.1035 - multlabel_prec: 0.2780 - multlabel_recall: 0.1868 - multlabel_F1: 0.1981 - multlabel_acc: 0.1507 - val_loss: 0.2827 - val_multlabel_prec: 0.2454 - val_multlabel_recall: 0.0944 - val_multlabel_F1: 0.1278 - val_multlabel_acc: 0.0837\n",
      "Epoch 4/20\n",
      "46663/46663 [==============================] - 1170s - loss: 5.8764 - multlabel_prec: 0.3310 - multlabel_recall: 0.2129 - multlabel_F1: 0.2316 - multlabel_acc: 0.1751 - val_loss: 0.2766 - val_multlabel_prec: 0.2876 - val_multlabel_recall: 0.1117 - val_multlabel_F1: 0.1513 - val_multlabel_acc: 0.0993\n",
      "Epoch 5/20\n",
      "46663/46663 [==============================] - 1195s - loss: 5.7375 - multlabel_prec: 0.3562 - multlabel_recall: 0.2261 - multlabel_F1: 0.2479 - multlabel_acc: 0.1871 - val_loss: 0.2690 - val_multlabel_prec: 0.3551 - val_multlabel_recall: 0.1397 - val_multlabel_F1: 0.1874 - val_multlabel_acc: 0.1275\n",
      "Epoch 6/20\n",
      "46663/46663 [==============================] - 1205s - loss: 5.6259 - multlabel_prec: 0.3817 - multlabel_recall: 0.2379 - multlabel_F1: 0.2624 - multlabel_acc: 0.1981 - val_loss: 0.2516 - val_multlabel_prec: 0.2994 - val_multlabel_recall: 0.0997 - val_multlabel_F1: 0.1409 - val_multlabel_acc: 0.0935\n",
      "Epoch 7/20\n",
      "46663/46663 [==============================] - 1903s - loss: 5.5342 - multlabel_prec: 0.3989 - multlabel_recall: 0.2474 - multlabel_F1: 0.2741 - multlabel_acc: 0.2069 - val_loss: 0.2577 - val_multlabel_prec: 0.2737 - val_multlabel_recall: 0.1134 - val_multlabel_F1: 0.1489 - val_multlabel_acc: 0.0999\n",
      "Epoch 8/20\n",
      "46663/46663 [==============================] - 2035s - loss: 5.4520 - multlabel_prec: 0.4066 - multlabel_recall: 0.2549 - multlabel_F1: 0.2820 - multlabel_acc: 0.2131 - val_loss: 0.2489 - val_multlabel_prec: 0.3440 - val_multlabel_recall: 0.1412 - val_multlabel_F1: 0.1859 - val_multlabel_acc: 0.1277\n",
      "Epoch 9/20\n",
      "46663/46663 [==============================] - 2524s - loss: 5.3656 - multlabel_prec: 0.4240 - multlabel_recall: 0.2646 - multlabel_F1: 0.2936 - multlabel_acc: 0.2222 - val_loss: 0.2497 - val_multlabel_prec: 0.3701 - val_multlabel_recall: 0.1629 - val_multlabel_F1: 0.2104 - val_multlabel_acc: 0.1449\n",
      "Epoch 10/20\n",
      "46663/46663 [==============================] - 2727s - loss: 5.2864 - multlabel_prec: 0.4340 - multlabel_recall: 0.2720 - multlabel_F1: 0.3022 - multlabel_acc: 0.2287 - val_loss: 0.2620 - val_multlabel_prec: 0.3718 - val_multlabel_recall: 0.1662 - val_multlabel_F1: 0.2143 - val_multlabel_acc: 0.1462\n",
      "Epoch 11/20\n",
      "46663/46663 [==============================] - 2459s - loss: 5.2099 - multlabel_prec: 0.4477 - multlabel_recall: 0.2826 - multlabel_F1: 0.3136 - multlabel_acc: 0.2375 - val_loss: 0.2469 - val_multlabel_prec: 0.3676 - val_multlabel_recall: 0.1534 - val_multlabel_F1: 0.2000 - val_multlabel_acc: 0.1378\n",
      "Epoch 12/20\n",
      "46663/46663 [==============================] - 1153s - loss: 5.1295 - multlabel_prec: 0.4559 - multlabel_recall: 0.2903 - multlabel_F1: 0.3218 - multlabel_acc: 0.2437 - val_loss: 0.2611 - val_multlabel_prec: 0.4145 - val_multlabel_recall: 0.2286 - val_multlabel_F1: 0.2701 - val_multlabel_acc: 0.1882\n",
      "Epoch 13/20\n",
      "46663/46663 [==============================] - 1151s - loss: 5.0533 - multlabel_prec: 0.4631 - multlabel_recall: 0.2972 - multlabel_F1: 0.3293 - multlabel_acc: 0.2494 - val_loss: 0.2455 - val_multlabel_prec: 0.3771 - val_multlabel_recall: 0.1546 - val_multlabel_F1: 0.2030 - val_multlabel_acc: 0.1407\n",
      "Epoch 14/20\n",
      "46663/46663 [==============================] - 1151s - loss: 4.9712 - multlabel_prec: 0.4741 - multlabel_recall: 0.3064 - multlabel_F1: 0.3387 - multlabel_acc: 0.2567 - val_loss: 0.2482 - val_multlabel_prec: 0.4020 - val_multlabel_recall: 0.1938 - val_multlabel_F1: 0.2417 - val_multlabel_acc: 0.1678\n",
      "Epoch 15/20\n",
      "46663/46663 [==============================] - 1152s - loss: 4.8996 - multlabel_prec: 0.4834 - multlabel_recall: 0.3152 - multlabel_F1: 0.3485 - multlabel_acc: 0.2644 - val_loss: 0.2490 - val_multlabel_prec: 0.4119 - val_multlabel_recall: 0.1899 - val_multlabel_F1: 0.2393 - val_multlabel_acc: 0.1666\n",
      "Epoch 16/20\n",
      "46663/46663 [==============================] - 1149s - loss: 4.8284 - multlabel_prec: 0.4911 - multlabel_recall: 0.3250 - multlabel_F1: 0.3574 - multlabel_acc: 0.2714 - val_loss: 0.2470 - val_multlabel_prec: 0.3866 - val_multlabel_recall: 0.1559 - val_multlabel_F1: 0.2059 - val_multlabel_acc: 0.1413\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "46663/46663 [==============================] - 482s   \n",
      "[0.16377994844201901, 0.48585930447300174, 0.2983579639260544, 0.33348192516020181, 0.25754860427462994]\n",
      "evaluation on validation set:\n",
      "11665/11665 [==============================] - 121s   \n",
      "[0.24701561009071438, 0.38658155847454195, 0.15593987479263041, 0.20589986870179502, 0.14128725074592496]\n"
     ]
    }
   ],
   "source": [
    "embed1_w2v = Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_w2v],input_length=INPUT_SEQ_LEN, trainable=False )\n",
    "embed2_glove = Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_glove],input_length=INPUT_SEQ_LEN, trainable=False )\n",
    "\n",
    "input_layer = Input(shape=(INPUT_SEQ_LEN,), dtype='int32', name='main_input')\n",
    "\n",
    "embed1 = embed1_w2v(input_layer)\n",
    "conv_embed1 = Conv1D(128, 5, activation='relu')(embed1)\n",
    "\n",
    "embed2 = embed2_glove(input_layer)\n",
    "conv_embed2 = Conv1D(128, 5, activation='relu')(embed2)\n",
    "\n",
    "from keras.layers import merge # `Merge` is for model, while `merge` is for tensor.\n",
    "merge_layer = merge([conv_embed1, conv_embed2], mode='sum')\n",
    "\n",
    "x = MaxPooling1D(5)(merge_layer)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(p=0.5)(x)\n",
    "x = Dense(500, activation='relu')(x)\n",
    "x = Dropout(p=0.5)(x)\n",
    "output_layer = Dense(N_LABELS, activation='sigmoid')(x)\n",
    "\n",
    "model_2embed_2conv1d_2FC = Model(input=input_layer, output=output_layer, \n",
    "                                 name = 'model_2embed_2conv1d_2FC')\n",
    "\n",
    "compile_fit_evaluate(model_2embed_2conv1d_2FC, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 1000, 200)     0           embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 996, 128)      128128      embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 4992)          0           maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4992)          0           flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 500)           2496500     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 500)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 50)            25050       dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2731726\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1129_model_2conv1d_2FC\" to launch tensorboard\n",
      "Train on 46663 samples, validate on 11665 samples\n",
      "Epoch 1/20\n",
      "46663/46663 [==============================] - 793s - loss: 7.3299 - multlabel_prec: 0.1485 - multlabel_recall: 0.0829 - multlabel_F1: 0.0880 - multlabel_acc: 0.0634 - val_loss: 0.2900 - val_multlabel_prec: 0.0286 - val_multlabel_recall: 0.0059 - val_multlabel_F1: 0.0094 - val_multlabel_acc: 0.0056\n",
      "Epoch 2/20\n",
      "46663/46663 [==============================] - 794s - loss: 6.3061 - multlabel_prec: 0.2225 - multlabel_recall: 0.1561 - multlabel_F1: 0.1611 - multlabel_acc: 0.1235 - val_loss: 0.2793 - val_multlabel_prec: 0.2120 - val_multlabel_recall: 0.0805 - val_multlabel_F1: 0.1078 - val_multlabel_acc: 0.0704\n",
      "Epoch 3/20\n",
      "46663/46663 [==============================] - 796s - loss: 5.9937 - multlabel_prec: 0.2997 - multlabel_recall: 0.1978 - multlabel_F1: 0.2114 - multlabel_acc: 0.1601 - val_loss: 0.2626 - val_multlabel_prec: 0.2682 - val_multlabel_recall: 0.1052 - val_multlabel_F1: 0.1403 - val_multlabel_acc: 0.0940\n",
      "Epoch 4/20\n",
      "46663/46663 [==============================] - 791s - loss: 5.8012 - multlabel_prec: 0.3470 - multlabel_recall: 0.2208 - multlabel_F1: 0.2409 - multlabel_acc: 0.1824 - val_loss: 0.2601 - val_multlabel_prec: 0.2215 - val_multlabel_recall: 0.0789 - val_multlabel_F1: 0.1071 - val_multlabel_acc: 0.0709\n",
      "Epoch 5/20\n",
      "46663/46663 [==============================] - 790s - loss: 5.6862 - multlabel_prec: 0.3755 - multlabel_recall: 0.2348 - multlabel_F1: 0.2582 - multlabel_acc: 0.1951 - val_loss: 0.2596 - val_multlabel_prec: 0.3182 - val_multlabel_recall: 0.1148 - val_multlabel_F1: 0.1577 - val_multlabel_acc: 0.1044\n",
      "Epoch 6/20\n",
      "46663/46663 [==============================] - 791s - loss: 5.5736 - multlabel_prec: 0.3972 - multlabel_recall: 0.2457 - multlabel_F1: 0.2722 - multlabel_acc: 0.2059 - val_loss: 0.2502 - val_multlabel_prec: 0.3481 - val_multlabel_recall: 0.1347 - val_multlabel_F1: 0.1804 - val_multlabel_acc: 0.1245\n",
      "Epoch 7/20\n",
      "46663/46663 [==============================] - 792s - loss: 5.4915 - multlabel_prec: 0.4130 - multlabel_recall: 0.2547 - multlabel_F1: 0.2835 - multlabel_acc: 0.2146 - val_loss: 0.2480 - val_multlabel_prec: 0.3589 - val_multlabel_recall: 0.1269 - val_multlabel_F1: 0.1757 - val_multlabel_acc: 0.1187\n",
      "Epoch 8/20\n",
      "46663/46663 [==============================] - 791s - loss: 5.4044 - multlabel_prec: 0.4277 - multlabel_recall: 0.2624 - multlabel_F1: 0.2930 - multlabel_acc: 0.2218 - val_loss: 0.2622 - val_multlabel_prec: 0.3647 - val_multlabel_recall: 0.1624 - val_multlabel_F1: 0.2097 - val_multlabel_acc: 0.1409\n",
      "Epoch 9/20\n",
      "46663/46663 [==============================] - 794s - loss: 5.3230 - multlabel_prec: 0.4392 - multlabel_recall: 0.2722 - multlabel_F1: 0.3033 - multlabel_acc: 0.2295 - val_loss: 0.2537 - val_multlabel_prec: 0.4117 - val_multlabel_recall: 0.1573 - val_multlabel_F1: 0.2121 - val_multlabel_acc: 0.1444\n",
      "Epoch 10/20\n",
      "46663/46663 [==============================] - 789s - loss: 5.2486 - multlabel_prec: 0.4485 - multlabel_recall: 0.2796 - multlabel_F1: 0.3115 - multlabel_acc: 0.2361 - val_loss: 0.2482 - val_multlabel_prec: 0.4033 - val_multlabel_recall: 0.1775 - val_multlabel_F1: 0.2285 - val_multlabel_acc: 0.1572\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "46663/46663 [==============================] - 327s   \n",
      "[0.18360787302825965, 0.46829564513121014, 0.29140081706428317, 0.32704235805234916, 0.2496942447007981]\n",
      "evaluation on validation set:\n",
      "11665/11665 [==============================] - 81s    \n",
      "[0.24815692502160569, 0.40333048068961003, 0.17750735236399684, 0.22847659846155419, 0.15721142977488894]\n"
     ]
    }
   ],
   "source": [
    "model_2conv1d_2FC = Sequential(\n",
    "       [Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_w2v],input_length=INPUT_SEQ_LEN, trainable=False ),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(5),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(5),\n",
    "        Flatten(),\n",
    "        Dropout(p=0.5),\n",
    "        Dense(500, activation='relu'),\n",
    "        Dropout(p=0.5),\n",
    "        Dense(N_LABELS, activation='sigmoid') \n",
    "       ], name = 'model_2conv1d_2FC')\n",
    "compile_fit_evaluate(model_2conv1d_2FC, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 1000, 200)     0           embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 996, 128)      128128      embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_7 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_6 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 4992)          0           maxpooling1d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4992)          0           flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 500)           2496500     dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 500)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 50)            25050       dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2731726\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1129_model_2conv1d_2FC_glove\" to launch tensorboard\n",
      "Train on 46663 samples, validate on 11665 samples\n",
      "Epoch 1/20\n",
      "46663/46663 [==============================] - 793s - loss: 7.4296 - multlabel_prec: 0.1627 - multlabel_recall: 0.0940 - multlabel_F1: 0.0993 - multlabel_acc: 0.0720 - val_loss: 0.2893 - val_multlabel_prec: 0.0012 - val_multlabel_recall: 2.1901e-04 - val_multlabel_F1: 3.6590e-04 - val_multlabel_acc: 2.1901e-04\n",
      "Epoch 2/20\n",
      "46663/46663 [==============================] - 793s - loss: 6.3555 - multlabel_prec: 0.2143 - multlabel_recall: 0.1484 - multlabel_F1: 0.1529 - multlabel_acc: 0.1177 - val_loss: 0.2910 - val_multlabel_prec: 0.0270 - val_multlabel_recall: 0.0088 - val_multlabel_F1: 0.0126 - val_multlabel_acc: 0.0083\n",
      "Epoch 3/20\n",
      "46663/46663 [==============================] - 790s - loss: 6.0854 - multlabel_prec: 0.2604 - multlabel_recall: 0.1785 - multlabel_F1: 0.1876 - multlabel_acc: 0.1439 - val_loss: 0.2683 - val_multlabel_prec: 0.2022 - val_multlabel_recall: 0.0744 - val_multlabel_F1: 0.1020 - val_multlabel_acc: 0.0668\n",
      "Epoch 4/20\n",
      "46663/46663 [==============================] - 790s - loss: 5.8971 - multlabel_prec: 0.3131 - multlabel_recall: 0.2060 - multlabel_F1: 0.2219 - multlabel_acc: 0.1685 - val_loss: 0.2639 - val_multlabel_prec: 0.2906 - val_multlabel_recall: 0.1098 - val_multlabel_F1: 0.1492 - val_multlabel_acc: 0.0987\n",
      "Epoch 5/20\n",
      "46663/46663 [==============================] - 790s - loss: 5.7659 - multlabel_prec: 0.3450 - multlabel_recall: 0.2223 - multlabel_F1: 0.2424 - multlabel_acc: 0.1839 - val_loss: 0.2731 - val_multlabel_prec: 0.2591 - val_multlabel_recall: 0.1016 - val_multlabel_F1: 0.1364 - val_multlabel_acc: 0.0891\n",
      "Epoch 6/20\n",
      "46663/46663 [==============================] - 792s - loss: 5.6500 - multlabel_prec: 0.3681 - multlabel_recall: 0.2334 - multlabel_F1: 0.2559 - multlabel_acc: 0.1935 - val_loss: 0.2556 - val_multlabel_prec: 0.2613 - val_multlabel_recall: 0.0821 - val_multlabel_F1: 0.1178 - val_multlabel_acc: 0.0776\n",
      "Epoch 7/20\n",
      "46663/46663 [==============================] - 791s - loss: 5.5571 - multlabel_prec: 0.3880 - multlabel_recall: 0.2426 - multlabel_F1: 0.2680 - multlabel_acc: 0.2026 - val_loss: 0.2574 - val_multlabel_prec: 0.2845 - val_multlabel_recall: 0.1179 - val_multlabel_F1: 0.1547 - val_multlabel_acc: 0.1038\n",
      "Epoch 8/20\n",
      "46663/46663 [==============================] - 790s - loss: 5.4729 - multlabel_prec: 0.4001 - multlabel_recall: 0.2502 - multlabel_F1: 0.2766 - multlabel_acc: 0.2093 - val_loss: 0.2624 - val_multlabel_prec: 0.3063 - val_multlabel_recall: 0.1412 - val_multlabel_F1: 0.1787 - val_multlabel_acc: 0.1204\n",
      "Epoch 9/20\n",
      "46663/46663 [==============================] - 790s - loss: 5.3929 - multlabel_prec: 0.4125 - multlabel_recall: 0.2575 - multlabel_F1: 0.2854 - multlabel_acc: 0.2159 - val_loss: 0.2619 - val_multlabel_prec: 0.3646 - val_multlabel_recall: 0.1771 - val_multlabel_F1: 0.2205 - val_multlabel_acc: 0.1517\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "46663/46663 [==============================] - 328s   \n",
      "[0.19777813819593212, 0.44691549627012922, 0.30360357611531591, 0.32866910366883983, 0.24926008316855791]\n",
      "evaluation on validation set:\n",
      "11665/11665 [==============================] - 81s    \n",
      "[0.2619033445118325, 0.36459770299721012, 0.17708627738975119, 0.22046224352274132, 0.15170867275742059]\n"
     ]
    }
   ],
   "source": [
    "model_2conv1d_2FC_glove = Sequential(\n",
    "       [Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_glove],input_length=INPUT_SEQ_LEN, trainable=False ),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(5),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(5),\n",
    "        Flatten(),\n",
    "        Dropout(p=0.5),\n",
    "        Dense(500, activation='relu'),\n",
    "        Dropout(p=0.5),\n",
    "        Dense(N_LABELS, activation='sigmoid') \n",
    "       ], name = 'model_2conv1d_2FC_glove')\n",
    "compile_fit_evaluate(model_2conv1d_2FC_glove, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 1000, 200)     0           embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 996, 256)      256256      embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_7 (MaxPooling1D)    (None, 199, 256)      0           convolution1d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_9 (Convolution1D)  (None, 195, 128)      163968      maxpooling1d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_8 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_10 (Convolution1D) (None, 38, 64)        16448       maxpooling1d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_9 (MaxPooling1D)    (None, 7, 64)         0           convolution1d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 448)           0           maxpooling1d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 448)           0           flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 50)            22450       dropout_7[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 459122\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=./logs/1130_model_3conv1d_dropout\" to launch tensorboard\n",
      "Train on 46663 samples, validate on 11665 samples\n",
      "Epoch 1/20\n",
      "46663/46663 [==============================] - 1438s - loss: 7.4569 - multlabel_prec: 0.0982 - multlabel_recall: 0.0444 - multlabel_F1: 0.0498 - multlabel_acc: 0.0333 - val_loss: 0.2990 - val_multlabel_prec: 0.0000e+00 - val_multlabel_recall: 0.0000e+00 - val_multlabel_F1: 0.0000e+00 - val_multlabel_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "46663/46663 [==============================] - 1438s - loss: 6.5113 - multlabel_prec: 0.1544 - multlabel_recall: 0.1146 - multlabel_F1: 0.1140 - multlabel_acc: 0.0891 - val_loss: 0.3212 - val_multlabel_prec: 0.0720 - val_multlabel_recall: 0.0244 - val_multlabel_F1: 0.0335 - val_multlabel_acc: 0.0212\n",
      "Epoch 3/20\n",
      "46663/46663 [==============================] - 1436s - loss: 6.2885 - multlabel_prec: 0.1741 - multlabel_recall: 0.1346 - multlabel_F1: 0.1340 - multlabel_acc: 0.1040 - val_loss: 0.2884 - val_multlabel_prec: 0.0956 - val_multlabel_recall: 0.0348 - val_multlabel_F1: 0.0464 - val_multlabel_acc: 0.0302\n",
      "Epoch 4/20\n",
      "46663/46663 [==============================] - 1436s - loss: 6.1541 - multlabel_prec: 0.1893 - multlabel_recall: 0.1473 - multlabel_F1: 0.1476 - multlabel_acc: 0.1155 - val_loss: 0.2795 - val_multlabel_prec: 0.0240 - val_multlabel_recall: 0.0068 - val_multlabel_F1: 0.0101 - val_multlabel_acc: 0.0066\n",
      "Epoch 5/20\n",
      "46663/46663 [==============================] - 1436s - loss: 6.0530 - multlabel_prec: 0.2170 - multlabel_recall: 0.1601 - multlabel_F1: 0.1632 - multlabel_acc: 0.1271 - val_loss: 0.2865 - val_multlabel_prec: 0.1914 - val_multlabel_recall: 0.0649 - val_multlabel_F1: 0.0873 - val_multlabel_acc: 0.0576\n",
      "Epoch 6/20\n",
      "46663/46663 [==============================] - 1434s - loss: 5.9853 - multlabel_prec: 0.2456 - multlabel_recall: 0.1728 - multlabel_F1: 0.1788 - multlabel_acc: 0.1381 - val_loss: 0.2799 - val_multlabel_prec: 0.1633 - val_multlabel_recall: 0.0556 - val_multlabel_F1: 0.0767 - val_multlabel_acc: 0.0505\n",
      "Epoch 7/20\n",
      "46663/46663 [==============================] - 1435s - loss: 5.9099 - multlabel_prec: 0.2695 - multlabel_recall: 0.1846 - multlabel_F1: 0.1933 - multlabel_acc: 0.1487 - val_loss: 0.2666 - val_multlabel_prec: 0.1650 - val_multlabel_recall: 0.0550 - val_multlabel_F1: 0.0763 - val_multlabel_acc: 0.0502\n",
      "Epoch 8/20\n",
      "46663/46663 [==============================] - 1436s - loss: 5.8537 - multlabel_prec: 0.2835 - multlabel_recall: 0.1919 - multlabel_F1: 0.2028 - multlabel_acc: 0.1557 - val_loss: 0.2686 - val_multlabel_prec: 0.2417 - val_multlabel_recall: 0.0954 - val_multlabel_F1: 0.1263 - val_multlabel_acc: 0.0830\n",
      "Epoch 9/20\n",
      "46663/46663 [==============================] - 1441s - loss: 5.8084 - multlabel_prec: 0.2937 - multlabel_recall: 0.1985 - multlabel_F1: 0.2106 - multlabel_acc: 0.1615 - val_loss: 0.2713 - val_multlabel_prec: 0.2293 - val_multlabel_recall: 0.0979 - val_multlabel_F1: 0.1243 - val_multlabel_acc: 0.0822\n",
      "Epoch 10/20\n",
      "46663/46663 [==============================] - 1437s - loss: 5.7669 - multlabel_prec: 0.3027 - multlabel_recall: 0.2032 - multlabel_F1: 0.2167 - multlabel_acc: 0.1659 - val_loss: 0.2766 - val_multlabel_prec: 0.3019 - val_multlabel_recall: 0.1438 - val_multlabel_F1: 0.1791 - val_multlabel_acc: 0.1210\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "46663/46663 [==============================] - 597s   \n",
      "[0.21446297752247404, 0.3515346914812732, 0.2496387526171637, 0.26516582468012878, 0.20175946097890213]\n",
      "evaluation on validation set:\n",
      "11665/11665 [==============================] - 149s   \n",
      "[0.27656050228633139, 0.30191867785856441, 0.14376669670193684, 0.17914246059874328, 0.12097127058962819]\n"
     ]
    }
   ],
   "source": [
    "model_3conv1d_dropout =Sequential(\n",
    "        [ Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_w2v],input_length=INPUT_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(256, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(64, 2, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_3conv1d_dropout')\n",
    "\n",
    "compile_fit_evaluate(model_3conv1d_dropout, flag_quick_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

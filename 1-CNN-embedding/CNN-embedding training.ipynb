{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, Merge, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Sequential, load_model, Model\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "from settings import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46663, 1000) (46663, 50)\n",
      "(11665, 1000) (11665, 50)\n"
     ]
    }
   ],
   "source": [
    "pk_data = pk.load(open(PK_FPATH, 'rb'))\n",
    "# print pk_data.keys()\n",
    "\n",
    "embedding_w2v = pk_data['embedding_w2v']\n",
    "embedding_glove = pk_data['embedding_glove']\n",
    "\n",
    "X_train, Y_train = pk_data['X_train'], pk_data['Y_train']\n",
    "X_val, Y_val = pk_data['X_val'], pk_data['Y_val']\n",
    "\n",
    "INPUT_SEQ_LEN = X_train.shape[1]\n",
    "EMBEDDING_INPUT_DIM = embedding_w2v.shape[0]\n",
    "\n",
    "print X_train.shape, Y_train.shape\n",
    "print X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify sample weight, and use larger batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46663,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 12.01673109,  17.46144513,   0.1048649 , ...,  15.49525083,\n",
       "        14.95808575,  43.77665432])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_freq = 1e6*Y_train.sum(axis=0)**(-1.5)\n",
    "sample_weight = (inv_freq * Y_train).sum(axis=1)\n",
    "print sample_weight.shape\n",
    "sample_weight\n",
    "# y_n_poslabels = Y_train_noother.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "reload(utils)\n",
    "from utils import multlabel_prec, multlabel_recall, multlabel_F1, multlabel_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    print 'evaluation on training set:'\n",
    "    print model.evaluate(X_train, Y_train, batch_size=128)\n",
    "    print 'evaluation on validation set:'\n",
    "    print model.evaluate(X_val, Y_val, batch_size=128)\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "# wraps up operations on models\n",
    "def compile_fit_evaluate(model, quick_test=False, print_summary=True,\n",
    "                         save_log=True, save_model=True, del_model=False):\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=[multlabel_prec, multlabel_recall, multlabel_F1, multlabel_acc])\n",
    "    if print_summary:\n",
    "        print model.summary()\n",
    "        \n",
    "    if quick_test: # use tiny data for quick testing\n",
    "        print '(quick test mode)'\n",
    "        model.fit(X_train[:100], Y_train[:100], nb_epoch=1)\n",
    "        return  \n",
    "    \n",
    "    _callbacks = [EarlyStopping(monitor='val_loss', patience=2)] \n",
    "    if save_log:\n",
    "        logdir = os.path.join( LOG_PATH, time.strftime('%m%d')+'_'+str(model.name) )\n",
    "        if not os.path.exists(logdir):\n",
    "            os.makedirs(logdir)\n",
    "        _callbacks.append(TensorBoard(log_dir=logdir))\n",
    "        print 'run \"tensorboard --logdir=%s\" to launch tensorboard'%logdir\n",
    "    \n",
    "    model.fit( X_train, Y_train, \n",
    "              validation_data=(X_val, Y_val), \n",
    "              nb_epoch=N_EPOCHS, batch_size=BATCH_SZ, \n",
    "              sample_weight = sample_weight, \n",
    "              callbacks=_callbacks )\n",
    "    \n",
    "    print 'evaluating model...'\n",
    "    evaluate_model(model)\n",
    "    \n",
    "    if save_model: \n",
    "        model_fpath = os.path.join( MODEL_PATH, time.strftime('%m%d')+'_%s.h5'% str(model.name) )\n",
    "        model.save(model_fpath)\n",
    "        print 'model is saved at %s' % model_fpath\n",
    "    \n",
    "    if del_model:\n",
    "        del model # delete the model to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model: 2 conv layers and 2 FC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag_quick_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 1000, 200)     20000200    main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 1000, 200)     20000200    main_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 996, 128)      128128      embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_9 (Convolution1D)  (None, 996, 128)      128128      embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 996, 128)      0           convolution1d_8[0][0]            \n",
      "                                                                   convolution1d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_7 (MaxPooling1D)    (None, 199, 128)      0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_10 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_8 (MaxPooling1D)    (None, 39, 128)       0           convolution1d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 4992)          0           maxpooling1d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 4992)          0           flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 500)           2496500     dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 500)           0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 500)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 50)            25050       dropout_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 42,860,254\n",
      "Trainable params: 2,859,854\n",
      "Non-trainable params: 40,000,400\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=../logs/0206_model_2embed_2conv1d_2FC\" to launch tensorboard\n",
      "Train on 46663 samples, validate on 11665 samples\n",
      "Epoch 1/20\n",
      "46663/46663 [==============================] - 1070s - loss: 7.5281 - multlabel_prec: 0.1593 - multlabel_recall: 0.1046 - multlabel_F1: 0.1032 - multlabel_acc: 0.0757 - val_loss: 0.2874 - val_multlabel_prec: 0.0000e+00 - val_multlabel_recall: 0.0000e+00 - val_multlabel_F1: 0.0000e+00 - val_multlabel_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "46663/46663 [==============================] - 1041s - loss: 6.4396 - multlabel_prec: 0.1578 - multlabel_recall: 0.1256 - multlabel_F1: 0.1226 - multlabel_acc: 0.0976 - val_loss: 0.2971 - val_multlabel_prec: 0.1286 - val_multlabel_recall: 0.0292 - val_multlabel_F1: 0.0445 - val_multlabel_acc: 0.0279\n",
      "Epoch 3/20\n",
      "46663/46663 [==============================] - 1025s - loss: 6.1168 - multlabel_prec: 0.2749 - multlabel_recall: 0.1813 - multlabel_F1: 0.1922 - multlabel_acc: 0.1471 - val_loss: 0.2755 - val_multlabel_prec: 0.3143 - val_multlabel_recall: 0.1225 - val_multlabel_F1: 0.1647 - val_multlabel_acc: 0.1101\n",
      "Epoch 4/20\n",
      "46663/46663 [==============================] - 972s - loss: 5.8554 - multlabel_prec: 0.3289 - multlabel_recall: 0.2144 - multlabel_F1: 0.2313 - multlabel_acc: 0.1752 - val_loss: 0.2613 - val_multlabel_prec: 0.2141 - val_multlabel_recall: 0.0727 - val_multlabel_F1: 0.1020 - val_multlabel_acc: 0.0664\n",
      "Epoch 5/20\n",
      "46663/46663 [==============================] - 959s - loss: 5.7168 - multlabel_prec: 0.3625 - multlabel_recall: 0.2323 - multlabel_F1: 0.2537 - multlabel_acc: 0.1922 - val_loss: 0.2584 - val_multlabel_prec: 0.2613 - val_multlabel_recall: 0.0931 - val_multlabel_F1: 0.1293 - val_multlabel_acc: 0.0854\n",
      "Epoch 6/20\n",
      "46663/46663 [==============================] - 955s - loss: 5.5883 - multlabel_prec: 0.3878 - multlabel_recall: 0.2436 - multlabel_F1: 0.2683 - multlabel_acc: 0.2027 - val_loss: 0.2539 - val_multlabel_prec: 0.3701 - val_multlabel_recall: 0.1492 - val_multlabel_F1: 0.1983 - val_multlabel_acc: 0.1366\n",
      "Epoch 7/20\n",
      "46663/46663 [==============================] - 1023s - loss: 5.4980 - multlabel_prec: 0.4091 - multlabel_recall: 0.2540 - multlabel_F1: 0.2815 - multlabel_acc: 0.2128 - val_loss: 0.2555 - val_multlabel_prec: 0.3182 - val_multlabel_recall: 0.1297 - val_multlabel_F1: 0.1716 - val_multlabel_acc: 0.1169\n",
      "Epoch 8/20\n",
      "46663/46663 [==============================] - 1011s - loss: 5.4014 - multlabel_prec: 0.4190 - multlabel_recall: 0.2611 - multlabel_F1: 0.2899 - multlabel_acc: 0.2188 - val_loss: 0.2490 - val_multlabel_prec: 0.3825 - val_multlabel_recall: 0.1517 - val_multlabel_F1: 0.2033 - val_multlabel_acc: 0.1394\n",
      "Epoch 9/20\n",
      "46663/46663 [==============================] - 1007s - loss: 5.3253 - multlabel_prec: 0.4297 - multlabel_recall: 0.2699 - multlabel_F1: 0.2991 - multlabel_acc: 0.2261 - val_loss: 0.2525 - val_multlabel_prec: 0.3539 - val_multlabel_recall: 0.1450 - val_multlabel_F1: 0.1921 - val_multlabel_acc: 0.1306\n",
      "Epoch 10/20\n",
      "46663/46663 [==============================] - 1014s - loss: 5.2382 - multlabel_prec: 0.4427 - multlabel_recall: 0.2782 - multlabel_F1: 0.3086 - multlabel_acc: 0.2330 - val_loss: 0.2515 - val_multlabel_prec: 0.3896 - val_multlabel_recall: 0.1839 - val_multlabel_F1: 0.2313 - val_multlabel_acc: 0.1607\n",
      "Epoch 11/20\n",
      "46663/46663 [==============================] - 951s - loss: 5.1617 - multlabel_prec: 0.4551 - multlabel_recall: 0.2877 - multlabel_F1: 0.3189 - multlabel_acc: 0.2409 - val_loss: 0.2481 - val_multlabel_prec: 0.3904 - val_multlabel_recall: 0.1876 - val_multlabel_F1: 0.2345 - val_multlabel_acc: 0.1629\n",
      "Epoch 12/20\n",
      "46663/46663 [==============================] - 989s - loss: 5.0727 - multlabel_prec: 0.4628 - multlabel_recall: 0.2957 - multlabel_F1: 0.3273 - multlabel_acc: 0.2476 - val_loss: 0.2476 - val_multlabel_prec: 0.4135 - val_multlabel_recall: 0.1743 - val_multlabel_F1: 0.2276 - val_multlabel_acc: 0.1568\n",
      "Epoch 13/20\n",
      "46663/46663 [==============================] - 985s - loss: 4.9868 - multlabel_prec: 0.4758 - multlabel_recall: 0.3069 - multlabel_F1: 0.3390 - multlabel_acc: 0.2565 - val_loss: 0.2447 - val_multlabel_prec: 0.4485 - val_multlabel_recall: 0.2019 - val_multlabel_F1: 0.2591 - val_multlabel_acc: 0.1808\n",
      "Epoch 14/20\n",
      "46663/46663 [==============================] - 1002s - loss: 4.9081 - multlabel_prec: 0.4857 - multlabel_recall: 0.3162 - multlabel_F1: 0.3488 - multlabel_acc: 0.2640 - val_loss: 0.2465 - val_multlabel_prec: 0.4712 - val_multlabel_recall: 0.2217 - val_multlabel_F1: 0.2795 - val_multlabel_acc: 0.1951\n",
      "Epoch 15/20\n",
      "46663/46663 [==============================] - 1013s - loss: 4.8225 - multlabel_prec: 0.4955 - multlabel_recall: 0.3269 - multlabel_F1: 0.3599 - multlabel_acc: 0.2731 - val_loss: 0.2458 - val_multlabel_prec: 0.4443 - val_multlabel_recall: 0.2054 - val_multlabel_F1: 0.2597 - val_multlabel_acc: 0.1802\n",
      "Epoch 16/20\n",
      "46663/46663 [==============================] - 1011s - loss: 4.7484 - multlabel_prec: 0.5005 - multlabel_recall: 0.3336 - multlabel_F1: 0.3668 - multlabel_acc: 0.2786 - val_loss: 0.2459 - val_multlabel_prec: 0.4394 - val_multlabel_recall: 0.2173 - val_multlabel_F1: 0.2693 - val_multlabel_acc: 0.1876\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "46663/46663 [==============================] - 377s   \n",
      "[0.16652846115416384, 0.53968577214116908, 0.34604143074628047, 0.38958340002143976, 0.29846883581393741]\n",
      "evaluation on validation set:\n",
      "11665/11665 [==============================] - 101s   \n",
      "[0.24587731805166563, 0.4394286318086934, 0.21731284905338411, 0.26929296140143455, 0.187640779173226]\n",
      "model is saved at ../models/0206_model_2embed_2conv1d_2FC.h5\n"
     ]
    }
   ],
   "source": [
    "embed1_w2v = Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_w2v],input_length=INPUT_SEQ_LEN, trainable=False )\n",
    "embed2_glove = Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_glove],input_length=INPUT_SEQ_LEN, trainable=False )\n",
    "\n",
    "input_layer = Input(shape=(INPUT_SEQ_LEN,), dtype='int32', name='main_input')\n",
    "\n",
    "embed1 = embed1_w2v(input_layer)\n",
    "conv_embed1 = Conv1D(128, 5, activation='relu')(embed1)\n",
    "\n",
    "embed2 = embed2_glove(input_layer)\n",
    "conv_embed2 = Conv1D(128, 5, activation='relu')(embed2)\n",
    "\n",
    "from keras.layers import merge # `Merge` is for model, while `merge` is for tensor.\n",
    "merge_layer = merge([conv_embed1, conv_embed2], mode='sum')\n",
    "\n",
    "x = MaxPooling1D(5)(merge_layer)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(p=0.5)(x)\n",
    "x = Dense(500)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(p=0.5)(x)\n",
    "output_layer = Dense(N_LABELS, activation='sigmoid')(x)\n",
    "\n",
    "model_2embed_2conv1d_2FC = Model(input=input_layer, output=output_layer, \n",
    "                                 name = 'model_2embed_2conv1d_2FC')\n",
    "\n",
    "compile_fit_evaluate(model_2embed_2conv1d_2FC, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_7 (Embedding)          (None, 1000, 200)     20000200    embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_11 (Convolution1D) (None, 996, 128)      128128      embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_9 (MaxPooling1D)    (None, 199, 128)      0           convolution1d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_12 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_10 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 4992)          0           maxpooling1d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 4992)          0           flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 500)           2496500     dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 500)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 500)           0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 50)            25050       dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 22,731,926\n",
      "Trainable params: 2,731,726\n",
      "Non-trainable params: 20,000,200\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=../logs/0206_model_2conv1d_2FC\" to launch tensorboard\n",
      "Train on 46663 samples, validate on 11665 samples\n",
      "Epoch 1/20\n",
      "46663/46663 [==============================] - 556s - loss: 7.2952 - multlabel_prec: 0.1358 - multlabel_recall: 0.0777 - multlabel_F1: 0.0817 - multlabel_acc: 0.0596 - val_loss: 0.2891 - val_multlabel_prec: 0.0000e+00 - val_multlabel_recall: 0.0000e+00 - val_multlabel_F1: 0.0000e+00 - val_multlabel_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "46663/46663 [==============================] - 525s - loss: 6.3951 - multlabel_prec: 0.1482 - multlabel_recall: 0.1216 - multlabel_F1: 0.1182 - multlabel_acc: 0.0950 - val_loss: 0.2888 - val_multlabel_prec: 0.0000e+00 - val_multlabel_recall: 0.0000e+00 - val_multlabel_F1: 0.0000e+00 - val_multlabel_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "46663/46663 [==============================] - 522s - loss: 6.1475 - multlabel_prec: 0.2176 - multlabel_recall: 0.1566 - multlabel_F1: 0.1603 - multlabel_acc: 0.1252 - val_loss: 0.2839 - val_multlabel_prec: 0.2778 - val_multlabel_recall: 0.1305 - val_multlabel_F1: 0.1646 - val_multlabel_acc: 0.1085\n",
      "Epoch 4/20\n",
      "46663/46663 [==============================] - 507s - loss: 5.9079 - multlabel_prec: 0.2978 - multlabel_recall: 0.1992 - multlabel_F1: 0.2123 - multlabel_acc: 0.1618 - val_loss: 0.2728 - val_multlabel_prec: 0.2541 - val_multlabel_recall: 0.1044 - val_multlabel_F1: 0.1369 - val_multlabel_acc: 0.0895\n",
      "Epoch 5/20\n",
      "46663/46663 [==============================] - 501s - loss: 5.7744 - multlabel_prec: 0.3301 - multlabel_recall: 0.2164 - multlabel_F1: 0.2339 - multlabel_acc: 0.1780 - val_loss: 0.2584 - val_multlabel_prec: 0.2360 - val_multlabel_recall: 0.0801 - val_multlabel_F1: 0.1126 - val_multlabel_acc: 0.0740\n",
      "Epoch 6/20\n",
      "46663/46663 [==============================] - 506s - loss: 5.6797 - multlabel_prec: 0.3565 - multlabel_recall: 0.2309 - multlabel_F1: 0.2518 - multlabel_acc: 0.1912 - val_loss: 0.2541 - val_multlabel_prec: 0.3256 - val_multlabel_recall: 0.1220 - val_multlabel_F1: 0.1655 - val_multlabel_acc: 0.1140\n",
      "Epoch 7/20\n",
      "46663/46663 [==============================] - 514s - loss: 5.5933 - multlabel_prec: 0.3811 - multlabel_recall: 0.2424 - multlabel_F1: 0.2662 - multlabel_acc: 0.2018 - val_loss: 0.2537 - val_multlabel_prec: 0.3472 - val_multlabel_recall: 0.1286 - val_multlabel_F1: 0.1760 - val_multlabel_acc: 0.1195\n",
      "Epoch 8/20\n",
      "46663/46663 [==============================] - 557s - loss: 5.5131 - multlabel_prec: 0.4022 - multlabel_recall: 0.2509 - multlabel_F1: 0.2776 - multlabel_acc: 0.2103 - val_loss: 0.2599 - val_multlabel_prec: 0.3507 - val_multlabel_recall: 0.1525 - val_multlabel_F1: 0.1986 - val_multlabel_acc: 0.1334\n",
      "Epoch 9/20\n",
      "46663/46663 [==============================] - 583s - loss: 5.4309 - multlabel_prec: 0.4163 - multlabel_recall: 0.2595 - multlabel_F1: 0.2878 - multlabel_acc: 0.2180 - val_loss: 0.2497 - val_multlabel_prec: 0.3805 - val_multlabel_recall: 0.1348 - val_multlabel_F1: 0.1867 - val_multlabel_acc: 0.1266\n",
      "Epoch 10/20\n",
      "46663/46663 [==============================] - 515s - loss: 5.3606 - multlabel_prec: 0.4332 - multlabel_recall: 0.2678 - multlabel_F1: 0.2985 - multlabel_acc: 0.2261 - val_loss: 0.2483 - val_multlabel_prec: 0.3924 - val_multlabel_recall: 0.1626 - val_multlabel_F1: 0.2147 - val_multlabel_acc: 0.1464\n",
      "Epoch 11/20\n",
      "46663/46663 [==============================] - 495s - loss: 5.2916 - multlabel_prec: 0.4417 - multlabel_recall: 0.2765 - multlabel_F1: 0.3074 - multlabel_acc: 0.2330 - val_loss: 0.2556 - val_multlabel_prec: 0.4022 - val_multlabel_recall: 0.1954 - val_multlabel_F1: 0.2433 - val_multlabel_acc: 0.1679\n",
      "Epoch 12/20\n",
      "46663/46663 [==============================] - 482s - loss: 5.2232 - multlabel_prec: 0.4496 - multlabel_recall: 0.2827 - multlabel_F1: 0.3142 - multlabel_acc: 0.2379 - val_loss: 0.2490 - val_multlabel_prec: 0.4298 - val_multlabel_recall: 0.2118 - val_multlabel_F1: 0.2623 - val_multlabel_acc: 0.1838\n",
      "Epoch 13/20\n",
      "46663/46663 [==============================] - 483s - loss: 5.1557 - multlabel_prec: 0.4617 - multlabel_recall: 0.2922 - multlabel_F1: 0.3248 - multlabel_acc: 0.2464 - val_loss: 0.2432 - val_multlabel_prec: 0.4047 - val_multlabel_recall: 0.1740 - val_multlabel_F1: 0.2261 - val_multlabel_acc: 0.1563\n",
      "Epoch 14/20\n",
      "46663/46663 [==============================] - 483s - loss: 5.0943 - multlabel_prec: 0.4661 - multlabel_recall: 0.2989 - multlabel_F1: 0.3311 - multlabel_acc: 0.2510 - val_loss: 0.2470 - val_multlabel_prec: 0.4268 - val_multlabel_recall: 0.1708 - val_multlabel_F1: 0.2275 - val_multlabel_acc: 0.1562\n",
      "Epoch 15/20\n",
      "46663/46663 [==============================] - 484s - loss: 5.0304 - multlabel_prec: 0.4764 - multlabel_recall: 0.3054 - multlabel_F1: 0.3388 - multlabel_acc: 0.2571 - val_loss: 0.2483 - val_multlabel_prec: 0.4436 - val_multlabel_recall: 0.1953 - val_multlabel_F1: 0.2524 - val_multlabel_acc: 0.1747\n",
      "Epoch 16/20\n",
      "46663/46663 [==============================] - 490s - loss: 4.9650 - multlabel_prec: 0.4844 - multlabel_recall: 0.3145 - multlabel_F1: 0.3478 - multlabel_acc: 0.2641 - val_loss: 0.2474 - val_multlabel_prec: 0.4109 - val_multlabel_recall: 0.1710 - val_multlabel_F1: 0.2242 - val_multlabel_acc: 0.1537\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "46663/46663 [==============================] - 180s   \n",
      "[0.17403738800281141, 0.4898231782293288, 0.30089873133508521, 0.33915232212476093, 0.25939148784895977]\n",
      "evaluation on validation set:\n",
      "11665/11665 [==============================] - 45s    \n",
      "[0.24744754086555557, 0.41085165574527122, 0.17096864177825061, 0.22416714344778849, 0.15372788752295458]\n",
      "model is saved at ../models/0206_model_2conv1d_2FC.h5\n"
     ]
    }
   ],
   "source": [
    "model_2conv1d_2FC = Sequential(\n",
    "       [Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_w2v],input_length=INPUT_SEQ_LEN, trainable=False ),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(5),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(5),\n",
    "        Flatten(),\n",
    "        Dropout(p=0.5),\n",
    "        Dense(500),\n",
    "        Activation('relu'),\n",
    "        Dropout(p=0.5),\n",
    "        Dense(N_LABELS, activation='sigmoid') \n",
    "       ], name = 'model_2conv1d_2FC')\n",
    "compile_fit_evaluate(model_2conv1d_2FC, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_8 (Embedding)          (None, 1000, 200)     20000200    embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_13 (Convolution1D) (None, 996, 128)      128128      embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_11 (MaxPooling1D)   (None, 199, 128)      0           convolution1d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_14 (Convolution1D) (None, 195, 128)      82048       maxpooling1d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_12 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 4992)          0           maxpooling1d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 4992)          0           flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 500)           2496500     dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 500)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 500)           0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 50)            25050       dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 22,731,926\n",
      "Trainable params: 2,731,726\n",
      "Non-trainable params: 20,000,200\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "run \"tensorboard --logdir=../logs/0206_model_2conv1d_2FC_glove\" to launch tensorboard\n",
      "Train on 46663 samples, validate on 11665 samples\n",
      "Epoch 1/20\n",
      "46663/46663 [==============================] - 503s - loss: 7.3215 - multlabel_prec: 0.1552 - multlabel_recall: 0.0989 - multlabel_F1: 0.1006 - multlabel_acc: 0.0748 - val_loss: 0.3142 - val_multlabel_prec: 0.0000e+00 - val_multlabel_recall: 0.0000e+00 - val_multlabel_F1: 0.0000e+00 - val_multlabel_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "46663/46663 [==============================] - 501s - loss: 6.4244 - multlabel_prec: 0.1453 - multlabel_recall: 0.1203 - multlabel_F1: 0.1166 - multlabel_acc: 0.0939 - val_loss: 0.2912 - val_multlabel_prec: 0.0000e+00 - val_multlabel_recall: 0.0000e+00 - val_multlabel_F1: 0.0000e+00 - val_multlabel_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "46663/46663 [==============================] - 501s - loss: 6.2597 - multlabel_prec: 0.1517 - multlabel_recall: 0.1318 - multlabel_F1: 0.1269 - multlabel_acc: 0.1035 - val_loss: 0.2855 - val_multlabel_prec: 0.0950 - val_multlabel_recall: 0.0332 - val_multlabel_F1: 0.0468 - val_multlabel_acc: 0.0310\n",
      "Epoch 4/20\n",
      "46663/46663 [==============================] - 502s - loss: 6.0815 - multlabel_prec: 0.2124 - multlabel_recall: 0.1631 - multlabel_F1: 0.1655 - multlabel_acc: 0.1304 - val_loss: 0.3072 - val_multlabel_prec: 0.2565 - val_multlabel_recall: 0.1221 - val_multlabel_F1: 0.1476 - val_multlabel_acc: 0.0964\n",
      "Epoch 5/20\n",
      "46663/46663 [==============================] - 505s - loss: 5.9377 - multlabel_prec: 0.2749 - multlabel_recall: 0.1875 - multlabel_F1: 0.1978 - multlabel_acc: 0.1526 - val_loss: 0.2676 - val_multlabel_prec: 0.2457 - val_multlabel_recall: 0.0937 - val_multlabel_F1: 0.1256 - val_multlabel_acc: 0.0840\n",
      "Epoch 6/20\n",
      "46663/46663 [==============================] - 508s - loss: 5.8117 - multlabel_prec: 0.3213 - multlabel_recall: 0.2123 - multlabel_F1: 0.2288 - multlabel_acc: 0.1745 - val_loss: 0.2661 - val_multlabel_prec: 0.2351 - val_multlabel_recall: 0.0900 - val_multlabel_F1: 0.1222 - val_multlabel_acc: 0.0809\n",
      "Epoch 7/20\n",
      "46663/46663 [==============================] - 508s - loss: 5.7035 - multlabel_prec: 0.3406 - multlabel_recall: 0.2227 - multlabel_F1: 0.2419 - multlabel_acc: 0.1841 - val_loss: 0.2678 - val_multlabel_prec: 0.2767 - val_multlabel_recall: 0.1106 - val_multlabel_F1: 0.1481 - val_multlabel_acc: 0.0974\n",
      "Epoch 8/20\n",
      "46663/46663 [==============================] - 508s - loss: 5.6216 - multlabel_prec: 0.3589 - multlabel_recall: 0.2334 - multlabel_F1: 0.2549 - multlabel_acc: 0.1938 - val_loss: 0.2625 - val_multlabel_prec: 0.2727 - val_multlabel_recall: 0.1048 - val_multlabel_F1: 0.1428 - val_multlabel_acc: 0.0929\n",
      "Epoch 9/20\n",
      "46663/46663 [==============================] - 508s - loss: 5.5390 - multlabel_prec: 0.3821 - multlabel_recall: 0.2444 - multlabel_F1: 0.2685 - multlabel_acc: 0.2035 - val_loss: 0.2593 - val_multlabel_prec: 0.3288 - val_multlabel_recall: 0.1287 - val_multlabel_F1: 0.1726 - val_multlabel_acc: 0.1180\n",
      "Epoch 10/20\n",
      "46663/46663 [==============================] - 508s - loss: 5.4679 - multlabel_prec: 0.3936 - multlabel_recall: 0.2494 - multlabel_F1: 0.2750 - multlabel_acc: 0.2084 - val_loss: 0.2604 - val_multlabel_prec: 0.3515 - val_multlabel_recall: 0.1590 - val_multlabel_F1: 0.2030 - val_multlabel_acc: 0.1407\n",
      "Epoch 11/20\n",
      "46663/46663 [==============================] - 513s - loss: 5.3945 - multlabel_prec: 0.4059 - multlabel_recall: 0.2575 - multlabel_F1: 0.2842 - multlabel_acc: 0.2152 - val_loss: 0.2606 - val_multlabel_prec: 0.3472 - val_multlabel_recall: 0.1437 - val_multlabel_F1: 0.1876 - val_multlabel_acc: 0.1277\n",
      "Epoch 12/20\n",
      "46663/46663 [==============================] - 513s - loss: 5.3341 - multlabel_prec: 0.4175 - multlabel_recall: 0.2647 - multlabel_F1: 0.2926 - multlabel_acc: 0.2215 - val_loss: 0.2548 - val_multlabel_prec: 0.2902 - val_multlabel_recall: 0.1018 - val_multlabel_F1: 0.1413 - val_multlabel_acc: 0.0935\n",
      "Epoch 13/20\n",
      "46663/46663 [==============================] - 515s - loss: 5.2731 - multlabel_prec: 0.4273 - multlabel_recall: 0.2707 - multlabel_F1: 0.2998 - multlabel_acc: 0.2270 - val_loss: 0.2526 - val_multlabel_prec: 0.3621 - val_multlabel_recall: 0.1480 - val_multlabel_F1: 0.1950 - val_multlabel_acc: 0.1330\n",
      "Epoch 14/20\n",
      "46663/46663 [==============================] - 515s - loss: 5.2142 - multlabel_prec: 0.4356 - multlabel_recall: 0.2757 - multlabel_F1: 0.3054 - multlabel_acc: 0.2312 - val_loss: 0.2539 - val_multlabel_prec: 0.4081 - val_multlabel_recall: 0.1774 - val_multlabel_F1: 0.2292 - val_multlabel_acc: 0.1581\n",
      "Epoch 15/20\n",
      "46663/46663 [==============================] - 516s - loss: 5.1429 - multlabel_prec: 0.4473 - multlabel_recall: 0.2840 - multlabel_F1: 0.3145 - multlabel_acc: 0.2381 - val_loss: 0.2591 - val_multlabel_prec: 0.3833 - val_multlabel_recall: 0.1657 - val_multlabel_F1: 0.2150 - val_multlabel_acc: 0.1466\n",
      "Epoch 16/20\n",
      "46663/46663 [==============================] - 513s - loss: 5.0840 - multlabel_prec: 0.4547 - multlabel_recall: 0.2911 - multlabel_F1: 0.3219 - multlabel_acc: 0.2439 - val_loss: 0.2487 - val_multlabel_prec: 0.3562 - val_multlabel_recall: 0.1444 - val_multlabel_F1: 0.1907 - val_multlabel_acc: 0.1304\n",
      "Epoch 17/20\n",
      "46663/46663 [==============================] - 512s - loss: 5.0157 - multlabel_prec: 0.4655 - multlabel_recall: 0.2988 - multlabel_F1: 0.3306 - multlabel_acc: 0.2507 - val_loss: 0.2500 - val_multlabel_prec: 0.3991 - val_multlabel_recall: 0.1781 - val_multlabel_F1: 0.2273 - val_multlabel_acc: 0.1581\n",
      "Epoch 18/20\n",
      "46663/46663 [==============================] - 509s - loss: 4.9469 - multlabel_prec: 0.4703 - multlabel_recall: 0.3048 - multlabel_F1: 0.3364 - multlabel_acc: 0.2547 - val_loss: 0.2528 - val_multlabel_prec: 0.4070 - val_multlabel_recall: 0.1978 - val_multlabel_F1: 0.2465 - val_multlabel_acc: 0.1701\n",
      "Epoch 19/20\n",
      "46663/46663 [==============================] - 509s - loss: 4.8976 - multlabel_prec: 0.4788 - multlabel_recall: 0.3133 - multlabel_F1: 0.3451 - multlabel_acc: 0.2613 - val_loss: 0.2590 - val_multlabel_prec: 0.4349 - val_multlabel_recall: 0.2315 - val_multlabel_F1: 0.2791 - val_multlabel_acc: 0.1940\n",
      "evaluating model...\n",
      "evaluation on training set:\n",
      "46663/46663 [==============================] - 179s   \n",
      "[0.17775070713538588, 0.52714616636146938, 0.37421303902495889, 0.40126660312976892, 0.306823183081397]\n",
      "evaluation on validation set:\n",
      "11665/11665 [==============================] - 44s    \n",
      "[0.25904770811969408, 0.43491434626348324, 0.23145870327489651, 0.27911289843989706, 0.19400181738389086]\n",
      "model is saved at ../models/0206_model_2conv1d_2FC_glove.h5\n"
     ]
    }
   ],
   "source": [
    "model_2conv1d_2FC_glove = Sequential(\n",
    "       [Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_glove],input_length=INPUT_SEQ_LEN, trainable=False ),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(5),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(5),\n",
    "        Flatten(),\n",
    "        Dropout(p=0.5),\n",
    "        Dense(500),\n",
    "        Activation('relu'),\n",
    "        Dropout(p=0.5),\n",
    "        Dense(N_LABELS, activation='sigmoid') \n",
    "       ], name = 'model_2conv1d_2FC_glove')\n",
    "compile_fit_evaluate(model_2conv1d_2FC_glove, flag_quick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_10 (Embedding)         (None, 1000, 200)     4000200     embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_19 (Convolution1D) (None, 996, 256)      256256      embedding_10[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_16 (MaxPooling1D)   (None, 199, 256)      0           convolution1d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_20 (Convolution1D) (None, 195, 128)      163968      maxpooling1d_16[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_17 (MaxPooling1D)   (None, 39, 128)       0           convolution1d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_21 (Convolution1D) (None, 38, 64)        16448       maxpooling1d_17[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_18 (MaxPooling1D)   (None, 7, 64)         0           convolution1d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 448)           0           maxpooling1d_18[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 448)           0           flatten_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 50)            22450       dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4,459,322\n",
      "Trainable params: 459,122\n",
      "Non-trainable params: 4,000,200\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "(quick test mode)\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s - loss: 0.5522 - multlabel_prec: 0.0552 - multlabel_recall: 0.1725 - multlabel_F1: 0.0723 - multlabel_acc: 0.0415     \n"
     ]
    }
   ],
   "source": [
    "model_3conv1d_dropout =Sequential(\n",
    "        [ Embedding(input_dim=EMBEDDING_INPUT_DIM ,output_dim=EMBEDDING_DIM, \n",
    "                  weights=[embedding_w2v],input_length=INPUT_SEQ_LEN, trainable=False ),\n",
    "            Conv1D(256, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(128, 5, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Conv1D(64, 2, activation='relu'),\n",
    "            MaxPooling1D(5),\n",
    "            Flatten(),\n",
    "            Dropout(p=0.5),\n",
    "            Dense(N_LABELS, activation='sigmoid') ],\n",
    "        name = 'model_3conv1d_dropout')\n",
    "\n",
    "compile_fit_evaluate(model_3conv1d_dropout, flag_quick_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

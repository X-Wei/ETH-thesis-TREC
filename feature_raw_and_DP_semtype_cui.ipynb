{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating raw feature Xraw, using (semtype,cui) pair and output k-hot encoding raw features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOTE_DATA_DIR = '/local/XW/DATA/MIMIC/noteevents_by_sid/'\n",
    "UMLS_DATA_DIR = '/local/XW/DATA/MIMIC/UMLS_by_sid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nin UMLS_DATA_DIR, each .pk file contains a list, each element in list corresponds to a noteevent\\n\\neach noteevent is represented as a list of lists of dicts (one list per sentence?), \\nthe concepts are stored in the dicts\\n\\nCUI: The Concept Unique Identifier\\nsemtype: Semantic Type - One of the broad categories \\n\\nsee: https://www.nlm.nih.gov/research/umls/new_users/online_learning/glossary.html\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "in UMLS_DATA_DIR, each .pk file contains a list, each element in list corresponds to a noteevent\n",
    "\n",
    "each noteevent is represented as a list of lists of dicts (one list per sentence?), \n",
    "the concepts are stored in the dicts\n",
    "\n",
    "CUI: The Concept Unique Identifier\n",
    "semtype: Semantic Type - One of the broad categories \n",
    "\n",
    "see: https://www.nlm.nih.gov/research/umls/new_users/online_learning/glossary.html\n",
    "'''\n",
    "# example:\n",
    "# with open(os.path.join(UMLS_DATA_DIR, '2.pk')) as f:\n",
    "#     example = pk.load(f)\n",
    "#     pprint(example,indent=2, depth=3)\n",
    "#     pprint(example[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46146"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(UMLS_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46146/46146 [40:52<00:00, 18.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_cui_semtype_pair = set()\n",
    "for fn in tqdm(os.listdir(UMLS_DATA_DIR)[:]):\n",
    "    fpath = os.path.join(UMLS_DATA_DIR, fn)\n",
    "    with open(fpath) as f:\n",
    "        concepts_per_sid = pk.load(f)\n",
    "        for concepts_per_note in concepts_per_sid:\n",
    "            for concept_per_sentence in concepts_per_note:\n",
    "                for concept in concept_per_sentence:\n",
    "                    cui = concept['cui']\n",
    "                    for st in concept['semtypes']:\n",
    "                        unique_cui_semtype_pair.add((st,cui))\n",
    "print len(unique_cui_semtype_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0 \n",
    "concept2id = {} # each \"concept\" is a (semtype,cui) pair\n",
    "for c in unique_cui_semtype_pair:\n",
    "    concept2id[c] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46146/46146 [1:12:11<00:00, 10.65it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "sids = []\n",
    "i = 0\n",
    "for fn in tqdm(os.listdir(UMLS_DATA_DIR)[:]):\n",
    "    x = set()\n",
    "    sid = int(fn[:-3])\n",
    "    sids.append(sid); i+=1\n",
    "    fpath = os.path.join(UMLS_DATA_DIR, fn)\n",
    "    with open(fpath) as f:\n",
    "        concepts_per_sid = pk.load(f)\n",
    "        for concepts_per_note in concepts_per_sid:\n",
    "            for concept_per_sentence in concepts_per_note:\n",
    "                for concept in concept_per_sentence:\n",
    "                    cui = concept['cui']\n",
    "                    for st in concept['semtypes']:\n",
    "                        concept = (st, cui)\n",
    "                        x.add(concept2id[concept])\n",
    "    X.append(list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46146, 69574)\n",
      "[    2     3     4 ..., 99992 99995 99999]\n"
     ]
    }
   ],
   "source": [
    "# turn X into sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "data, rows, cols = [], [], []\n",
    "for r in xrange(len(X)):\n",
    "    for c in X[r]:\n",
    "        rows.append(r)\n",
    "        cols.append(c)\n",
    "        data.append(1.0)\n",
    "X = csr_matrix((data, (rows, cols)))\n",
    "print X.shape\n",
    "sids = np.array(sids)\n",
    "print sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90.0, 1419.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].sum(), X[1].sum() # 1st and 2nd row, corresponds to sid=2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle X's rows (sids are to be shuffled too)\n",
    "shuffle_index = np.arange(X.shape[0])\n",
    "np.random.shuffle(shuffle_index)\n",
    "X = X[shuffle_index]\n",
    "sids = sids[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sid2rowidx = {} # map sid(int) to the row index in the (shuffled) raw feature matrix X\n",
    "for sid,rowidx in zip(sids, range(len(sids))):\n",
    "    sid2rowidx[sid] = rowidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90.0, 1419.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[sid2rowidx[2]].sum(), X[sid2rowidx[3]].sum() # check the mapping is correct..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OUT_FILENAME = './data/umls_raw_features.pk'\n",
    "# data_to_pickle ={\n",
    "#     'X_raw': X,\n",
    "#     'unique_concepts': unique_concepts,\n",
    "#     'unique_semtypes': unique_semtypes,\n",
    "#     'concept2id': concept2id,\n",
    "#     'sid2rowidx': sid2rowidx \n",
    "# }\n",
    "# with open(OUT_FILENAME,'wb') as f:\n",
    "#     pk.dump(data_to_pickle, f, pk.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46146"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sid2rowidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xraw = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import Callback, EarlyStopping, TensorBoard\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENCODING_DIM = 500\n",
    "INPUT_DIM = Xraw.shape[-1]\n",
    "NOISE_PORTION = 0.5 # randomly mask protion\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SZ = 128\n",
    "NB_EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_raw = Input(shape=(INPUT_DIM,))\n",
    "hiddenlayer = Dense(ENCODING_DIM, activation='relu')\n",
    "outputlayer = Dense(INPUT_DIM, activation='sigmoid')\n",
    "\n",
    "encoded = hiddenlayer(input_raw)\n",
    "decoded = outputlayer(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_raw, output=decoded, name='autoencoder')\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(X):\n",
    "    nb_masked = int(INPUT_DIM*NOISE_PORTION)\n",
    "    masks = []\n",
    "    mask = [0]*nb_masked+[1]*(INPUT_DIM-nb_masked)\n",
    "    for i in xrange(X.shape[0]):\n",
    "        np.random.shuffle(mask)\n",
    "        masks.append(mask)\n",
    "    masks = np.array(masks)\n",
    "    X_noisy = X * masks\n",
    "    return X_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, batch_size=BATCH_SZ): \n",
    "    # from sparse X, generate dense x_batch and x_batch_noisy\n",
    "    shuffle_index = np.arange(X.shape[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    X =  X[shuffle_index, :]\n",
    "    samples_per_epoch = X.shape[0]\n",
    "    number_of_batches = samples_per_epoch//batch_size\n",
    "    counter=0\n",
    "    while 1:\n",
    "        offset = batch_size*counter\n",
    "        index_batch = shuffle_index[offset: min(samples_per_epoch, offset+batch_size)]\n",
    "        X_batch = X[index_batch,:].toarray()\n",
    "        X_batch_noisy = add_noise(X_batch)\n",
    "        counter += 1\n",
    "        if (counter >= number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0\n",
    "        yield ( X_batch_noisy, X_batch ) # X: corrupted (input), y: original (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864, 69574) (9282, 69574)\n"
     ]
    }
   ],
   "source": [
    "train_sz = int(Xraw.shape[0]*(1-VALIDATION_SPLIT))\n",
    "train_sz = (train_sz//BATCH_SZ) * BATCH_SZ # make train_sz divisible by BATCH_SX\n",
    "X_train = Xraw[:train_sz]\n",
    "X_val = Xraw[train_sz:]\n",
    "print X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "36864/36864 [==============================] - 687s - loss: 0.6597 - val_loss: 0.4714\n",
      "Epoch 2/50\n",
      "36864/36864 [==============================] - 676s - loss: 0.1994 - val_loss: 0.1058\n",
      "Epoch 3/50\n",
      "36864/36864 [==============================] - 677s - loss: 0.0897 - val_loss: 0.0804\n",
      "Epoch 4/50\n",
      "36864/36864 [==============================] - 687s - loss: 0.0743 - val_loss: 0.0707\n",
      "Epoch 5/50\n",
      "36864/36864 [==============================] - 683s - loss: 0.0671 - val_loss: 0.0643\n",
      "Epoch 6/50\n",
      "36864/36864 [==============================] - 685s - loss: 0.0632 - val_loss: 0.0611\n",
      "Epoch 7/50\n",
      "36864/36864 [==============================] - 669s - loss: 0.0604 - val_loss: 0.0589\n",
      "Epoch 8/50\n",
      "36864/36864 [==============================] - 668s - loss: 0.0582 - val_loss: 0.0586\n",
      "Epoch 9/50\n",
      "36864/36864 [==============================] - 679s - loss: 0.0567 - val_loss: 0.0564\n",
      "Epoch 10/50\n",
      "36864/36864 [==============================] - 673s - loss: 0.0556 - val_loss: 0.0540\n",
      "Epoch 11/50\n",
      "36864/36864 [==============================] - 684s - loss: 0.0544 - val_loss: 0.0545\n",
      "Epoch 12/50\n",
      "36864/36864 [==============================] - 676s - loss: 0.0537 - val_loss: 0.0529\n",
      "Epoch 13/50\n",
      "36864/36864 [==============================] - 674s - loss: 0.0529 - val_loss: 0.0521\n",
      "Epoch 14/50\n",
      "36864/36864 [==============================] - 679s - loss: 0.0522 - val_loss: 0.0521\n",
      "Epoch 15/50\n",
      "36864/36864 [==============================] - 678s - loss: 0.0516 - val_loss: 0.0512\n",
      "Epoch 16/50\n",
      "36864/36864 [==============================] - 673s - loss: 0.0510 - val_loss: 0.0511\n",
      "Epoch 17/50\n",
      "36864/36864 [==============================] - 676s - loss: 0.0507 - val_loss: 0.0505\n",
      "Epoch 18/50\n",
      "36864/36864 [==============================] - 681s - loss: 0.0502 - val_loss: 0.0503\n",
      "Epoch 19/50\n",
      "36864/36864 [==============================] - 679s - loss: 0.0498 - val_loss: 0.0499\n",
      "Epoch 20/50\n",
      "36864/36864 [==============================] - 671s - loss: 0.0494 - val_loss: 0.0497\n",
      "Epoch 21/50\n",
      "36864/36864 [==============================] - 677s - loss: 0.0490 - val_loss: 0.0485\n",
      "Epoch 22/50\n",
      "36864/36864 [==============================] - 684s - loss: 0.0486 - val_loss: 0.0490\n",
      "Epoch 23/50\n",
      "36864/36864 [==============================] - 681s - loss: 0.0481 - val_loss: 0.0480\n",
      "Epoch 24/50\n",
      "36864/36864 [==============================] - 681s - loss: 0.0479 - val_loss: 0.0480\n",
      "Epoch 25/50\n",
      "36864/36864 [==============================] - 678s - loss: 0.0475 - val_loss: 0.0477\n",
      "Epoch 26/50\n",
      "36864/36864 [==============================] - 679s - loss: 0.0471 - val_loss: 0.0470\n",
      "Epoch 27/50\n",
      "36864/36864 [==============================] - 675s - loss: 0.0467 - val_loss: 0.0467\n",
      "Epoch 28/50\n",
      "36864/36864 [==============================] - 675s - loss: 0.0463 - val_loss: 0.0461\n",
      "Epoch 29/50\n",
      "36864/36864 [==============================] - 674s - loss: 0.0458 - val_loss: 0.0458\n",
      "Epoch 30/50\n",
      "36864/36864 [==============================] - 683s - loss: 0.0454 - val_loss: 0.0449\n",
      "Epoch 31/50\n",
      "36864/36864 [==============================] - 681s - loss: 0.0450 - val_loss: 0.0448\n",
      "Epoch 32/50\n",
      "36864/36864 [==============================] - 680s - loss: 0.0444 - val_loss: 0.0442\n",
      "Epoch 33/50\n",
      "36864/36864 [==============================] - 674s - loss: 0.0439 - val_loss: 0.0438\n",
      "Epoch 34/50\n",
      "36864/36864 [==============================] - 676s - loss: 0.0434 - val_loss: 0.0432\n",
      "Epoch 35/50\n",
      "36864/36864 [==============================] - 676s - loss: 0.0428 - val_loss: 0.0428\n",
      "Epoch 36/50\n",
      "36864/36864 [==============================] - 671s - loss: 0.0423 - val_loss: 0.0420\n",
      "Epoch 37/50\n",
      "36864/36864 [==============================] - 676s - loss: 0.0418 - val_loss: 0.0416\n",
      "Epoch 38/50\n",
      "36864/36864 [==============================] - 684s - loss: 0.0413 - val_loss: 0.0411\n",
      "Epoch 39/50\n",
      "36864/36864 [==============================] - 680s - loss: 0.0408 - val_loss: 0.0409\n",
      "Epoch 40/50\n",
      "36864/36864 [==============================] - 680s - loss: 0.0404 - val_loss: 0.0404\n",
      "Epoch 41/50\n",
      "36864/36864 [==============================] - 680s - loss: 0.0401 - val_loss: 0.0398\n",
      "Epoch 42/50\n",
      "36864/36864 [==============================] - 677s - loss: 0.0397 - val_loss: 0.0402\n",
      "Epoch 43/50\n",
      "36864/36864 [==============================] - 681s - loss: 0.0394 - val_loss: 0.0395\n",
      "Epoch 44/50\n",
      "36864/36864 [==============================] - 680s - loss: 0.0390 - val_loss: 0.0391\n",
      "Epoch 45/50\n",
      "36864/36864 [==============================] - 674s - loss: 0.0389 - val_loss: 0.0388\n",
      "Epoch 46/50\n",
      "36864/36864 [==============================] - 669s - loss: 0.0386 - val_loss: 0.0389\n",
      "Epoch 47/50\n",
      "36864/36864 [==============================] - 677s - loss: 0.0384 - val_loss: 0.0383\n",
      "Epoch 48/50\n",
      "36864/36864 [==============================] - 676s - loss: 0.0383 - val_loss: 0.0383\n",
      "Epoch 49/50\n",
      "36864/36864 [==============================] - 674s - loss: 0.0379 - val_loss: 0.0380\n",
      "Epoch 50/50\n",
      "36864/36864 [==============================] - 676s - loss: 0.0379 - val_loss: 0.0378\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logdirb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-292f6e32e4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     callbacks = _callbacks )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'run \"tensorboard --logdir=%s\" to launch tensorboard'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlogdirb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logdirb' is not defined"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join('logs/autoencoder', time.strftime('%m%d_%Hh%M'))\n",
    "\n",
    "_callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "              TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=False) # \n",
    "             ]\n",
    "\n",
    "autoencoder.fit_generator( # memory usage is ~11G \n",
    "    generator=batch_generator(X_train),\n",
    "    samples_per_epoch=X_train.shape[0],\n",
    "    validation_data = batch_generator(X_val),\n",
    "    nb_val_samples = X_val.shape[0],\n",
    "    nb_epoch=NB_EPOCH, \n",
    "    callbacks = _callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run \"tensorboard --logdir=logs/autoencoder/1108_19h37\" to launch tensorboard\n"
     ]
    }
   ],
   "source": [
    "print 'run \"tensorboard --logdir=%s\" to launch tensorboard'%logdir\n",
    "MODEL_PATH = './models/'\n",
    "model_fpath = os.path.join( MODEL_PATH, 'autoencoder_%s.h5' % time.strftime('%m%d_%Hh%M') )\n",
    "autoencoder.save(model_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting deep patient feature using trained autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded2 = hiddenlayer(decoded)\n",
    "decoded2 = outputlayer(encoded2)\n",
    "encoded3 = hiddenlayer(decoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dpencoder = Model(input=input_raw, output=encoded3)\n",
    "model_fpath = os.path.join(MODEL_PATH, 'dpencoder_%s.h5'% time.strftime('%m%d_%Hh%M') )\n",
    "dpencoder.save(model_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [05:10<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "dpvecs = []\n",
    "for i in tqdm(xrange(0, Xraw.shape[0], BATCH_SZ)):\n",
    "    x_batch = Xraw[i:min(i+BATCH_SZ, Xraw.shape[0])].toarray()\n",
    "    dpveci = dpencoder.predict(x_batch)\n",
    "    dpvecs.append(dpveci)\n",
    "Xdp = np.vstack(dpvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46146, 500) (46146, 69574)\n",
      "46146 69574 69574\n"
     ]
    }
   ],
   "source": [
    "print Xdp.shape, Xraw.shape\n",
    "print len(sid2rowidx), len(unique_cui_semtype_pair), len(concept2id)\n",
    "\n",
    "description = '''\n",
    "contains sid2rowidx mapping, and deep patient feature Xdp and raw feature Xraw\n",
    "here the Xraw uses (semtype,cui) pair and each row is k-hot encoding\n",
    "all unique such pairs are in unique_cui_semtype_pair\n",
    "(st,cui) pair to encoding id is in concept2id.\n",
    "'''\n",
    "\n",
    "data_to_pickle = {\n",
    "    'description': description,\n",
    "    'sid2rowidx': sid2rowidx,\n",
    "    'Xdp': Xdp,\n",
    "    'Xraw': Xraw,\n",
    "    'unique_cui_semtype_pair': unique_cui_semtype_pair,\n",
    "    'concept2id': concept2id,\n",
    "}\n",
    "with open('./data/feature_DP_st_cui.pk', 'wb') as f:\n",
    "    pk.dump(data_to_pickle, f, pk.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

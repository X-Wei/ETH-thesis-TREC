{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, time, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../2-DRMM/') # use what is contained in the file `../2-DRMM/DRMM.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "PK_FPATH = '../data/processed_data_sidhid.pk'\n",
    "MODEL_FPATH = '../models/1124_model_2embed_2conv1d_2FC.h5' # path of best trained model \n",
    "NOTES_DIR = '/local/XW/DATA/MIMIC/noteevents_by_sid_hid/'\n",
    "TOKENIZER_FPATH = '../data/tokenizer.pk'\n",
    "# constants\n",
    "MAX_NB_WORDS = 20000 # top 20k most freq words\n",
    "MAX_SEQ_LEN = 1000\n",
    "N_LABELS = 50\n",
    "N_SIDHID = 58328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains the prepared data for note2vec training, \n",
      "* sidhids:     list of the 58361 unique (sid,hid) pairs\n",
      "* sidhid2icds: mapping from (sid,hid) pair --> set of icd codes\n",
      "* sidhid2khot: mapping from (sid,hid) pair --> khot-encoding correponding to this sidhid pair\n",
      "* sidhid2seq:  mapping from (sid,hid) pair --> fix-length sequences (len=1000) of word ids\n",
      "* word2idx:    mapping from a word to its id used in the sequence\n",
      "* embedding_w2vÔºèembedding_glove: matrices for the embedding layer (used as the weights parameter)\n",
      "* train_sidhids/val_sidhids: list of (sid,hid) pairs used as training/validation set\n",
      "* X_train/Y_train/X_val/Y_val: ndarray generated for training/validation\n",
      "\n",
      "And here are 2 useful functions' source code: \n",
      "\n",
      "def to_khot(sidhid2icds, K=N_LABELS): # generate khot encoding (useful if want to change the K)\n",
      "    icds = zip( *icd_ctr.most_common(N_LABELS-1) )[0] + ('other',)\n",
      "    sidhid2khot = {} # map subject_id to k-hot vector\n",
      "    for sid,hid in sidhid2icds.keys():\n",
      "        _khot = np.zeros(N_LABELS)\n",
      "        for _icd in sidhid2icds[(sid,hid)]:\n",
      "            if _icd in icds: \n",
      "                _khot[icds.index(_icd)] = 1\n",
      "            else: # label 'other icds'\n",
      "                _khot[-1] = 1\n",
      "        sidhid2khot[(sid,hid)] = _khot\n",
      "    return sidhid2khot\n",
      "\n",
      "def getXY(sidhid_lst): # give a list of (sid, hid) pairs, generate the X and Y\n",
      "    data, labels = [], []\n",
      "    for sidhid in sidhid_lst:\n",
      "        data.append(sidhid2seq[sidhid])\n",
      "        labels.append(sidhid2khot[sidhid])\n",
      "    X = np.array(data)\n",
      "    Y = np.array(labels)\n",
      "    return X,Y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load pickled data\n",
    "pk_data = pk.load(open(PK_FPATH, 'rb'))\n",
    "X_train = pk_data['X_train']\n",
    "print pk_data['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load note2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     4,   415,  3867],\n",
       "       [ 9846,    48,  3477, ...,  1159,   269,  7250],\n",
       "       [ 4008,    11,  5635, ...,   121,    69,  6624],\n",
       "       ..., \n",
       "       [10310,   421,  1747, ...,   680,    57,   475],\n",
       "       [  785,   486,  1517, ...,  3268,   470,   682],\n",
       "       [ 4917,    20,  2463, ...,  1062,    97,   116]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X_train[:10].shape\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ***NOTE***\n",
    "# To load models from file, we have to modify metrics.py at: \n",
    "# `/local/XW/SOFT/anaconda2/envs/thesis_nb/lib/python2.7/site-packages/keras/` \n",
    "# to add the custom metric function, otherwise `load_model` throws exception ! \n",
    "# cf issue: https://github.com/fchollet/keras/issues/3911\n",
    "from keras.models import load_model\n",
    "model = load_model(MODEL_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"main_input:0\", shape=(?, 1000), dtype=int32)\n",
      "Tensor(\"Relu_3:0\", shape=(?, 500), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print model.layers[0].input\n",
    "print model.layers[11].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use K.function to construct a model that outputs embedding vector\n",
    "from keras import backend as K\n",
    "get_embedvec = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                                  [model.layers[11].output])\n",
    "embedvec = lambda X: get_embedvec([X,0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 500)\n"
     ]
    }
   ],
   "source": [
    "# output in test mode = 0\n",
    "layer_output = embedvec(X_train[:10])\n",
    "print layer_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn a paragraph into 500-dimensional input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sidhids = []\n",
    "# texts = [] # text bodies\n",
    "# for fname in tqdm(os.listdir(NOTES_DIR)): # the data is 3.7G in size, can hold in memory...\n",
    "#     sid,hid = map( int, fname[:-4].split('_') )\n",
    "#     sidhids.append( (sid,hid) )\n",
    "#     fpath = os.path.join(NOTES_DIR, fname)\n",
    "#     df = pd.read_csv(fpath)\n",
    "#     texts.append( '\\n=======\\n\\n\\n'.join(df['text']) )\n",
    "# print('found %d texts' % len(texts))\n",
    "\n",
    "# tokenizer = Tokenizer(nb_words=MAX_NB_WORDS, # filter out numbers, otherwise lots of numbers\n",
    "#                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+'0123456789') \n",
    "# print 'fitting on whole text corpus...',\n",
    "# tokenizer.fit_on_texts(texts) # this might take some time\n",
    "# print 'done. '\n",
    "\n",
    "# pk.dump(tokenizer, open('data/tokenizer.pk', 'wb'), pk.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(TOKENIZER_FPATH, 'rb') as f:\n",
    "    tokenizer = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paragraph2vec(paragraph):\n",
    "    seqs = tokenizer.texts_to_sequences([paragraph.encode('utf-8')])\n",
    "    seqs_padded = pad_sequences(seqs, maxlen=MAX_SEQ_LEN)\n",
    "    return embedvec(seqs_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_sample = ''' The imaged portions of the abdomen show a few [**Last Name (un) 36399**]-filled loops of bowel\n",
    "   within the left abdomen.  No abnormal soft tissue mass or calcifications.  No\n",
    "   free interperitoneal air.  The imaged bony structures are unremarkable.'''\n",
    "paragraph2vec(paragraph_sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "topic_tree = etree.parse('../data/topics2016.xml')\n",
    "pat = re.compile('\\W*\\n\\W*\\n')\n",
    "def get_query_paragraphs(i): # returns the paragraphs in topic i \n",
    "    text = '\\n=====\\n'.join( topic_tree.xpath('//topic[@number=\"%d\"]/*/text()'%i) )\n",
    "    paras = pat.split(text.lower())\n",
    "    return [p.strip() for p in paras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 12, 3, 4, 4, 4, 7, 6, 11, 5, 4, 3, 7, 4, 3, 4, 5, 9, 7, 5, 3, 6, 8, 4, 4, 5, 8, 6, 6, 5]\n"
     ]
    }
   ],
   "source": [
    "QUERIES = [get_query_paragraphs(i) for i in xrange(1,31)]\n",
    "print map(len, QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "MAX_QLEN = max(map(len, QUERIES))\n",
    "print MAX_QLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# padding queries to the same length N\n",
    "PARA_PLACEHOLDER = '</s>'\n",
    "def pad_query(q, SZ=N):\n",
    "    return q + [PARA_PLACEHOLDER]*(SZ-len(q))\n",
    "QUERIES = map(pad_query, QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QUERIES = {i+1:QUERIES[i] for i in xrange(30)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to extract histvec from query/article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PMC_PATH = '/local/XW/DATA/TREC/PMCs/'\n",
    "pmcid2fpath = {}\n",
    "\n",
    "for subdir1 in os.listdir(PMC_PATH):\n",
    "    for subdir2 in os.listdir(os.path.join(PMC_PATH, subdir1)):\n",
    "        diry = os.path.join(PMC_PATH, subdir1, subdir2)\n",
    "        for fn in os.listdir(diry):\n",
    "            pmcid = fn[:-5]\n",
    "            fpath = os.path.join(diry, fn)\n",
    "            pmcid2fpath[pmcid] = fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "78 m w/ pmh of cabg in early [**month (only) 3**] at [**hospital6 4406**]\n",
      "   (transferred to nursing home for rehab on [**12-8**] after several falls out\n",
      "   of bed.) he was then readmitted to [**hospital6 1749**] on\n",
      "   [**3120-12-11**] after developing acute pulmonary edema/chf/unresponsiveness?.\n",
      "   there was a question whether he had a small mi; he reportedly had a\n",
      "   small nqwmi. he improved with diuresis and was not intubated\n",
      "---\n",
      "yesterday, he was noted to have a melanotic stool earlier this evening\n",
      "   and then approximately 9 loose bm w/ some melena and some frank blood\n",
      "   just prior to transfer, unclear quantity\n",
      "---\n",
      "78 m transferred to nursing home for rehab after cabg. reportedly readmitted with a small nqwmi. yesterday, he was noted to have a melanotic stool and then today he had approximately 9 loose bm w/ some melena and some frank blood just prior to transfer, unclear quantity\n",
      "---\n",
      "a 78 year old male presents with frequent stools and melena.\n"
     ]
    }
   ],
   "source": [
    "for p in get_query_paragraphs(1):\n",
    "    print '---'\n",
    "    print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_article_paragraphs(pmcid):\n",
    "    'returns a list of texts, each as a paragraph'\n",
    "    fpath = pmcid2fpath[pmcid]\n",
    "    tree = etree.parse(fpath)\n",
    "    ret = []\n",
    "    body = tree.xpath('//body')[0]\n",
    "    for p in body.xpath('.//p'):\n",
    "        ret.append( p.xpath('string(.)').strip() )\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['By 1998, a hospital stay of 48 hours or less following an uncomplicated, singleton vaginal delivery had become common practice in Ontario. This shortened stay has reduced access to in-hospital identification and treatment of postpartum complications [1]. In response, health care providers, including family physicians, have attempted to provide safe, integrated, cost-effective care for postpartum women and their infants. The objectives of the Ontario Mother and Infant Survey were to provide planning information by examining utilization patterns, health outcomes and costs associated with existing practices in the management of postpartum women and their infants that could be used to further integrate services, and to identify for whom targeted interventions might be beneficial.',\n",
       " 'One of the difficulties that can follow childbirth is maternal depression. Researchers have reported depression rates in North American women between 8% and 26% during the period one month to one year after the birth of a child [1-5]. They found that postpartum depression (PPD) could have a profound impact on the well being of a mother [6], a newborn infant [7-9], and a family in general [10,11].',\n",
       " 'Research has focused on predisposing characteristics and circumstances of individual women that place them at risk for postnatal depression [12-16]. For example, Beck (1995) identified eight predisposing factors: prenatal depression, maternal history of depression, lack of social support, life stress, child care stress, maternal \"blues\", marital dissatisfaction, and, prenatal anxiety. A recent meta-analysis identified that postpartum depression is most strongly associated with poor marital adjustment, recent life stressors, and antepartum depression. Other researchers have discussed the difficulties in defining postpartum depression as an entity separate from other types of depression [17,18] and have found wide variations in prevalence using different assessment tools [11,17]. In Ontario, no universal screening protocol is used to detect PPD.',\n",
       " 'The purpose of this article is to describe the outcomes of a study of the health and social care needs of healthy postpartum women, to alert family physicians to signs of depression in the early postpartum period, and to discuss the impact of reduced lengths of postpartum hospital stay and the introduction of community outreach initiatives on the detection of PPD.',\n",
       " u\"The settings for the 1998\\u201399 TOMIS study recruitment were five Ontario hospitals chosen for their varied size, practice characteristics and geographic locations. The design was cross-sectional with follow-up at four weeks after postpartum discharge from hospital. The study recruited 1250 women, 250 from each site, who had vaginally delivered a live, singleton infant who was discharged to the care of, and at the same time as, the mother. Exclusion criteria included women having caesarean sections, multiple births, or major complications for either mother or infants. Maternity floor nurses and/or a site research assistant identified subjects. The study was conducted in seven languages. Ethics approval was obtained from McMaster University, Hamilton, Ontario and each of the five participating hospital sites. The two instruments used, the Mother's Questionnaire and the Mother's Interview Schedule, were developed and tested for reliability and validity during a 1997 pilot project in Hamilton. The mothers answered the questionnaire in hospital, prior to discharge and the interview schedule was administered by telephone, four to six weeks after postpartum discharge, by trained interviewers. Sample size was calculated using 30 subjects per variable [19].\",\n",
       " u'The interview schedule included the Edinburgh Postpartum Depression Scale (EPDS) [20,21] and the Duke UNC Functional Social Support Questionnaire [22]. The EPDS has been used as a screening tool for postpartum depression and a score of \\u2265 12 has been found to be predictive of a diagnosis of postpartum depression [23-26]. Although the EPDS is most often used at 6 weeks postpartum, it has been used antenatally [38,39] and in the early postnatal period (e.g. day 5) [40]. The EPDS was developed as a screening tool, and is not meant to diagnose postpartum depression. A recent review of eighteen EPDS validation studies, suggests that when used in a general population, such as the sample for TOMIS, the positive predictive value may be less than 50%, emphasising the need for further clinical assessment of the women who are identified as having EPDS scores of \\u2265 12 [37]. Two studies have determined that the EPDS, when using \\u2265 12 as a cut-off level, has a sensitivity of 86% and 68%, a specificity of 78% and 96%, and a positive predictive value of 73% and 67%. [20,38]',\n",
       " 'All service utilization, including hospital, physician, and community care, was collected using the Health and Social Services Utilization Questionnaire [27].',\n",
       " 'Using t-test, chi-square or Fisher exact tests, we identified potential predictors for postpartum depression. Multiple logistic regression analysis was used to identify the most important predictors. These findings are presented as adjusted odds ratios with corresponding 95% confidence intervals. The final step in the modelling procedure was to test for the significance of interaction terms, representing possible effect modifiers. The goodness of fit for the final logistic regression model was assessed using the rho-square statistic [28]. We used SPSS Version 10.0.5 for Windows, 1999 and Epi-Info Version 6.04c, (1997) for statistical computations and a probability level of <0.05 to determine statistical significance.',\n",
       " 'The study is not predicated on a random sample of all women delivering healthy infants in Ontario. Rather, the study provides five snapshots of groups of women in five locales in Ontario. This geographic diversity is an important consideration if programs and services are purported to be universally available throughout the province. Analysis of the data retains the integrity of each locale and uses location as a variable for understanding differences between groups. A full description of the methodology has been published [29].',\n",
       " 'Of the 1,250 women recruited, 875 (70%) completed the follow-up interview [29]. A profile of women who took part in the interview and their infants is presented in Table 1. There was no difference in age, parity, or length of stay for those subjects in the study and those who refused to participated or were missed by recruiters. There were no statistically significant differences in the sociodemographic characteristics of interview participants and women and their infants who were lost to follow-up.',\n",
       " 'Profile of Interview Respondents',\n",
       " u\"Scores of \\u2265 12 on the EPDS were found to range from 4.3% to 15.2% (n = 86/873) of otherwise healthy women in each of the sites. Despite the fact that each of these women had seen a physician in relation to her own or her baby's health, no evidence was found that a health care provider identified maternal depression as a health problem. None of the women reported taking medication normally associated with the treatment of either depression or anxiety, nor did they report seeing a mental health professional, such as a psychiatrist, psychologist, or social worker. No larger percentage of this group had seen a public health nurse or other community care provider than had women scoring <12. Therefore, as identified by Wilson et al., there appears to be an undetected, undiagnosed, and untreated group of clinically depressed early postpartum women in the community who are seeing health providers but not being identified as having a mental health problem [16].\",\n",
       " \"In order to identify the best predictors of PPD we first conducted univariate analyses of all variables hypothesized a priori to be associated with PPD (hospital site was a variable we hypothesized could be associated with PPD). In fact, we did find that the site of recruitment was associated with PPD. In order to identify the most important predictors of PPD (and simultaneously adjust for other important predictors) we conducted a logistic regression analysis. Site was not an important predictor of PPD, given the other variables we examined. In fact, forcing site into the final logistic regression model (i.e, adjusting for site) did not have any effect on the size of the odds ratios (i.e, was not a confounding factor). As such, site was neither a confounder nor did it significantly improve the fit of the model. Thus, other variable's were examined in an effort to find more predictive variables and to understand the wide variability in the found rates of depression among the sites.\",\n",
       " u'The univariate analyses revealed 55 variables that were statistically associated with an EPDS score of \\u2265 12. Social and health characteristics of the mother (e.g., age, presence of chronic health problems), characteristics of their social environment (e.g., cultural background, language spoken at home, confident support [30], and their care experiences (e.g., use of paediatrician, readiness for discharge, unmet learning needs) were among the significant associated variables. There was a significant correlation between these scores and maternal endorsement of an unmet need for help with a mental health problem or an emotional difficulty and with a self-rating of their own general health as \"fair\" to \"poor\".',\n",
       " u'Only variables that had a statistically significant association with PPD were included in the logistic regression analysis. A forward, likelihood-ratio method was used for the logistic regression modelling. In order to be included, variables had to either significantly improve the fit of the model (p\\u2264 0.05) or be confounding factors. The logistic regression analysis produced odds ratios that have been simultaneously adjusted for all other variables in the final model. The goodness of fit of the logistic regression models was assessed using the rho-squared statistic [18]. A rho-square value between 0.20 and 0.40 suggests a very good fit of the model.',\n",
       " u\"When entered into a logistic regression, eight factors were determined to provide the best predictors of an EPDS score of \\u2265 12 for this group: lack of confidant support (i.e., social relationships in which participants can share thoughts, experiences, and ideas), lack of affective support (i.e., social relationships in which individuals provide positive emotional support for each other), household income of <$20,000, wanting to stay in hospital longer, identification of learning needs while in hospital, self-identified unmet need for care for an emotional/mental health problem, mother's rating of her own health as fair or poor, and mother's rating of the health of her baby as fair or poor (See Table 2). Length of post delivery hospital stay, initiation or continuation of breastfeeding, and the amount or type of health and social service utilization, although identified in the literature as predictive factors, were not associated with EPDS scores.\",\n",
       " 'Logistic Regression Model of the Best Predictors of Postpartum Depression1 within the First Four Weeks Post Discharge (N = 8702)',\n",
       " 'Final Logistic Regression Model Statistics: Rho-square = 0.21 (a pseudo R2, values between 0.2 and 0.4 suggest a very good fit) Hosmer and Lemeshow Goodness-of-fit test = 0.91 (values greater than 0.25 indicate good fit) 91.0% correctly classified 1Edinburgh Postnatal Depression Scale 2Five mothers had missing values for one or more of the variables included in the final model 3Exact questions may be obtained from the corresponding author 3Odds ratios for categorical variables represent comparisons with the referent group (OR = 1.00) after adjustment for all other variables in the model 4From The Duke-UNC Functional Social Support Questionnaire. 5Information collected from mother four weeks after discharge from hospital 6Information collected from mother prior to discharge from hospital 7Learning needs included information on hospital routines, breast feeding, bottle feeding, infant care and behaviour, signs of illness in infant, physical changes and care of self, emotional changes for self, sexual changes and intercourse, family changes, community support services and other',\n",
       " 'Health care providers have long been concerned with identifying and treating depression in new mothers but it has been difficult to predict which women are most at risk. This difficulty has been exacerbated by shorter hospital stays, a initial focus on infant rather than maternal health, and practice patterns that splinter the care of mothers and newborns among a variety of health professionals.',\n",
       " 'While the literature often provides conflicting evidence about the etiology and prevalence of this phenomenon [31], the clinician is faced with a woman who is in distress, who is often not able to identify the nature or source of the difficulty, and who is looking to the primary care provider for help. Whether one views the etiology of this distress from a biomedical or sociological perspective, the problem of early identification and intervention remains. Failure to diagnosis and treat PPD may result in the inability of a mother to provide adequate infant care [32] and increase the risk for infant cognitive and emotional delay [33].',\n",
       " u'None of the mothers in this study who score \\u2265 12 on the EPDS reported being diagnosed with or treated for depression. None reported seeing a mental health specialist and none were taking antidepressant drugs, a finding similar to a previous study [34]. Despite the predictive value of self-identified emotional or mental health issues in relation to early postpartum depression [35], only 22.2% to 30.8% of women in this study with EPDS of \\u2265 12 reported that they had experienced an emotional or mental health problem since discharge from hospital. However, 44.4% to 52.0% identified the need for reassurance and support.',\n",
       " u\"The EPDS was developed as a screening tool, and is not meant to diagnose actual postpartum depression. A recent review of eighteen EPDS validation studies, suggests that when used in a general population such as the sample for TOMIS, the positive predictive value may be less than 50%, emphasizing the need for further clinical assessment of the women who are identified as \\u2265 12 [40]. The TOMIS results also suggest that prenatal distress, while important, is an insufficient predictor of postpartum depression [37,38]. Given that this group of distressed mothers rarely identified themselves as having received help for a prenatal mental health problem, and not all of the mothers who identified prenatal mental health problems had scores of \\u2265 12 at four weeks post discharge, it is not adequate for primary care providers to assume that a woman's pre-pregnancy or prenatal mental health status is predictive of postnatal depression [39].\",\n",
       " 'Perhaps women have normalized the symptoms that professionals associate with depression. While women who identified a need for reassurance and support were, in the main, able to get it, women who identified a need for help with an emotional or mental health problem reported much less success in obtaining assistance. It is unclear how the women themselves differentiated between these two needs but it was evident that somehow they discriminated between common social support needs and the need for help with what they had defined as a mental health issue.',\n",
       " \"All participants had contact with a physician since their discharge from hospital. All identified contact in relation to their infant's health, but less than 10 % of women in any of the sites identified that this contact had been for their own needs.\",\n",
       " u'Mothers who scored \\u2265 12 identified their own health and the health of their newborn infant as less than optimal. This evaluation was in contrast to mothers who scored less than 12, who evaluated both as \"good to excellent\". Hospital readmission of either mother or infant was not found to be a related to \\u2265 12 scores.',\n",
       " u'Given that mothers with scores of \\u2265 12 reported low levels of both confident and affective support, these results lend credibility to the notion that early postpartum depression may be an expression of a woman\\'s sense of being overwhelmed by a major life-changing event. Thrust into the care of a newborn infant, without strong support, mothers may be primed for an emotional response that they identify in a negative way. \"Anxiety\", \"depression\", or \"stress\" may be used to describe the set of responses, but this research shows these women are experiencing significant distress and may be at risk for more serious, long-term difficulties [12,33,37,38]. These finding are consistent with other studies that have identified worries about ones own health or about an infant\\'s health, and lack of social support as predictors of PPD [44,45].',\n",
       " u'Although a woman\\'s sense of personal readiness for discharge was not one of the most strongly associated variables with \\u2265 12 EPDS scores, it was an important predictor and may be a clue to providers in identifying an \"at risk\" group while they are still in hospital. It is important to recognize that the message from these mothers was not \"I want to stay in hospital\" as much as \"I don\\'t think I can manage at home\". Given that most women (60.0% to 76.9%) said at the time of discharge that they thought they were ready for discharge, women who want to stay in hospital for a longer period need particular attention. We need to understand their reasons for believing that an increased length of stay would be helpful. Does the woman want to stay longer because she is afraid that she or her infant is \"sick\"? Is the hospital a \"safe haven\"? What resources-personal, financial, social \\u2013 would make discharge feel \"safer\"? What role could primary care providers in the community play in easing the transition home?',\n",
       " u\"A recently published UK study [46] found that enhanced and flexible community care for postpartum women that focused on the individual needs of each woman. Home visits during the first 4 weeks after the baby's birth were scheduled according to the needs of the mother. Four months after deliver the mother who received this enhanced care were found to be equally physically health and in better mental health than those who received only standard midwifery care. Mothers receiving enhance care reported a significantly different appreciation of the relationship with their midwife that suggests that both affective and confidant support, notably absent in the group of women in our study who scored \\u2265 12 on the EPDS was achieved through the provision of these services.\",\n",
       " u\"Simple inquiries by care providers about a woman's sense of her own readiness for discharge might alert them to potential distress [27]. At four weeks post-discharge, only 44.0% to 72.0 % of women at each site thought that their stay had been the appropriate length for them \\u2013 significantly fewer than at the time of discharge. Policy changes introduced in Ontario after this research was completed provide a choice of a 60-hour stay at the discretion of the mother. Women exercising this option may represent a group at higher risk for depression in the postpartum period. It is unclear if extended hospitalization reduces the risk for PPD. However, it is reasonable to assume that discharging a distressed woman into a community without guaranteeing adequate assistance is a certain prescription for increased risk.\",\n",
       " 'Our results suggest that if women express undue concern about their own health, or the health of their infants, it might be wise for health care providers to explore the possibility of maternal depression. It is not clear if mothers would volunteer this concern or would only evaluate their own health and that of their infant in negative terms if asked. Frequent unscheduled contact with providers by telephone or visits may signal this heightened concern.',\n",
       " 'The ideal time frame for screening for PPD has not yet been established. Family physicians need to recognize that despite recent policy changes that offer all consenting women a telephone call from a public health nurse within 48 hours of hospital discharge and a possible home visit, these contacts may be too early or too \"baby-focused\" to identify women at risk for PPD.',\n",
       " \"Family physicians, midwives, and public health nurses have an important role to play not only in ensuring the physical well being of newborns and women in the postpartum period, but also in early detection of PPD. Well baby follow up appointments occur much earlier than the standard six-week post delivery check up. For at least some women, screening for PPD as part of well baby follow up may afford an earlier opportunity for prompt and effective interventions including additional social support and targeted learning opportunities in the woman's own community that have been shown to be helpful to a significant number of women in reducing the incidence of PPD.\",\n",
       " 'PPDPost Partum Depression',\n",
       " 'TOMISThe Ontario Mother and Infant Survey',\n",
       " 'EPDSEdinburgh Postnatal Depression Scale',\n",
       " 'SPSSStatistical Package for the Social Sciences',\n",
       " 'None declared.',\n",
       " 'The pre-publication history for this paper can be accessed here:',\n",
       " '']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_paragraphs('107838')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARA_PLACEHOLDER = '</s>'\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_histvec(query_para, pmcid):\n",
    "    if query_para == PARA_PLACEHOLDER: \n",
    "        return np.zeros(30)\n",
    "    qvec = paragraph2vec(query_para)\n",
    "    dvecs = np.vstack( [ paragraph2vec(p.encode('ascii','ignore')) for p in get_article_paragraphs(pmcid)] )\n",
    "    cossims = np.dot(dvecs, qvec.T) / norm(qvec) / norm(dvecs, axis=1)\n",
    "    hist, _ = np.histogram( cossims, bins=30, range=(0,1) )\n",
    "    ret = np.log(hist+1)\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  3.04452244,\n",
       "        4.4308168 ,  4.33073334,  3.52636052,  3.61091791,  4.21950771,\n",
       "        4.26267988,  4.76217393,  4.49980967,  5.01727984,  5.27811466])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_histvec(get_query_paragraphs(1)[1], '107838')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_para = get_query_paragraphs(1)[1] \n",
    "pmcid = '107838'\n",
    "qvec = paragraph2vec(query_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_doc_feature(qid, pmcid): # query: list of paragraphs\n",
    "    query = QUERIES[qid]\n",
    "    return np.array([ get_histvec(p, pmcid) for p in query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_query_doc_feature(1, '107838').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data: padded queries, positive and negative histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37707/37707 [01:36<00:00, 390.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "candidates = defaultdict(list) # dict[int, list<str>] mapping qid to list of its candidate docids (that appeared in the qrel)\n",
    "n_pos = defaultdict(int) # dict[int, int] mapping qid to the number of positive documents in qrel\n",
    "relevance = {} # dict[(int,str), int] mapping (qid,docid) pairs to its relevance (0,1,2)\n",
    "with open('../data/qrels.txt') as f:\n",
    "    for line in tqdm(f, total=37707): \n",
    "        qid, _, pmcid, rel = line.split()\n",
    "        qid = int(qid); rel = int(rel)\n",
    "        try: \n",
    "            if len( get_article_paragraphs(pmcid) ) <= 3: \n",
    "                continue\n",
    "            relevance[(qid,pmcid)] =rel\n",
    "            candidates[qid].append(pmcid)\n",
    "            if rel>0: n_pos[qid] += 1\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(para):\n",
    "    return -10 if para==PARA_PLACEHOLDER else 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IDFs = {}\n",
    "for qid in QUERIES.keys(): \n",
    "    IDFs[qid] = np.array([idf(para) for para in QUERIES[qid]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22, 8), (27, 12), (4, 18), (10, 19), (2, 34), (30, 39), (18, 67), (15, 69), (7, 71), (21, 73), (5, 95), (23, 106), (12, 108), (26, 112), (14, 117), (29, 117), (9, 121), (1, 128), (6, 141), (13, 148), (3, 150), (17, 175), (16, 182), (28, 211), (25, 216), (19, 218), (11, 364), (20, 631), (24, 757), (8, 831)]\n",
      "[8, 12, 18, 19, 34, 39, 67, 69, 71, 73, 95, 106, 108, 112, 117, 117, 121, 128, 141, 148, 150, 175, 182, 211, 216, 218, 364, 631, 757, 831]\n"
     ]
    }
   ],
   "source": [
    "print sorted(n_pos.items(), key=lambda (k,v): v)\n",
    "all_pos = sorted( n_pos.values() ) \n",
    "print all_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 112 364\n"
     ]
    }
   ],
   "source": [
    "avg_pos_80 = all_pos[len(all_pos) * 9 / 10 - 1] # x1.5\n",
    "avg_pos_50 = all_pos[len(all_pos) * 5 / 10 - 2] # x3\n",
    "avg_pos_10 = all_pos[len(all_pos) * 5 / 30] # x10\n",
    "print avg_pos_10, avg_pos_50, avg_pos_80 # quantiles of posid numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores = [2, 1, 0] total= 163263 got 3840 instances for query 1\n",
      "scores = [2, 1, 0] total= 42372 got 6800 instances for query 2\n",
      "scores = [2, 1, 0] total= 192356 got 4500 instances for query 3\n",
      "scores = [2, 1, 0] total= 24345 got 3600 instances for query 4\n",
      "scores = [2, 1, 0] total= 126691 got 5700 instances for query 5\n",
      "scores = [2, 1, 0] total= 97817 got 4230 instances for query 6\n",
      "scores = [2, 1, 0] total= 72479 got 4260 instances for query 7\n",
      "scores = [2, 1, 0] total= 435854 got 8000 instances for query 8\n",
      "scores = [2, 1, 0] total= 126334 got 3630 instances for query 9\n",
      "scores = [2, 0] total= 21318 got 3800 instances for query 10\n",
      "scores = [2, 1, 0] total= 255176 got 10920 instances for query 11\n",
      "scores = [2, 1, 0] total= 117927 got 6480 instances for query 12\n",
      "scores = [2, 1, 0] total= 189428 got 4440 instances for query 13\n",
      "scores = [2, 1, 0] total= 124466 got 3510 instances for query 14\n",
      "scores = [2, 1, 0] total= 68651 got 4140 instances for query 15\n",
      "scores = [2, 1, 0] total= 250340 got 5460 instances for query 16\n",
      "scores = [2, 1, 0] total= 161175 got 5250 instances for query 17\n",
      "scores = [2, 1, 0] total= 71502 got 4020 instances for query 18\n",
      "scores = [2, 1, 0] total= 219438 got 6540 instances for query 19\n",
      "scores = [2, 1, 0] total= 356988 got 8000 instances for query 20\n",
      "scores = [2, 1, 0] total= 64822 got 4380 instances for query 21\n",
      "scores = [2, 0] total= 9296 got 1600 instances for query 22\n",
      "scores = [2, 1, 0] total= 161688 got 6360 instances for query 23\n",
      "scores = [2, 1, 0] total= 615971 got 8000 instances for query 24\n",
      "scores = [2, 1, 0] total= 205871 got 6480 instances for query 25\n",
      "scores = [2, 1, 0] total= 103127 got 6720 instances for query 26\n",
      "scores = [2, 0] total= 11400 got 2400 instances for query 27\n",
      "scores = [2, 1, 0] total= 307502 got 6330 instances for query 28\n",
      "scores = [2, 1, 0] total= 76023 got 3510 instances for query 29\n",
      "scores = [2, 1, 0] total= 49700 got 7800 instances for query 30\n"
     ]
    }
   ],
   "source": [
    "instances = {} # mapping qid to list, instances[qid] = list (pos_docid, neg_docid) pairs for qid, \n",
    "# use pairs in instances for training\n",
    "np.random.seed(1)\n",
    "for qid in QUERIES.keys():\n",
    "    \n",
    "    pernegative = 20 # number of limited pairs per positive sample\n",
    "    num_of_instances = 8000 # number limit of pairs per query\n",
    "    \n",
    "    num_pos_currquery = n_pos[qid]\n",
    "    curr_pernegative = pernegative\n",
    "    curr_num_of_instance = num_of_instances # -- their trick: gen less pairs for queries with more pos docs\n",
    "    if(num_pos_currquery <= avg_pos_10): \n",
    "        curr_pernegative *= 10; curr_num_of_instance *= 10\n",
    "    elif(num_pos_currquery <= avg_pos_50): \n",
    "        curr_pernegative *= 3; curr_num_of_instance *= 3; \n",
    "    elif(num_pos_currquery <= avg_pos_80): \n",
    "        curr_pernegative *= 1.5; curr_num_of_instance *= 1.5; \n",
    "    \n",
    "    rel_scores = defaultdict(list) # mapping a rel score to list of docids\n",
    "    for docid in candidates[qid]:\n",
    "        rel = relevance[(qid,docid)]\n",
    "        rel_scores[rel].append(docid)\n",
    "    scores = sorted( rel_scores.keys(), reverse=True ) # scores are sorted in desc order\n",
    "    print 'scores =',scores, \n",
    "    total_instance = 0\n",
    "    for i in xrange(len(scores)): # scores[i] = pos score\n",
    "        for j in xrange(i+1, len(scores)): # scores[j] = neg score\n",
    "            total_instance += len(rel_scores[scores[i]]) * len(rel_scores[scores[j]])\n",
    "    print 'total=', total_instance, \n",
    "    total_instance = min(total_instance, curr_num_of_instance)\n",
    "    from numpy.random import choice \n",
    "    instances_for_q = []\n",
    "    for i in xrange(len(scores)):# scores are sorted in desc order\n",
    "        pos_score = scores[i]\n",
    "        cur_pos_ids = rel_scores[pos_score] # mapping a rel score to list of docids\n",
    "        cur_neg_ids = []\n",
    "        for j in xrange(i+1, len(scores)):\n",
    "            neg_score = scores[j]\n",
    "            cur_neg_ids += rel_scores[neg_score]# FOUND A BUG HERE\n",
    "        if len(cur_neg_ids)==0: break\n",
    "        for posid in cur_pos_ids:\n",
    "            for negid in choice(cur_neg_ids, min(len(cur_neg_ids),int(curr_pernegative)), replace=False):\n",
    "                instances_for_q.append( (posid,negid) )\n",
    "            if len(instances_for_q)>=total_instance: break\n",
    "        if len(instances_for_q)>=total_instance: break\n",
    "    print 'got %d instances for query %d' % (len(instances_for_q), qid)\n",
    "    instances[qid] = instances_for_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1380, 1272, 1404, 1368, 1414, 810, 1080, 1175, 1135, 1141, 986, 1177, 1397, 1167, 1062, 1512, 1054, 1125, 1185, 1039, 943, 1170, 1606, 1400, 1119, 1005, 962, 1623, 746, 1307]\n"
     ]
    }
   ],
   "source": [
    "print map(len, candidates.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 986/986 [36:11<00:00,  1.46s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1177/1177 [1:13:16<00:00,  1.49s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1397/1397 [2:57:28<00:00,  2.54s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1167/1167 [1:24:52<00:00,  1.72s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1062/1062 [1:03:48<00:00,  1.31s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1512/1512 [1:51:10<00:00,  2.32s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1054/1054 [1:55:07<00:00,  1.73s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1125/1125 [3:08:06<00:00,  3.75s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1185/1185 [2:49:27<00:00,  2.69s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1039/1039 [1:55:01<00:00,  1.68s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 943/943 [1:01:51<00:00,  1.24it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1170/1170 [2:09:17<00:00,  2.26s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1606/1606 [3:27:05<00:00,  5.68s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1400/1400 [1:40:39<00:00,  2.07s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1119/1119 [1:17:22<00:00,  1.14s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1005/1005 [1:50:01<00:00,  2.14s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 962/962 [3:02:28<00:00,  3.48s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1623/1623 [2:19:34<00:00,  2.74s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 746/746 [1:51:36<00:00,  3.49s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1307/1307 [2:08:45<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "qid_docid2histvec = {} # mapping from (qid, docid) to histvec\n",
    "for qid in QUERIES.keys()[10:]:\n",
    "    for docid in tqdm(candidates[qid]):\n",
    "        _hist = get_query_doc_feature(qid, docid).reshape(1,MAX_QLEN,30)\n",
    "        qid_docid2histvec[(qid, docid)] = _hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35764"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qid_docid2histvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/DRMM+embedding_processed_10topics-0201.pk') as f:\n",
    "    data = pk.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qid_docid2histvec.update( data['qid_docid2histvec'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_to_pickle = {\n",
    "    'QUERIES': QUERIES,\n",
    "    'candidates': candidates,# mapping qid to list of docids that corresponds to qid in the qrel file \n",
    "    'n_pos': n_pos, # n_pos[qid] = number of positive \n",
    "    'relevance': relevance,  # mapping (qid,docid) pairs to relevance (0,1,2)\n",
    "    'qid_docid2histvec': qid_docid2histvec, # mapping (qid, docid) to histvec\n",
    "    'instances': instances,  # instances[qid] = list (pos_docid, neg_docid) pairs for qid\n",
    "}\n",
    "PK_FOUT = '../data/DRMM+embedding_processed.pk'\n",
    "with open(PK_FOUT, 'wb') as f:\n",
    "    pk.dump(data_to_pickle, f, pk.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from DRMM import gen_DRMM_model\n",
    "\n",
    "scoring_model, ranking_model = gen_DRMM_model(MAX_QLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VALDATION_SPLIT = 0.2\n",
    "BATCH_SZ = 64\n",
    "NB_EPOCH = 50\n",
    "logdir = '../logs/relevance_matching_0131'\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "_callbacks = [ EarlyStopping(monitor='val_loss', patience=2),\n",
    "               TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=False) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(idx_pairs, batch_size=BATCH_SZ): \n",
    "    # ** parameter `idx_pairs` is list of tuple (qid, pos_docid, neg_docid)**\n",
    "    np.random.shuffle(idx_pairs)\n",
    "    batches_pre_epoch = len(idx_pairs) // batch_size\n",
    "    samples_per_epoch = batches_pre_epoch * batch_size # make samples_per_epoch a multiple of batch size\n",
    "    counter = 0\n",
    "    y_true_batch_dummy = np.ones((batch_size))\n",
    "    while 1:\n",
    "        idx_batch = idx_pairs[batch_size*counter: min(samples_per_epoch, batch_size*(counter+1))]\n",
    "        idfs_batch, pos_batch, neg_batch = [], [], []\n",
    "        for qid, pos_docid, neg_docid in idx_batch:\n",
    "            idfs_batch.append(IDFs[qid])\n",
    "            pos_batch.append(qid_docid2histvec[(qid,pos_docid)].reshape(MAX_QLEN,30))\n",
    "            neg_batch.append(qid_docid2histvec[(qid,neg_docid)].reshape(MAX_QLEN,30))\n",
    "        idfs_batch, pos_batch, neg_batch = map(np.array, [idfs_batch, pos_batch, neg_batch])\n",
    "#         print idfs_batch.shape, pos_batch.shape, neg_batch.shape\n",
    "        counter += 1\n",
    "        if (counter >= batches_pre_epoch):\n",
    "            np.random.shuffle(idx_pairs)\n",
    "            counter=0\n",
    "        yield [idfs_batch, pos_batch, neg_batch], y_true_batch_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idx_pairs(qids):\n",
    "    idx_pairs = []\n",
    "    for qid in qids:\n",
    "        for posid, negid in instances[qid]:\n",
    "            idx_pairs.append( (qid,posid, negid) )\n",
    "    return idx_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_weights = ranking_model.get_weights()\n",
    "\n",
    "def shuffle_weights(model, weights=None):\n",
    "    \"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "    This is a fast approximation of re-initializing the weights of a model.\n",
    "    Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "      (i.e., the weights have the same distribution along each dimension).\n",
    "    :param Model model: Modify the weights of the given model.\n",
    "    :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "      If `None`, permute the model's current weights.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = model.get_weights()\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "    model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TREC_output(qid, run_name = 'my_run', fpath = None):\n",
    "    res = [] # list of (score, pmcid) tuples\n",
    "    for docid in candidates[qid]:\n",
    "        input_idf = IDFs[qid].reshape((-1,MAX_QLEN))\n",
    "        input_hist = qid_docid2histvec[(qid,docid)]\n",
    "        score = scoring_model.predict([input_idf, input_hist])[0]\n",
    "        res.append( (score, docid) )\n",
    "    res = sorted(res, reverse=True)\n",
    "    fout = sys.stdout if fpath==None else open(fpath, 'a')\n",
    "    for rank, (score, docid) in enumerate(res[:2000]):\n",
    "        print >>fout, '%d  Q0  %s  %d  %f  %s' % (qid, docid, rank, score, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KFold(fpath, K = 5, run_name = 'my_run',  batch_size=BATCH_SZ, qids = sorted( QUERIES.keys() )):\n",
    "    open(fpath,'w').close() # clear previous content in file \n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(qids)\n",
    "    fold_sz = len(qids) / K\n",
    "    for fold in xrange(K):\n",
    "        print 'fold %d' % fold, \n",
    "        val_start, val_end = fold*fold_sz, (fold+1)*fold_sz\n",
    "        qids_val = qids[val_start:val_end] # train/val queries for each fold \n",
    "        qids_train = qids[:val_start] + qids[val_end:]\n",
    "        print qids_val\n",
    "        idx_pairs_train = get_idx_pairs(qids_train)\n",
    "        idx_pairs_val = get_idx_pairs(qids_val)\n",
    "        \n",
    "        shuffle_weights(ranking_model, initial_weights) # reset model parameters\n",
    "        ranking_model.fit_generator( batch_generator(idx_pairs_train, batch_size=batch_size), # train model \n",
    "                    samples_per_epoch = len(idx_pairs_train)//batch_size*batch_size,\n",
    "                    nb_epoch=10,\n",
    "                    validation_data=batch_generator(idx_pairs_val, batch_size=batch_size),\n",
    "                    nb_val_samples=len(idx_pairs_val)//batch_size*batch_size, \n",
    "                    callbacks = _callbacks)\n",
    "        print 'fold %d complete, outputting to %s...' % (fold, fpath)\n",
    "        for qid in qids_val:\n",
    "            TREC_output(qid, run_name = run_name, fpath = fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 [15]\n",
      "Epoch 1/10\n",
      "156544/156544 [==============================] - 13s - loss: 0.1041 - ranking_acc: 0.4509 - val_loss: 0.1011 - val_ranking_acc: 0.4341\n",
      "Epoch 2/10\n",
      "156544/156544 [==============================] - 12s - loss: 0.1013 - ranking_acc: 0.4507 - val_loss: 0.1007 - val_ranking_acc: 0.4277\n",
      "Epoch 3/10\n",
      "156544/156544 [==============================] - 12s - loss: 0.1008 - ranking_acc: 0.4509 - val_loss: 0.1006 - val_ranking_acc: 0.4272\n",
      "Epoch 4/10\n",
      "156544/156544 [==============================] - 13s - loss: 0.1006 - ranking_acc: 0.4506 - val_loss: 0.1004 - val_ranking_acc: 0.4255\n",
      "Epoch 5/10\n",
      "156544/156544 [==============================] - 13s - loss: 0.1005 - ranking_acc: 0.4502 - val_loss: 0.1004 - val_ranking_acc: 0.4336\n",
      "Epoch 6/10\n",
      "156544/156544 [==============================] - 12s - loss: 0.1004 - ranking_acc: 0.4504 - val_loss: 0.1003 - val_ranking_acc: 0.4192\n",
      "Epoch 7/10\n",
      "156544/156544 [==============================] - 13s - loss: 0.1004 - ranking_acc: 0.4500 - val_loss: 0.1003 - val_ranking_acc: 0.4302\n",
      "Epoch 8/10\n",
      " 63360/156544 [===========>..................] - ETA: 7s - loss: 0.1004 - ranking_acc: 0.4514"
     ]
    }
   ],
   "source": [
    "KFold('../data/trec-output/0203_DRMM-embedding_LOO_10epoch.rankedlist', K=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "NOTE_DATA_DIR = '/local/XW/DATA/MIMIC/noteevents_by_sid/'\n",
    "ICD_FPATH = 'data/subject_diag_icds.txt'\n",
    "PK_FPATH = 'data/diag_processed_data.pk' # './processed_data_small.pk'\n",
    "N_LABELS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read k-hot labels data\n",
    "pk_data = pk.load(open(PK_FPATH, 'rb'))\n",
    "Y_train = pk_data['Y_train']\n",
    "Y_val = pk_data['Y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36917, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding_matrix',\n",
       " 'X_train',\n",
       " 'X_val',\n",
       " 'Y_val',\n",
       " 'Y_train',\n",
       " 'sid2khot',\n",
       " 'sid2seq']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multilabel_evaluate(y_pred, y_true=Y_val):\n",
    "    y_pred, y_true = y_pred[:,:-1], y_true[:,:-1] # test without last column considered\n",
    "#     print y_pred.shape, y_true.shape\n",
    "    tp = np.sum(y_true * y_pred, axis=-1) \n",
    "    sum_true = np.sum(y_true, axis=-1)\n",
    "    sum_pred = np.sum(y_pred, axis=-1)\n",
    "    union = np.sum(np.clip(y_true+y_pred, 0, 1), axis=-1)\n",
    "    print 'precision =', np.mean(tp/(sum_pred+1e-10))\n",
    "    print 'recall = ', np.mean(tp/(sum_true+1e-10))\n",
    "    print 'F1 = ', 2*np.mean(tp/(sum_true+sum_pred+1e-10))\n",
    "    print 'acc = ', np.mean(tp/(union+1e-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36917, 50) (9229, 50)\n",
      "[ 14021.   8595.   8119.   7855.   6168.   5990.   5872.   5258.   4578.\n",
      "   4558.   4390.   4220.   4196.   3952.   3483.   3409.   3296.   3015.\n",
      "   2882.   2810.   2829.   2718.   2670.   2539.   2362.   2304.   2348.\n",
      "   2286.   2225.   2198.   2226.   2214.   2175.   2128.   2028.   2020.\n",
      "   1897.   1852.   1854.   1866.   1847.   1815.   1787.   1713.   1642.\n",
      "   1642.   1638.   1591.   1599.  35142.]\n",
      "precision = 0.0\n",
      "recall =  0.0\n",
      "F1 =  0.0\n",
      "acc =  0.0\n"
     ]
    }
   ],
   "source": [
    "print Y_train.shape, Y_val.shape\n",
    "# print Y_train[:2,]\n",
    "stat = Y_train.sum(axis=0)\n",
    "print stat# naive algo just find which label is most common, then always predict this label\n",
    "pred_naive = stat > Y_train.shape[0]/2\n",
    "pred_naive = np.array(pred_naive, dtype=np.float64)\n",
    "# print pred_naive\n",
    "pred_naive = np.tile(pred_naive, (Y_val.shape[0],1))\n",
    "# print pred_naive.shape\n",
    "multilabel_evaluate(pred_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The problem with SVM is that for each instance, there are several labels, so I split each instance into several (instance, one-label) pairs... NOT SURE IF THIS MAKES SENSE. **\n",
    "\n",
    "This baseline use the method described at: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # prepare label data\n",
    "# N_LABELS = 50\n",
    "# K_ICDS_TOKEEP = N_LABELS - 1 # predict only on top K frequent icd codes\n",
    "# N_SUBJECTS = 46146\n",
    "# from collections import Counter\n",
    "# sid2icds = {} # map subject_id ---> icd codes of this patient\n",
    "# icd_ctr = Counter()\n",
    "# with open(ICD_FPATH) as f: \n",
    "#     for line in tqdm(f, total=N_SUBJECTS): \n",
    "#         sid, _icds = line.split(',')\n",
    "#         _icds = _icds.split()\n",
    "#         icd_ctr.update(_icds)\n",
    "#         sid2icds[sid] = set(_icds)\n",
    "# print icd_ctr.most_common(K_ICDS_TOKEEP)\n",
    "# icds = zip( *icd_ctr.most_common(K_ICDS_TOKEEP) )[0] + ('other',)\n",
    "# sid2khot = {} # map subject_id to k-hot vector\n",
    "# for sid in sid2icds.keys():\n",
    "#     _khot = np.zeros(N_LABELS)\n",
    "#     for _icd in sid2icds[sid]:\n",
    "#         if _icd in icds: \n",
    "#             _khot[icds.index(_icd)] = 1\n",
    "#         else: # label 'other icds'\n",
    "#             _khot[-1] = 1\n",
    "#     sid2khot[sid] = _khot\n",
    "# sids = sid2icds.keys()\n",
    "# np.random.shuffle(sids)\n",
    "# VALIDATION_SPLIT = 0.2\n",
    "# validset_sz = int(VALIDATION_SPLIT*len(sids))\n",
    "# train_sids = sids[:-validset_sz] \n",
    "# val_sids = sids[-validset_sz:]\n",
    "\n",
    "# Y_train = np.array([sid2khot[sid] for sid in train_sids])\n",
    "# Y_val = np.array([sid2khot[sid] for sid in val_sids])\n",
    "# print Y_train.shape, Y_val.shape\n",
    "\n",
    "# # To prepare training data for svm (tdidf), need to write our own generator of documents.\n",
    "# def notes_generator(fpaths):\n",
    "#     for fpath in tqdm(fpaths):\n",
    "#         df = pd.read_csv(fpath)\n",
    "#         yield '\\n=======\\n\\n\\n'.join(df['text'])\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# MAX_NB_WORDS = 20000 # top 20k most freq words\n",
    "# cnt_vect = CountVectorizer(max_features=MAX_NB_WORDS)\n",
    "\n",
    "# train_files = [os.path.join(NOTE_DATA_DIR, '%s.csv'%sid) for sid in train_sids]\n",
    "# X_train_counts = cnt_vect.fit_transform(notes_generator(train_files))\n",
    "# print X_train_counts.shape\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# print X_train_tfidf.shape\n",
    "\n",
    "# val_files = [os.path.join(NOTE_DATA_DIR, '%s.csv'%sid) for sid in val_sids]\n",
    "# X_val_counts = cnt_vect.fit_transform(notes_generator(val_files))\n",
    "# print X_val_counts.shape\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_val_tfidf = tfidf_transformer.fit_transform(X_val_counts)\n",
    "# print X_val_tfidf.shape\n",
    "\n",
    "# print X_train_tfidf.shape, Y_train.shape\n",
    "# Y_train_labels = [Y_train[:,i] for i in xrange(Y_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# description = '''\n",
    "# this file contains the tfidf vectors for svm baseline'''\n",
    "# data_svm = {\n",
    "#     'description': description,\n",
    "#     'X_train': X_train_tfidf,\n",
    "#     'Y_train': Y_train,\n",
    "#     'X_val': X_val_tfidf,\n",
    "#     'Y_val': Y_val,\n",
    "#     'train_sids': train_sids,\n",
    "#     'val_sids': val_sids\n",
    "# }\n",
    "# pk.dump(data_svm, open('data/data_tfidf_svm.pk','wb'), pk.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_val',\n",
       " 'X_train',\n",
       " 'description',\n",
       " 'Y_val',\n",
       " 'Y_train',\n",
       " 'val_sids',\n",
       " 'train_sids']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_svm = pk.load(open('data/data_tfidf_svm.pk', 'rb'))\n",
    "data_svm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = data_svm['X_train']\n",
    "Y_train = data_svm['Y_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train 50 independent SVM classifiers**.   \n",
    "To prepare training data for svm (tdidf), need to write our own **generator** of documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** generate 0/1 label for each class ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [24:09<00:00, 26.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "precision = 0.056609600168\n",
      "recall =  0.0166419177699\n",
      "F1 =  0.0233054839194\n",
      "acc =  0.0158157916279\n"
     ]
    }
   ],
   "source": [
    "clfs2 = []\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1)\n",
    "    clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                   class_weight='balanced',\n",
    "                   alpha=1e-3, n_iter=200, random_state=1)\n",
    "    clf.fit(X_train_tfidf, Y_train_labels[i]) \n",
    "    clfs2.append(clf)\n",
    "preds = [clfs2[i].predict(X_val_tfidf) for i in xrange(N_LABELS)]    \n",
    "pred_svm2 = np.vstack(preds).T\n",
    "print pred_svm2.shape\n",
    "multilabel_evaluate(pred_svm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [23:16<00:00, 24.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "precision = 0.101886031631\n",
      "recall =  0.292810015915\n",
      "F1 =  0.138220455238\n",
      "acc =  0.0802666842077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "clfs = []\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1)\n",
    "    clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                   class_weight='balanced',\n",
    "                   alpha=1e-2, n_iter=200, random_state=1)\n",
    "    clf.fit(X_train_tfidf, Y_train_labels[i]) \n",
    "    clfs.append(clf)\n",
    "preds = [clfs[i].predict(X_val_tfidf) for i in xrange(N_LABELS)]    \n",
    "pred_svm = np.vstack(preds).T\n",
    "print pred_svm.shape\n",
    "multilabel_evaluate(pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best result for svm-tfidf vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [25:04<00:00, 29.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "precision = 0.112945553919\n",
      "recall =  0.517047153819\n",
      "F1 =  0.174670895744\n",
      "acc =  0.103387535765\n"
     ]
    }
   ],
   "source": [
    "clfs3 = []\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1)\n",
    "    clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                   class_weight='balanced',\n",
    "                   alpha=1e-1, n_iter=200, random_state=1)\n",
    "    clf.fit(X_train_tfidf, Y_train_labels[i]) \n",
    "    clfs3.append(clf)\n",
    "preds = [clfs3[i].predict(X_val_tfidf) for i in xrange(N_LABELS)]    \n",
    "pred_svm3 = np.vstack(preds).T \n",
    "print pred_svm3.shape\n",
    "multilabel_evaluate(pred_svm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep patient baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sid2khot = pk_data['sid2khot'] # maps sid(int) to khot encoding of Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid2khot[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pk.load(open('./data/feature_DP_st_cui.pk'))\n",
    "dpvecs = data['Xdp']\n",
    "sid2rowidx = data['sid2rowidx'] # map sid(int) to row index in deep patient feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46146, 46146)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sid2rowidx), len(sid2khot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79423 22600 88696 ...,  1326  2368 27617]\n"
     ]
    }
   ],
   "source": [
    "sids = np.array(sid2rowidx.keys())\n",
    "np.random.shuffle(sids)\n",
    "print sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sid_train, sid_val = sids[int(len(sids)*VALIDATION_SPLIT):], sids[:int(len(sids)*VALIDATION_SPLIT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36917, 9229)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sid_train), len(sid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36917, 500) (36917, 50)\n",
      "(9229, 500) (9229, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = [],[]\n",
    "for sid in sid_train:\n",
    "    X_train.append(dpvecs[sid2rowidx[sid]])\n",
    "    Y_train.append(sid2khot[sid])\n",
    "X_train = np.vstack(X_train)\n",
    "Y_train = np.vstack(Y_train)\n",
    "print X_train.shape, Y_train.shape\n",
    "\n",
    "X_val, Y_val = [],[]\n",
    "for sid in sid_val:\n",
    "    X_val.append(dpvecs[sid2rowidx[sid]])\n",
    "    Y_val.append(sid2khot[sid])\n",
    "X_val = np.vstack(X_val)\n",
    "Y_val = np.vstack(Y_val)\n",
    "print X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13966.,   8617.,   8183.,   7832.,   6078.,   5923.,   5862.,\n",
       "         5291.,   4576.,   4551.,   4352.,   4249.,   4209.,   3951.,\n",
       "         3461.,   3382.,   3285.,   3009.,   2870.,   2784.,   2808.,\n",
       "         2697.,   2713.,   2534.,   2394.,   2331.,   2312.,   2294.,\n",
       "         2250.,   2228.,   2189.,   2226.,   2156.,   2098.,   2065.,\n",
       "         2048.,   1879.,   1837.,   1828.,   1849.,   1842.,   1800.,\n",
       "         1809.,   1722.,   1667.,   1643.,   1665.,   1604.,   1580.,\n",
       "        35126.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3544.,  2119.,  2010.,  1970.,  1556.,  1498.,  1470.,  1341.,\n",
       "        1170.,  1127.,  1088.,  1071.,  1037.,  1016.,   930.,   849.,\n",
       "         835.,   780.,   702.,   720.,   695.,   690.,   649.,   650.,\n",
       "         588.,   576.,   590.,   595.,   564.,   561.,   594.,   549.,\n",
       "         551.,   545.,   489.,   486.,   497.,   481.,   474.,   450.,\n",
       "         455.,   447.,   432.,   432.,   410.,   429.,   390.,   405.,\n",
       "         398.,  8803.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [08:08<00:00,  9.00s/it]\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1,C=0.2)\n",
    "    clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                   class_weight='balanced',\n",
    "                   alpha=1e-1, n_iter=200, random_state=1)\n",
    "    clf.fit(X_train, Y_train[:,i]) \n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "[8053, 5722, 3457, 2928, 2233, 5700, 3102, 2234, 3516, 4000, 3443, 74, 4665, 3628, 2182, 3721, 2271, 237, 3839, 1627, 4038, 2174, 1275, 3080, 9229, 1571, 8994, 1724, 1602, 3144, 8047, 1019, 2989, 0, 2330, 2851, 1415, 0, 6704, 1344, 1092, 7195, 1449, 1606, 3024, 4284, 6485, 9229, 3261, 4220]\n",
      "precision = 0.148951811811\n",
      "recall =  0.551990251712\n",
      "F1 =  0.222779680756\n",
      "acc =  0.137435773717\n"
     ]
    }
   ],
   "source": [
    "preds = [clfs[i].predict(X_val) for i in xrange(N_LABELS)]    \n",
    "pred_svm_dp = np.vstack(preds).T\n",
    "print pred_svm_dp.shape\n",
    "print map(int, pred_svm_dp.sum(axis=0))\n",
    "multilabel_evaluate(y_pred=pred_svm_dp,y_true=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:39<00:00,  6.45s/it]\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1,C=0.2)\n",
    "    clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                   class_weight='balanced',\n",
    "                   alpha=1e-2, n_iter=200, random_state=1)\n",
    "    clf.fit(X_train, Y_train[:,i]) \n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "[8926, 11, 3371, 4719, 0, 3624, 4619, 3316, 4650, 3709, 2215, 0, 0, 5963, 2945, 4799, 5467, 19, 2796, 3432, 4559, 3152, 11, 5863, 71, 9173, 722, 4468, 2933, 4456, 252, 177, 3033, 0, 3536, 7988, 55, 0, 5261, 0, 131, 8269, 1785, 3812, 2904, 3602, 5455, 5955, 2524, 5641]\n",
      "precision = 0.153250140609\n",
      "recall =  0.515069144766\n",
      "F1 =  0.223008806094\n",
      "acc =  0.13826199174\n"
     ]
    }
   ],
   "source": [
    "preds = [clfs[i].predict(X_val) for i in xrange(N_LABELS)]    \n",
    "pred_svm_dp = np.vstack(preds).T\n",
    "print pred_svm_dp.shape\n",
    "print map(int, pred_svm_dp.sum(axis=0))\n",
    "multilabel_evaluate(y_pred=pred_svm_dp,y_true=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:52<00:00,  7.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "[8856, 8359, 2301, 7038, 61, 22, 7776, 2642, 615, 3654, 2094, 592, 0, 7911, 3833, 1356, 2706, 13, 3701, 0, 4872, 2029, 286, 8248, 5515, 9229, 565, 566, 6877, 5756, 122, 71, 3696, 0, 4335, 5679, 34, 0, 0, 0, 156, 9229, 655, 4576, 2321, 5047, 1978, 8277, 2690, 6678]\n",
      "precision = 0.151102121967\n",
      "recall =  0.531224538279\n",
      "F1 =  0.223866185888\n",
      "acc =  0.136047328727\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1,C=0.2)\n",
    "    clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "                   class_weight='balanced',\n",
    "                   alpha=1e-3, n_iter=200, random_state=1)\n",
    "    clf.fit(X_train, Y_train[:,i]) \n",
    "    clfs.append(clf)\n",
    "preds = [clfs[i].predict(X_val) for i in xrange(N_LABELS)]    \n",
    "pred_svm_dp = np.vstack(preds).T\n",
    "print pred_svm_dp.shape\n",
    "print map(int, pred_svm_dp.sum(axis=0))\n",
    "multilabel_evaluate(y_pred=pred_svm_dp,y_true=Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use grid search to find best param for each svm clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [50:05<00:00, 56.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9229, 50)\n",
      "[8053, 5722, 3457, 2928, 2233, 5700, 3102, 2234, 3516, 4000, 3443, 74, 4665, 3628, 2182, 3721, 2271, 237, 3839, 1627, 4038, 2174, 1275, 3080, 9229, 1571, 8994, 1724, 1602, 3144, 8047, 1019, 2989, 0, 2330, 2851, 1415, 0, 6704, 1344, 1092, 7195, 1449, 1606, 3024, 4284, 6485, 9229, 3261, 4220]\n",
      "precision = 0.148951811811\n",
      "recall =  0.551990251712\n",
      "F1 =  0.222779680756\n",
      "acc =  0.137435773717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "              'alpha': [1, 1e-1, 3e-1, 1e-2, 3e-2, 1e-3, 3e-3, 1e-4],\n",
    "              'n_iter': [10, 50, 200]}\n",
    "\n",
    "for i in tqdm(range(N_LABELS)):\n",
    "    sgd =  SGDClassifier(loss='hinge', penalty='l2', random_state=1, class_weight='balanced')\n",
    "    clf = GridSearchCV(sgd, parameters, n_jobs=-1)\n",
    "    clf.fit(X_train, Y_train[:,i]) \n",
    "    clfs.append(clf)\n",
    "\n",
    "preds = [clfs[i].predict(X_val) for i in xrange(N_LABELS)]    \n",
    "pred_svm = np.vstack(preds).T\n",
    "print pred_svm.shape\n",
    "print map(int, pred_svm.sum(axis=0))\n",
    "multilabel_evaluate(y_pred=pred_svm, y_true=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clfs = []\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# for i in tqdm(range(N_LABELS)):\n",
    "#     clf = SVC(class_weight='balanced',random_state=1,C=1.0)\n",
    "# #     clf =  SGDClassifier(loss='hinge', penalty='l2', \n",
    "# # #                    class_weight='balanced',\n",
    "# #                    alpha=1e-2, n_iter=200, random_state=1)\n",
    "#     clf.fit(X_train, Y_train[:,i]) \n",
    "#     clfs.append(clf)\n",
    "# preds = [clfs[i].predict(X_val) for i in xrange(N_LABELS)]    \n",
    "# pred_svm_dp = np.vstack(preds).T\n",
    "# print pred_svm_dp.shape\n",
    "# print map(int, pred_svm_dp.sum(axis=0))\n",
    "# multilabel_evaluate(y_pred=pred_svm_dp,y_true=Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVM + vector generated by our CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

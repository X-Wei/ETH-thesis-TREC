{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "import os, nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_tree = etree.parse('data/topics2016.xml')\n",
    "\n",
    "def get_topic(i):# returns the summary string of the ith topic\n",
    "    summary = topic_tree.xpath('//topic[@number=\"%d\"]/summary/text()'%i)[0]\n",
    "    return str(summary).lower()\n",
    "\n",
    "# build a mapping of article name (PMCID) to its file path\n",
    "\n",
    "PMC_PATH = '/local/XW/DATA/TREC/PMCs/'\n",
    "pmcid2fpath = {}\n",
    "\n",
    "for subdir1 in os.listdir(PMC_PATH):\n",
    "    for subdir2 in os.listdir(os.path.join(PMC_PATH, subdir1)):\n",
    "        diry = os.path.join(PMC_PATH, subdir1, subdir2)\n",
    "#         print diry, len(os.listdir(diry))\n",
    "        for fn in os.listdir(diry):\n",
    "            pmcid = fn[:-5]\n",
    "            fpath = os.path.join(diry, fn)\n",
    "            pmcid2fpath[pmcid] = fpath\n",
    "\n",
    "def get_article_abstract(pmcid):\n",
    "    fpath = pmcid2fpath[pmcid]\n",
    "    tree = etree.parse(fpath)\n",
    "    abstract = tree.xpath('//abstract')[0]\n",
    "    ret = u''+abstract.xpath('string(.)')\n",
    "    if len(ret.split())<20: raise Exception('abstraction too short:'+pmcid)\n",
    "    return ret.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37707/37707 [05:47<00:00, 108.38it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "pmcid_2relevance = [{} for i in xrange(31)] # list of dict mapping pmcid to relevance\n",
    "with open('data/qrels.txt') as f:\n",
    "    for line in tqdm(f, total=37707): \n",
    "        topicid, _, pmcid, relevance = line.split()\n",
    "        topicid = int(topicid)\n",
    "        try:\n",
    "            corpus.append(get_article_abstract(pmcid)) # !some articles don't have an abstract!\n",
    "            pmcid_2relevance[topicid][pmcid] = int(relevance)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34289 articles are retrieved\n"
     ]
    }
   ],
   "source": [
    "print '%d articles are retrieved' % len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(corpus)\n",
    "\n",
    "def get_idf(wd):\n",
    "    if wd not in vectorizer.vocabulary_: return 1.0\n",
    "    return vectorizer.idf_[ vectorizer.vocabulary_[wd] ]\n",
    "\n",
    "vocab = set(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2V_FPATH = '/local/XW/DATA/WORD_EMBEDDINGS/biomed-w2v-200.txt'\n",
    "GLOVE_FPATH = '/local/XW/DATA/WORD_EMBEDDINGS/glove.6B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5443657/5443657 [01:00<00:00, 89801.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 54911 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec = {} # maps word ---> embedding vector\n",
    "with open(W2V_FPATH) as f:\n",
    "    for line in tqdm(f, total=5443657): #5443657 400000\n",
    "        vals = line.split()\n",
    "        word = vals[0]\n",
    "        if word in vocab:\n",
    "            vec = np.asarray(vals[1:], dtype='float')\n",
    "            word2vec[word] = vec\n",
    "print 'found %d word vectors.' % len(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwds = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76-year-old female with personal history of diastolic congestive heart failure, atrial fibrillation on coumadin, presenting with low hematocrit and dyspnea.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_queries = [get_topic(i) for i in xrange(1,21)] # top 20 topics' queries\n",
    "QUERIES = []\n",
    "for q in _queries:\n",
    "    q2 = [wd for wd in q.split() if (wd not in stopwds) and (wd in word2vec)] # filter out stopword and words not in w2v\n",
    "    QUERIES.append(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 14, 26, 11, 12, 20, 16, 11, 13, 12, 14, 13, 23, 11, 40, 16, 11, 19, 20, 16]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(len, QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 40 # = max query length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WD_PLACEHOLDER = '</s>'\n",
    "def pad_query(q, SZ=40):\n",
    "    return q + [WD_PLACEHOLDER]*(SZ-len(q))\n",
    "QUERIES = map(pad_query, QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randvec = np.random.randn(200)\n",
    "def get_histvec(q_wd, doc):\n",
    "    if q_wd == WD_PLACEHOLDER: return np.zeros(30)\n",
    "    qvec = word2vec.get(q_wd, randvec)\n",
    "#     dvecs = np.vstack( [word2vec.get(wd, randvec) for wd in nltk.word_tokenize(doc)] )\n",
    "    words_doc = filter(lambda wd:wd in word2vec, nltk.word_tokenize(doc))\n",
    "    dvecs = np.vstack( [ word2vec[wd] for wd in words_doc ] )\n",
    "    cossims = np.dot(dvecs, qvec) / norm(qvec) / norm(dvecs, axis=1)\n",
    "    hist, _ = np.histogram( cossims[cossims<1.0], bins=29, range=(-1,1) )\n",
    "    ones = len(cossims) - sum(hist)\n",
    "    ret = np.array( list(hist) + [ones] )\n",
    "    return ret # np.reshape(ret, (-1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_doc_feature(query, pmcid): # query: list of words\n",
    "    doc = get_article_abstract(pmcid)\n",
    "    return np.array([ get_histvec(wd, doc) for wd in query])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 355/1328 [00:07<00:18, 53.10it/s]"
     ]
    }
   ],
   "source": [
    "pos_ids, neg_ids = [], [] # pos_ids[q] is a list (positive pmcids for query `q`)\n",
    "hists_pos, hists_neg = [], [] # hists_pos[q] is a list (positive hists for query `q`)\n",
    "                              # hists_pos[q][i] is an array of size N*30 (the ith hists-feature array for query q)\n",
    "for topic in xrange(1,6):\n",
    "    query = QUERIES[topic-1]\n",
    "    pos_ids_q, neg_ids_q = [], []\n",
    "    hists_pos_q, hists_neg_q = [], []\n",
    "    relevance = pmcid_2relevance[topic]\n",
    "    for pmcid in tqdm(relevance.keys()):\n",
    "        if relevance[pmcid]==0: \n",
    "            neg_ids_q.append(pmcid)\n",
    "            hists_neg_q.append(get_query_doc_feature(query,pmcid))\n",
    "        else: \n",
    "            pos_ids_q.append(pmcid)\n",
    "            hists_pos_q.append(get_query_doc_feature(query,pmcid))\n",
    "    hists_pos_q, hists_neg_q = map(np.array, [hists_pos_q, hists_neg_q])\n",
    "    hists_pos.append(hists_pos_q); hists_neg.append(hists_neg_q)\n",
    "    pos_ids.append(pos_ids_q); neg_ids.append(neg_ids_q)\n",
    "print len(pos_ids), len(neg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VALDATION_SPLIT = 0.2\n",
    "BATCH_SZ = 128\n",
    "NB_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124, 34]\n",
      "[1204, 1153]\n"
     ]
    }
   ],
   "source": [
    "print map(len, hists_pos)\n",
    "print map(len, hists_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150799, 3) (37699, 3)\n"
     ]
    }
   ],
   "source": [
    "idx_pairs = [] # list of tuples of form (q, pos_idx, neg_idx)\n",
    "for q in xrange(2):\n",
    "    hists_pos_q, hists_neg_q = hists_pos[q], hists_neg[q]\n",
    "    for pidx in xrange(len(hists_pos_q)):\n",
    "        for nidx in xrange(len(hists_neg_q)):\n",
    "            idx_pairs.append( (q, pidx, nidx) )\n",
    "idx_pairs = np.array(idx_pairs)\n",
    "val_sz = int(len(idx_pairs)*VALDATION_SPLIT)\n",
    "idx_pairs_train, idx_pairs_val = idx_pairs[val_sz:], idx_pairs[:val_sz]\n",
    "\n",
    "print idx_pairs_train.shape, idx_pairs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0, 0, 1, 0, 0, 1, 0, 0, 0),\n",
       " (30, 117, 43, 15, 121, 47, 0, 76, 71, 109),\n",
       " (602, 416, 878, 114, 1195, 178, 840, 891, 148, 1078)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_batch = idx_pairs_train[:10]\n",
    "zip(*idx_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDFs = [ np.array ([ get_idf(wd) for wd in query]) for query in QUERIES]\n",
    "IDFs = np.array(IDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(idx_pairs, batch_size=BATCH_SZ): \n",
    "    np.random.shuffle(idx_pairs)\n",
    "    batches_pre_epoch = len(idx_pairs) // batch_size\n",
    "    samples_per_epoch = batches_pre_epoch * batch_size # make samples_per_epoch a multiple of batch size\n",
    "    counter = 0\n",
    "    y_true_batch_dummy = np.ones((batch_size))\n",
    "    while 1:\n",
    "        idx_batch = idx_pairs[batch_size*counter: min(samples_per_epoch, batch_size*(counter+1))]\n",
    "#         q_batch, pidx_batch, nidx_batch = zip(*idx_batch)\n",
    "#         idfs_batch = IDFs[q_batch,]\n",
    "#         pos_batch = hists_pos[q_batch, pidx_batch]\n",
    "#         neg_batch = hists_neg[q_batch, nidx_batch]\n",
    "        idfs_batch, pos_batch, neg_batch = [], [], []\n",
    "        for q, pidx, nidx in idx_batch:\n",
    "            query = QUERIES[q]\n",
    "            _idfs = np.array([get_idf(wd) for wd in query])\n",
    "            idfs_batch.append(_idfs)\n",
    "            pos_batch.append(hists_pos[q][pidx])\n",
    "            neg_batch.append(hists_neg[q][nidx])\n",
    "        idfs_batch, pos_batch, neg_batch = map(np.array, [idfs_batch, pos_batch, neg_batch])\n",
    "#         print idfs_batch.shape, pos_batch.shape, neg_batch.shape\n",
    "        counter += 1\n",
    "        if (counter >= batches_pre_epoch):\n",
    "            np.random.shuffle(idx_pairs)\n",
    "            counter=0\n",
    "        \n",
    "        yield [idfs_batch, pos_batch, neg_batch], y_true_batch_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Define the deep relevance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# define a function for visualization of model\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "def viz_model(model):\n",
    "    return SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct the relevance IR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, InputLayer, Flatten, Input, Merge, merge, Reshape\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 main components of the structure: feed forward network and gating\n",
    "feed_forward = Sequential(\n",
    "    [Dense(input_dim=30, output_dim=5, activation='tanh'),\n",
    "     Dense(output_dim=1, activation='tanh')], \n",
    "    name='feed_forward_nw')\n",
    "\n",
    "# ***note: have to wrap ops into Lambda layers !!***\n",
    "# cf: https://groups.google.com/forum/#!topic/keras-users/fbRS-FkZw_Q\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "input_idf = Input(shape=(N,), name='input_idf')\n",
    "def scale(x): \n",
    "    w = K.variable(1, name='w_g')\n",
    "    return K.mul(x,w)\n",
    "def scale_output_shape(input_shape): return input_shape\n",
    "\n",
    "scaled = Lambda(scale, scale_output_shape, name='softmax_scale')(input_idf)\n",
    "gs_out = Activation('softmax', name='softmax')(scaled)\n",
    "gating = Model(input=input_idf, output=gs_out, name='gating')\n",
    "\n",
    "# first input: hist vectors\n",
    "input_hists = Input(shape=(N,30), name='input_hists')\n",
    "\n",
    "def slicei(x, i): return x[:,i,:]\n",
    "def slicei_output_shape(input_shape): return (input_shape[0], input_shape[2])\n",
    "zs = [ feed_forward( Lambda(lambda x:slicei(x,i), slicei_output_shape, name='slice%d'%i)(input_hists) )\\\n",
    "          for i in xrange(N) ]\n",
    "\n",
    "def concat(x): return K.concatenate(x) \n",
    "def concat_output_shape(input_shape): return (input_shape[0][0], N)\n",
    "zs = Lambda(concat, concat_output_shape, name='concat_zs')(zs)\n",
    "\n",
    "# second input: idf scores of each query term \n",
    "input_idf = Input(shape=(N,), name='input_idf')\n",
    "gs = gating(input_idf)\n",
    "\n",
    "def innerprod(x): return K.sum( K.mul(x[0],x[1]), axis=1)\n",
    "def innerprod_output_shape(input_shape): return (input_shape[0][0],1)\n",
    "scores = Lambda(innerprod, innerprod_output_shape, name='innerprod_zs_gs')([zs, gs])\n",
    "\n",
    "scoring_model = Model(input=[input_idf, input_hists], output=[scores], name='scoring_model')\n",
    "\n",
    "# third input -- the negative hists vector \n",
    "input_hists_neg = Input(shape=(N,30), name='input_hists_neg')\n",
    "\n",
    "zs_neg = [ feed_forward( Lambda(lambda x:slicei(x,i), slicei_output_shape, name='slice%d_neg'%i)(input_hists_neg) )\\\n",
    "          for i in xrange(N) ]\n",
    "\n",
    "zs_neg = Lambda(concat, concat_output_shape, name='concat_zs_neg')(zs_neg)\n",
    "\n",
    "scores_neg = Lambda(innerprod, innerprod_output_shape, name='innerprod_zs_gs_neg')([zs_neg, gs])\n",
    "\n",
    "two_score_model = Model(input=[input_idf, input_hists, input_hists_neg], \n",
    "                        output=[scores, scores_neg], \n",
    "                        name='two_score_model')\n",
    "\n",
    "def diff(x): return tf.sub(x[0], x[1]) #x[0]-x[1]\n",
    "def diff_output_shape(input_shape): return input_shape[0]\n",
    "posneg_score_diff = Lambda(diff, diff_output_shape, name='posneg_score_diff')([scores, scores_neg])\n",
    "ranking_model = Model(input=[input_idf, input_hists,  input_hists_neg]\n",
    "                      , output=[posneg_score_diff]\n",
    "                      , name='ranking_model')\n",
    "\n",
    "# define my loss function: hinge of score_pos - score_neg\n",
    "def pairwise_hinge(y_true, y_pred): # y_pred = score_pos - score_neg, **y_true doesn't matter here**\n",
    "    return K.mean( K.maximum(1. - y_pred, y_true*0.0) )  \n",
    "\n",
    "ranking_model.compile(optimizer='adagrad', loss=pairwise_hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. train model (for topic-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model using `fit_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# self-defined metrics\n",
    "def ranking_acc(y_true, y_pred):\n",
    "    y_pred = y_pred > 0 \n",
    "    return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranking_model.compile(optimizer='adagrad', loss=pairwise_hinge, metrics=[ranking_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150784/150784 [==============================] - 596s - loss: 0.4211 - ranking_acc: 0.8264 - val_loss: 0.4586 - val_ranking_acc: 0.8317\n",
      "Epoch 2/20\n",
      "150784/150784 [==============================] - 578s - loss: 0.4199 - ranking_acc: 0.8273 - val_loss: 0.4545 - val_ranking_acc: 0.8334\n",
      "Epoch 3/20\n",
      "150784/150784 [==============================] - 571s - loss: 0.4184 - ranking_acc: 0.8280 - val_loss: 0.4533 - val_ranking_acc: 0.8341\n",
      "Epoch 4/20\n",
      "150784/150784 [==============================] - 567s - loss: 0.4168 - ranking_acc: 0.8288 - val_loss: 0.4520 - val_ranking_acc: 0.8347\n",
      "Epoch 5/20\n",
      "150784/150784 [==============================] - 568s - loss: 0.4154 - ranking_acc: 0.8299 - val_loss: 0.4521 - val_ranking_acc: 0.8348\n",
      "Epoch 6/20\n",
      "150784/150784 [==============================] - 566s - loss: 0.4143 - ranking_acc: 0.8305 - val_loss: 0.4514 - val_ranking_acc: 0.8349\n",
      "Epoch 7/20\n",
      "150784/150784 [==============================] - 571s - loss: 0.4132 - ranking_acc: 0.8310 - val_loss: 0.4495 - val_ranking_acc: 0.8366\n",
      "Epoch 8/20\n",
      "150784/150784 [==============================] - 566s - loss: 0.4123 - ranking_acc: 0.8314 - val_loss: 0.4498 - val_ranking_acc: 0.8337\n",
      "Epoch 9/20\n",
      "150784/150784 [==============================] - 580s - loss: 0.4114 - ranking_acc: 0.8318 - val_loss: 0.4502 - val_ranking_acc: 0.8328\n",
      "Epoch 10/20\n",
      "150784/150784 [==============================] - 587s - loss: 0.4106 - ranking_acc: 0.8323 - val_loss: 0.4509 - val_ranking_acc: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4bc6a36650>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = './log/relevance_matching'\n",
    "_callbacks = [ EarlyStopping(monitor='val_loss', patience=2),\n",
    "               TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=False) ]\n",
    "# 30-5-1 tanh\n",
    "ranking_model.fit_generator( batch_generator(idx_pairs_train), \n",
    "                    samples_per_epoch = len(idx_pairs_train)//BATCH_SZ*BATCH_SZ,\n",
    "                    nb_epoch=NB_EPOCH,\n",
    "                    validation_data=batch_generator(idx_pairs_val),\n",
    "                    nb_val_samples=len(idx_pairs_val)//BATCH_SZ*BATCH_SZ, \n",
    "                    callbacks = _callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## below are some testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3429740', '3921765'),\n",
       " ('2999735', '4085271'),\n",
       " ('3526517', '4532844'),\n",
       " ('1750992', '2769307'),\n",
       " ('3503351', '3809984'),\n",
       " ('4130891', '4685986'),\n",
       " ('4471306', '2996340'),\n",
       " ('3286730', '4395018'),\n",
       " ('4659952', '28994'),\n",
       " ('4724023', '4716452')]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(pos_ids[0][:10], neg_ids[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 40) (2, 40, 30)\n"
     ]
    }
   ],
   "source": [
    "pos_sample = get_query_doc_feature(query, '3429740')\n",
    "neg_sample = get_query_doc_feature(query, '3921765')\n",
    "pair_sample = np.array([pos_sample, neg_sample])\n",
    "query = QUERIES[0]\n",
    "_idf = np.array([get_idf(wd) for wd in query])\n",
    "idf_sample = np.vstack([_idf]*2)\n",
    "\n",
    "print idf_sample.shape, pair_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test `scoring_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.73008156, -0.47747353], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model.predict([idf_sample,pair_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81683552]\n",
      " [-0.82646966]\n",
      " [-0.99879682]\n",
      " [-0.99982327]\n",
      " [-0.85237795]\n",
      " [-0.81685901]\n",
      " [-0.81277031]\n",
      " [-0.70481849]\n",
      " [-0.8772012 ]\n",
      " [ 0.20669119]\n",
      " [-0.62638611]\n",
      " [-0.81685901]\n",
      " [-0.81684172]\n",
      " [-0.8168422 ]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]\n",
      " [ 0.58492392]]\n"
     ]
    }
   ],
   "source": [
    "a = feed_forward.predict(pos_sample)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11612402  0.00800367  0.00871019  0.02551604  0.0907026   0.06773899\n",
      "  0.60106444  0.0024891   0.0024891   0.0024891   0.0024891   0.0024891\n",
      "  0.0024891   0.0024891   0.0024891   0.0024891   0.0024891   0.0024891\n",
      "  0.0024891   0.0024891   0.0024891   0.0024891   0.0024891   0.0024891\n",
      "  0.0024891   0.0024891   0.0024891   0.0024891   0.0024891   0.0024891\n",
      "  0.0024891   0.0024891   0.0024891   0.0024891   0.0024891   0.0024891\n",
      "  0.0024891   0.0024891   0.0024891   0.0024891 ]\n"
     ]
    }
   ],
   "source": [
    "b = gating.predict(idf_sample)[0]\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7300815], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87186098]\n",
      " [ 0.7142241 ]\n",
      " [-0.96034747]\n",
      " [ 0.94236648]\n",
      " [-0.3230921 ]\n",
      " [ 0.99326599]\n",
      " [-0.93802834]\n",
      " [ 0.99049699]\n",
      " [-0.08088312]\n",
      " [ 0.98430783]\n",
      " [ 0.87186098]]\n",
      "[ 0.44491631]\n"
     ]
    }
   ],
   "source": [
    "c = feed_forward.predict(neg_sample)\n",
    "print c\n",
    "print b.dot(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> the scoring model works all right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test ranking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25260803,  0.25260803], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_model.predict( [idf_sample, pair_sample, np.array([neg_sample, pos_sample]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25260803000000004"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.73008156 - -0.47747353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(pmcid):\n",
    "    _idf = np.array([get_idf(wd) for wd in query])\n",
    "    _idf = np.vstack([_idf])\n",
    "    _hist = get_query_doc_feature(query, pmcid).reshape(1,N,30)\n",
    "    return scoring_model.predict([_idf, _hist])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35019341"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score('3429740')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### see some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.35019341, 0.30549839),\n",
       " (0.37719917, -0.70841134),\n",
       " (0.38686728, -0.66828567),\n",
       " (-0.60399097, 0.36510727),\n",
       " (-0.7060799, -0.68677717),\n",
       " (0.33125544, 0.021299459),\n",
       " (0.35732347, -0.79787028),\n",
       " (0.37714282, -0.69743919),\n",
       " (0.37723261, -0.70512909),\n",
       " (0.48084351, -0.76500708)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip( map(predict_score, pos_ids[0][:10]), map(predict_score, neg_ids[0][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score_diff( (pmcid_pos, pmcid_neg) ):\n",
    "    _idf = np.array([get_idf(wd) for wd in query.split()])\n",
    "    _idf = np.vstack([_idf])\n",
    "    hist_pos = get_query_doc_feature(query, pmcid_pos).reshape((1,11,30))\n",
    "    hist_neg = get_query_doc_feature(query, pmcid_neg).reshape((1,11,30))\n",
    "    return ranking_model.predict([_idf, hist_pos, hist_neg])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the scoring model (metrics=AP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AP(pos_scores, neg_scores):\n",
    "    Q = len(pos_scores)\n",
    "    pos_tags = [1] * len(pos_scores)\n",
    "    neg_tags = [0] * len(neg_scores)\n",
    "    all_tagged = zip(pos_scores, pos_tags) + zip(neg_scores, neg_tags)\n",
    "    ranked_list = sorted(all_tagged, reverse=True)\n",
    "    print ranked_list[:20]\n",
    "    ranked_tag = zip(*ranked_list)[1]\n",
    "    print ranked_tag[:20]\n",
    "    precision_at_i = []\n",
    "    corr, total = 0.0, 0\n",
    "    while corr<Q:\n",
    "        if ranked_tag[total]==1: \n",
    "            corr += 1\n",
    "            precision_at_i.append(corr*1.0 / (total+1) )\n",
    "        total += 1\n",
    "    print precision_at_i[:20]\n",
    "    return np.mean(precision_at_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AP_of_topic(q):\n",
    "    query = QUERIES[q]\n",
    "    _idf = np.array([get_idf(wd) for wd in query])\n",
    "    _idfs = np.vstack([_idf]*len(hists_pos[q]))\n",
    "    pos_scores = scoring_model.predict( [ _idfs, hists_pos[q]])\n",
    "    _idfs = np.vstack([_idf]*len(hists_neg[q]))\n",
    "    neg_scores = scoring_model.predict( [ _idfs, hists_neg[q]])\n",
    "    print 'mean:', pos_scores.mean(), neg_scores.mean()\n",
    "    print 'max:',pos_scores.max(), neg_scores.max()\n",
    "    print 'min:',pos_scores.min(), neg_scores.min()\n",
    "    return AP(pos_scores, neg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.192697 -0.492493\n",
      "max: 0.582177 0.585927\n",
      "min: -0.800651 -0.843911\n",
      "[(0.58592725, 0), (0.58572489, 0), (0.5857085, 0), (0.58217734, 1), (0.58211708, 0), (0.57812393, 1), (0.56911486, 0), (0.56231618, 0), (0.54702652, 0), (0.54344326, 1), (0.52571243, 0), (0.52161843, 1), (0.5163936, 0), (0.51093429, 0), (0.50954407, 1), (0.50019461, 1), (0.4983612, 1), (0.49835235, 0), (0.49779099, 1), (0.48898831, 0)]\n",
      "(0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0)\n",
      "[0.25, 0.3333333333333333, 0.3, 0.3333333333333333, 0.3333333333333333, 0.375, 0.4117647058823529, 0.42105263157894735, 0.4090909090909091, 0.4166666666666667, 0.3793103448275862, 0.3870967741935484, 0.3611111111111111, 0.358974358974359, 0.375, 0.38095238095238093, 0.3541666666666667, 0.3673469387755102, 0.38, 0.38461538461538464]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32909877623586348"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_of_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.0839959 -0.612511\n",
      "max: 0.769786 0.854114\n",
      "min: -0.872192 -0.98742\n",
      "[(0.85411352, 0), (0.84318459, 0), (0.825872, 0), (0.81277239, 0), (0.79127645, 0), (0.77174681, 0), (0.76978552, 1), (0.76650035, 1), (0.76614183, 0), (0.76086164, 0), (0.75385493, 0), (0.75144458, 0), (0.74910921, 0), (0.74099368, 1), (0.74041063, 0), (0.73638779, 0), (0.73409617, 0), (0.73292655, 0), (0.73257864, 0), (0.72589278, 0)]\n",
      "(0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0)\n",
      "[0.14285714285714285, 0.25, 0.21428571428571427, 0.14814814814814814, 0.1724137931034483, 0.1875, 0.12962962962962962, 0.11428571428571428, 0.08256880733944955, 0.08264462809917356, 0.0859375, 0.09090909090909091, 0.0948905109489051, 0.09929078014184398, 0.1048951048951049, 0.10666666666666667, 0.10625, 0.10975609756097561, 0.1144578313253012, 0.11428571428571428]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.098118803256635245"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_of_topic(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

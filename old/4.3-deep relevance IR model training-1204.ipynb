{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "import os, nltk\n",
    "from keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_tree = etree.parse('data/topics2016.xml')\n",
    "\n",
    "def get_topic(i):# returns the summary string of the ith topic\n",
    "    summary = topic_tree.xpath('//topic[@number=\"%d\"]/summary/text()'%i)\n",
    "    return str(summary).lower()\n",
    "\n",
    "# build a mapping of article name (PMCID) to its file path\n",
    "\n",
    "PMC_PATH = '/local/XW/DATA/TREC/PMCs/'\n",
    "pmcid2fpath = {}\n",
    "\n",
    "for subdir1 in os.listdir(PMC_PATH):\n",
    "    for subdir2 in os.listdir(os.path.join(PMC_PATH, subdir1)):\n",
    "        diry = os.path.join(PMC_PATH, subdir1, subdir2)\n",
    "#         print diry, len(os.listdir(diry))\n",
    "        for fn in os.listdir(diry):\n",
    "            pmcid = fn[:-5]\n",
    "            fpath = os.path.join(diry, fn)\n",
    "            pmcid2fpath[pmcid] = fpath\n",
    "\n",
    "def get_article_abstract(pmcid):\n",
    "    fpath = pmcid2fpath[pmcid]\n",
    "    tree = etree.parse(fpath)\n",
    "    abstract = tree.xpath('//abstract')[0]\n",
    "    ret = u''+abstract.xpath('string(.)')\n",
    "    return ret.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 4174/37707 [00:04<00:40, 836.64it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "pmcid_2relevance = [{} for i in xrange(31)] # list of dict mapping pmcid to relevance\n",
    "with open('data/qrels.txt') as f:\n",
    "    for line in tqdm(f, total=37707): \n",
    "        topicid, _, pmcid, relevance = line.split()\n",
    "        topicid = int(topicid)\n",
    "        if topicid>3: break\n",
    "        try:\n",
    "            corpus.append(get_article_abstract(pmcid))\n",
    "            pmcid_2relevance[topicid][pmcid] = int(relevance)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3871"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(corpus)\n",
    "\n",
    "def get_idf(wd):\n",
    "    if wd not in vectorizer.vocabulary_: return 1.0\n",
    "    return vectorizer.idf_[ vectorizer.vocabulary_[wd] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2V_FPATH = '/local/XW/DATA/WORD_EMBEDDINGS/biomed-w2v-200.txt'\n",
    "GLOVE_FPATH = '/local/XW/DATA/WORD_EMBEDDINGS/glove.6B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:04<00:00, 98328.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 19408 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec = {} # maps word ---> embedding vector\n",
    "with open(GLOVE_FPATH) as f:\n",
    "    for line in tqdm(f, total=400000): #5443657 400000\n",
    "        vals = line.split()\n",
    "        word = vals[0]\n",
    "        if word in vocab:\n",
    "            vec = np.asarray(vals[1:], dtype='float')\n",
    "            word2vec[word] = vec\n",
    "print 'found %d word vectors.' % len(word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Define the deep relevance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function for visualization of model\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "def viz_model(model):\n",
    "    return SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct the relevance IR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, InputLayer, Flatten, Input, Merge, merge, Reshape\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(query.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 main components of the structure: feed forward network and gating\n",
    "feed_forward = Sequential(\n",
    "    [Dense(input_dim=30, output_dim=5, activation='tanh'),\n",
    "     Dense(output_dim=1, activation='tanh')], \n",
    "    name='feed_forward_nw')\n",
    "\n",
    "# ***note: have to wrap ops into Lambda layers !!***\n",
    "# cf: https://groups.google.com/forum/#!topic/keras-users/fbRS-FkZw_Q\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "input_idf = Input(shape=(N,), name='input_idf')\n",
    "def scale(x): \n",
    "    w = K.variable(1, name='w_g')\n",
    "    return K.mul(x,w)\n",
    "def scale_output_shape(input_shape): return input_shape\n",
    "\n",
    "scaled = Lambda(scale, scale_output_shape, name='softmax_scale')(input_idf)\n",
    "gs_out = Activation('softmax', name='softmax')(scaled)\n",
    "gating = Model(input=input_idf, output=gs_out, name='gating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first input\n",
    "input_hists = Input(shape=(N,30), name='input_hists')\n",
    "\n",
    "def slicei(x, i): return x[:,i,:]\n",
    "def slicei_output_shape(input_shape): return (input_shape[0], input_shape[2])\n",
    "zs = [ feed_forward( Lambda(lambda x:slicei(x,i), slicei_output_shape, name='slice%d'%i)(input_hists) )\\\n",
    "          for i in xrange(N) ]\n",
    "\n",
    "def concat(x): return K.concatenate(x) \n",
    "def concat_output_shape(input_shape): return (input_shape[0][0], N)\n",
    "zs = Lambda(concat, concat_output_shape, name='concat_zs')(zs)\n",
    "\n",
    "# second input\n",
    "input_idf = Input(shape=(N,), name='input_idf')\n",
    "gs = gating(input_idf)\n",
    "\n",
    "def innerprod(x): return K.sum( K.mul(x[0],x[1]), axis=1)\n",
    "def innerprod_output_shape(input_shape): return (input_shape[0][0],1)\n",
    "scores = Lambda(innerprod, innerprod_output_shape, name='innerprod_zs_gs')([zs, gs])\n",
    "\n",
    "scoring_model = Model(input=[input_idf, input_hists], output=[scores], name='scoring_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# third input -- the negative hists vector \n",
    "input_hists_neg = Input(shape=(N,30), name='input_hists_neg')\n",
    "\n",
    "zs_neg = [ feed_forward( Lambda(lambda x:slicei(x,i), slicei_output_shape, name='slice%d_neg'%i)(input_hists_neg) )\\\n",
    "          for i in xrange(N) ]\n",
    "\n",
    "zs_neg = Lambda(concat, concat_output_shape, name='concat_zs_neg')(zs_neg)\n",
    "\n",
    "scores_neg = Lambda(innerprod, innerprod_output_shape, name='innerprod_zs_gs_neg')([zs_neg, gs])\n",
    "\n",
    "two_score_model = Model(input=[input_idf, input_hists, input_hists_neg], \n",
    "                        output=[scores, scores_neg], \n",
    "                        name='2scoring_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.57720977, -0.09897145], dtype=float32),\n",
       " array([-0.57720977, -0.09897145], dtype=float32)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_score_model.predict([idf_sample, pair_sample, pair_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "innerprod_zs_gs\n",
      "(None, 1)\n",
      "[(None, 11), (None, 11)]\n"
     ]
    }
   ],
   "source": [
    "print scoring_model.layers[-1].name\n",
    "print scoring_model.layers[-1].output_shape\n",
    "print scoring_model.layers[-1].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_hists (InputLayer)         (None, 11, 30)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "slice0 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice1 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice2 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice3 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice4 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice5 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice6 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice7 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice8 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice9 (Lambda)                  (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "slice10 (Lambda)                 (None, 30)            0           input_hists[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "feed_forward_nw (Sequential)     (None, 1)             161         slice0[0][0]                     \n",
      "                                                                   slice1[0][0]                     \n",
      "                                                                   slice2[0][0]                     \n",
      "                                                                   slice3[0][0]                     \n",
      "                                                                   slice4[0][0]                     \n",
      "                                                                   slice5[0][0]                     \n",
      "                                                                   slice6[0][0]                     \n",
      "                                                                   slice7[0][0]                     \n",
      "                                                                   slice8[0][0]                     \n",
      "                                                                   slice9[0][0]                     \n",
      "                                                                   slice10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_idf (InputLayer)           (None, 11)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concat_zs (Lambda)               (None, 11)            0           feed_forward_nw[78][0]           \n",
      "                                                                   feed_forward_nw[79][0]           \n",
      "                                                                   feed_forward_nw[80][0]           \n",
      "                                                                   feed_forward_nw[81][0]           \n",
      "                                                                   feed_forward_nw[82][0]           \n",
      "                                                                   feed_forward_nw[83][0]           \n",
      "                                                                   feed_forward_nw[84][0]           \n",
      "                                                                   feed_forward_nw[85][0]           \n",
      "                                                                   feed_forward_nw[86][0]           \n",
      "                                                                   feed_forward_nw[87][0]           \n",
      "                                                                   feed_forward_nw[88][0]           \n",
      "____________________________________________________________________________________________________\n",
      "gating (Model)                   (None, 11)            0           input_idf[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "innerprod_zs_gs (Lambda)         (None, 1)             0           concat_zs[0][0]                  \n",
      "                                                                   gating[8][0]                     \n",
      "====================================================================================================\n",
      "Total params: 161\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "scoring_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_hists_pos = Input(shape=(N,30,), name='input_hists_pos')\n",
    "input_hists_neg = Input(shape=(N,30,), name='input_hists_neg')\n",
    "\n",
    "scores_pos = scoring_model([input_idf, input_hists_pos])\n",
    "scores_neg = scoring_model([input_idf, input_hists_neg])\n",
    "\n",
    "def diff(x): return tf.sub(x[0], x[1]) #x[0]-x[1]\n",
    "def diff_output_shape(input_shape): return input_shape[0]\n",
    "diff = Lambda(diff, diff_output_shape, name='posneg_score_diff')([scores_pos, scores_neg])\n",
    "\n",
    "ranking_model = Model(input=[input_idf, input_hists_pos,  input_hists_neg]\n",
    "                      , output=[diff]\n",
    "                      , name='ranking_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define my loss function: hinge of score_pos - score_neg\n",
    "def pairwise_hinge(y_true, y_pred): # y_pred = score_pos - score_neg, **y_true doesn't matter here**\n",
    "    return K.mean( K.maximum(1. - y_pred, y_true*0.0) )  \n",
    "\n",
    "ranking_model.compile(optimizer='adagrad', loss=pairwise_hinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_idf (InputLayer)           (None, 11)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_hists_pos (InputLayer)     (None, 11, 30)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_hists_neg (InputLayer)     (None, 11, 30)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "scoring_model (Model)            (None, 1)             161         input_idf[0][0]                  \n",
      "                                                                   input_hists_pos[0][0]            \n",
      "                                                                   input_idf[0][0]                  \n",
      "                                                                   input_hists_neg[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "posneg_score_diff (Lambda)       (None, 1)             0           scoring_model[3][0]              \n",
      "                                                                   scoring_model[4][0]              \n",
      "====================================================================================================\n",
      "Total params: 161\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ranking_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## below are some testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3429740', '3921765'),\n",
       " ('2999735', '4085271'),\n",
       " ('3526517', '4532844'),\n",
       " ('1750992', '2769307'),\n",
       " ('3503351', '3809984'),\n",
       " ('4130891', '4685986'),\n",
       " ('4471306', '2996340'),\n",
       " ('3286730', '4395018'),\n",
       " ('4659952', '28994'),\n",
       " ('4724023', '4716452')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(pos_ids[:10], neg_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 11) (2, 11, 30)\n"
     ]
    }
   ],
   "source": [
    "pos_sample = get_query_doc_feature(query, '3429740')\n",
    "neg_sample = get_query_doc_feature(query, '3921765')\n",
    "pair_sample = np.array([pos_sample, neg_sample])\n",
    "\n",
    "_idf = np.array([get_idf(wd) for wd in query.split()])\n",
    "idf_sample = np.vstack([_idf]*2)\n",
    "\n",
    "print idf_sample.shape, pair_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test `scoring_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57720977, -0.09897145], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model.predict([idf_sample,pair_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04990714]\n",
      " [ 0.20103526]\n",
      " [-0.9998787 ]\n",
      " [-0.99933815]\n",
      " [ 0.81653112]\n",
      " [-0.7265538 ]\n",
      " [-0.99144602]\n",
      " [-0.99986547]\n",
      " [-0.98050851]\n",
      " [-0.99987775]\n",
      " [-0.04990714]]\n"
     ]
    }
   ],
   "source": [
    "a = feed_forward.predict(pos_sample)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00482637  0.20997439  0.0174815   0.02042374  0.0538551   0.20764136\n",
      "  0.00537621  0.12458481  0.34606892  0.00494123  0.00482637]\n"
     ]
    }
   ],
   "source": [
    "b = gating.predict(idf_sample)[0]\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57720971], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83937836]\n",
      " [ 0.00692836]\n",
      " [-0.99940413]\n",
      " [-0.99986506]\n",
      " [ 0.8202067 ]\n",
      " [ 0.18778783]\n",
      " [-0.99873543]\n",
      " [-0.98785001]\n",
      " [-0.05901096]\n",
      " [-0.99953288]\n",
      " [ 0.83937836]]\n",
      "[-0.09897143]\n"
     ]
    }
   ],
   "source": [
    "c = feed_forward.predict(neg_sample)\n",
    "print c\n",
    "print b.dot(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> the scoring model works all right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**but when adding another input layer, the output is incorrect!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf_in = Input((N,))\n",
    "hists_in = Input((N,30))\n",
    "score_out = scoring_model([idf_in, hists_in])\n",
    "_model = Model(input=[idf_in, hists_in], output=score_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04990714,  0.83937836], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model.predict([idf_sample, pair_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test ranking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.8892855,  0.8892855], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_model.predict( [idf_sample, pair_sample, np.array([neg_sample, pos_sample]) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> **strange**, the ranking models gives `score_pos - score_neg = -0.8892855`,   \n",
    "but from what we have in `scoring_model`, it should be `-0.5772+0.1954 = -0.3818`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scoring_model'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_model.layers[-2].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04990714],\n",
       "       [ 0.20103526],\n",
       "       [-0.9998787 ],\n",
       "       [-0.99933815],\n",
       "       [ 0.81653112],\n",
       "       [-0.7265538 ],\n",
       "       [-0.99144602],\n",
       "       [-0.99986547],\n",
       "       [-0.98050851],\n",
       "       [-0.99987775],\n",
       "       [-0.04990714]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_fw_input = Input((30,))\n",
    "my_fw_output = feed_forward(my_fw_input)\n",
    "my_fw_model = Model(input=my_fw_input, output=my_fw_output)\n",
    "my_fw_model.predict(pos_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04990714],\n",
       "       [ 0.20103526],\n",
       "       [-0.9998787 ],\n",
       "       [-0.99933815],\n",
       "       [ 0.81653112],\n",
       "       [-0.7265538 ],\n",
       "       [-0.99144602],\n",
       "       [-0.99986547],\n",
       "       [-0.98050851],\n",
       "       [-0.99987775],\n",
       "       [-0.04990714]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my2nd_input = Input((30,))\n",
    "my_2nd_output = my_fw_model(my2nd_input)\n",
    "my_2nd_fwmodel = Model(input=my2nd_input, output=my_2nd_output)\n",
    "my_2nd_fwmodel.predict(pos_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00482637,  0.20997439,  0.0174815 ,  0.02042374,  0.0538551 ,\n",
       "         0.20764136,  0.00537621,  0.12458481,  0.34606892,  0.00494123,\n",
       "         0.00482637],\n",
       "       [ 0.00482637,  0.20997439,  0.0174815 ,  0.02042374,  0.0538551 ,\n",
       "         0.20764136,  0.00537621,  0.12458481,  0.34606892,  0.00494123,\n",
       "         0.00482637]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gatingin = Input((N,))\n",
    "my_gatingout = gating(my_gatingin)\n",
    "my_gatingmodel = Model(input=my_gatingin, output=my_gatingout)\n",
    "my_gatingmodel.predict(idf_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04990714,  0.83937836], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascore = scoring_model([my_gatingin, ahistinput])\n",
    "amodel = Model(input=[my_gatingin, ahistinput], output=ascore)\n",
    "amodel.predict( [idf_sample, pair_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 11), (None, 11, 30)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amodel.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 11), (None, 11, 30)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_idf_8:0' shape=(?, 11) dtype=float32>,\n",
       " <tf.Tensor 'input_hists_7:0' shape=(?, 11, 30) dtype=float32>]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ahistinput = Input(shape=(N,30))\n",
    "aidfinput = Input(shape=(N,), name='aidfinput')\n",
    "ascore = scoring_model.([aidfinput, ahistinput])\n",
    "amodel = Model(input=[aidfinput, ahistinput], output=ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04990714,  0.83937836], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amodel.predict( [idf_sample, pair_sample] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_hists_pos = Input(shape=(N,30), name='input_hists_pos')\n",
    "input_hists_neg = Input(shape=(N,30), name='input_hists_neg')\n",
    "\n",
    "scores_pos = scoring_model([input_idf, input_hists_pos])\n",
    "scores_neg = scoring_model([input_idf, input_hists_neg])\n",
    "\n",
    "twoscore_model = Model(input=[input_idf, input_hists_pos,  input_hists_neg]\n",
    "                      , output=[scores_pos, scores_neg]\n",
    "                      , name='twoscore_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onescore_model = Model(input=[input_idf, input_hists_pos], output = [scores_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04990714,  0.83937836], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onescore_model.predict([idf_sample, pair_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 11), (None, 11, 30)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.04990714,  0.83937836], dtype=float32),\n",
       " array([ 0.83937836, -0.04990714], dtype=float32)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoscore_model.predict( [idf_sample, pair_sample, np.array([neg_sample, pos_sample]) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_idf (InputLayer)           (None, 11)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_hists_pos (InputLayer)     (None, 11, 30)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_hists_neg (InputLayer)     (None, 11, 30)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "scoring_model (Model)            (None, 1)             161         input_idf[0][0]                  \n",
      "                                                                   input_hists_pos[0][0]            \n",
      "                                                                   input_idf[0][0]                  \n",
      "                                                                   input_hists_neg[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 161\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "twoscore_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. train model (for topic-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randvec = np.random.randn(200)\n",
    "def get_histvec(q_wd, doc):\n",
    "    qvec = word2vec.get(q_wd, randvec)\n",
    "#     dvecs = np.vstack( [word2vec.get(wd, randvec) for wd in nltk.word_tokenize(doc)] )\n",
    "    words_doc = filter(lambda wd:wd in word2vec, nltk.word_tokenize(doc))\n",
    "    dvecs = np.vstack( [ word2vec[wd] for wd in words_doc ] )\n",
    "    cossims = np.dot(dvecs, qvec) / norm(qvec) / norm(dvecs, axis=1)\n",
    "    hist, _ = np.histogram( cossims[cossims<1.0], bins=29, range=(-1,1) )\n",
    "    ones = len(cossims) - sum(hist)\n",
    "    ret = np.array( list(hist) + [ones] )\n",
    "    return ret # np.reshape(ret, (-1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_doc_feature(query, pmcid):\n",
    "    doc = get_article_abstract(pmcid)\n",
    "    return np.array([ get_histvec(wd, doc) for wd in query.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare positive/negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relevance = pmcid_2relevance[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 1209\n"
     ]
    }
   ],
   "source": [
    "pos_ids, neg_ids = [], []\n",
    "for pmcid in relevance.keys():\n",
    "    if relevance[pmcid]==0: neg_ids.append(pmcid)\n",
    "    else: pos_ids.append(pmcid)\n",
    "print len(pos_ids), len(neg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:03<00:00, 38.55it/s]\n",
      "100%|██████████| 1209/1209 [00:33<00:00, 35.71it/s]\n"
     ]
    }
   ],
   "source": [
    "hists_pos = np.array( [get_query_doc_feature(query, posid) for posid in tqdm(pos_ids)] )\n",
    "hists_neg = np.array( [get_query_doc_feature(query, negid) for negid in tqdm(neg_ids)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model using `fit_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VALDATION_SPLIT = 0.2\n",
    "BATCH_SZ = 128\n",
    "NB_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_pairs = []\n",
    "for pidx in xrange(len(hists_pos)):\n",
    "    for nidx in xrange(len(hists_neg)):\n",
    "        idx_pairs.append( (pidx, nidx) )\n",
    "idx_pairs = np.array(idx_pairs)\n",
    "val_sz = int(len(idx_pairs)*VALDATION_SPLIT)\n",
    "idx_pairs_train, idx_pairs_val = idx_pairs[val_sz:], idx_pairs[:val_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(idx_pairs, batch_size=BATCH_SZ): \n",
    "    np.random.shuffle(idx_pairs)\n",
    "    batches_pre_epoch = len(idx_pairs) //batch_size\n",
    "    samples_per_epoch = batches_pre_epoch * batch_size # make samples_per_epoch a multiple of batch size\n",
    "    counter = 0\n",
    "    _idf = np.array([get_idf(wd) for wd in query.split()])\n",
    "    idfs_batch = np.vstack([_idf]*batch_size)\n",
    "    y_true_batch_dummy = np.ones((batch_size))\n",
    "    while 1:\n",
    "        idx_batch = idx_pairs[batch_size*counter: min(samples_per_epoch, batch_size*(counter+1))]\n",
    "        pos_batch = hists_pos[idx_batch[:,0]]\n",
    "        neg_batch = hists_neg[idx_batch[:,1]]\n",
    "        counter += 1\n",
    "        if (counter >= batches_pre_epoch):\n",
    "            np.random.shuffle(idx_pairs)\n",
    "            counter=0\n",
    "        yield [idfs_batch, pos_batch, neg_batch], y_true_batch_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120832/120832 [==============================] - 6s - loss: 0.6785 - val_loss: 0.6921\n",
      "Epoch 2/20\n",
      "120832/120832 [==============================] - 6s - loss: 0.6729 - val_loss: 0.6961\n",
      "Epoch 3/20\n",
      "120832/120832 [==============================] - 6s - loss: 0.6701 - val_loss: 0.6979\n",
      "Epoch 4/20\n",
      "120832/120832 [==============================] - 6s - loss: 0.6682 - val_loss: 0.6982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ae96a8250>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = './log/relevance_matching'\n",
    "_callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "              TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=False) # \n",
    "             ]\n",
    "\n",
    "ranking_model.fit_generator( batch_generator(idx_pairs_train), \n",
    "                    samples_per_epoch = len(idx_pairs_train)//BATCH_SZ*BATCH_SZ,\n",
    "                    nb_epoch=NB_EPOCH,\n",
    "                    validation_data=batch_generator(idx_pairs_val),\n",
    "                    nb_val_samples=len(idx_pairs_val)//BATCH_SZ*BATCH_SZ, \n",
    "                    callbacks = _callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"120pt\" viewBox=\"0.00 0.00 518.00 120.00\" width=\"518pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 116)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,5 -4,-116 515,-116 515,5 -4,5\" stroke=\"white\"/>\n",
       "<!-- 139684857941584 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139684857941584</title>\n",
       "<polygon fill=\"none\" points=\"0,-75 0,-111 134,-111 134,-75 0,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-89.3\">input_idf: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139684857998864 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139684857998864</title>\n",
       "<polygon fill=\"none\" points=\"166.5,-1 166.5,-37 307.5,-37 307.5,-1 166.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-15.3\">scoring_model: Model</text>\n",
       "</g>\n",
       "<!-- 139684857941584&#45;&gt;139684857998864 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139684857941584-&gt;139684857998864</title>\n",
       "<path d=\"M107.288,-74.937C131.23,-64.7967 161.789,-51.854 187.231,-41.0785\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"188.864,-44.188 196.707,-37.0651 186.134,-37.7423 188.864,-44.188\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139684837486800 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139684837486800</title>\n",
       "<polygon fill=\"none\" points=\"152.5,-75 152.5,-111 321.5,-111 321.5,-75 152.5,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-89.3\">input_hists_pos: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139684837486800&#45;&gt;139684857998864 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139684837486800-&gt;139684857998864</title>\n",
       "<path d=\"M237,-74.937C237,-66.8072 237,-56.8761 237,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"240.5,-47.4406 237,-37.4407 233.5,-47.4407 240.5,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139684837488528 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139684837488528</title>\n",
       "<polygon fill=\"none\" points=\"340,-75 340,-111 510,-111 510,-75 340,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425\" y=\"-89.3\">input_hists_neg: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139684837488528&#45;&gt;139684857998864 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139684837488528-&gt;139684857998864</title>\n",
       "<path d=\"M380.447,-74.937C353.619,-64.6627 319.28,-51.5115 290.926,-40.6524\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"292.149,-37.3732 281.559,-37.0651 289.646,-43.9102 292.149,-37.3732\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_model(twoscore_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.892479  ],\n",
       "       [-0.706613  ],\n",
       "       [ 0.80454189],\n",
       "       [-0.99935871],\n",
       "       [ 0.58757395],\n",
       "       [-0.09228716],\n",
       "       [ 0.51544785],\n",
       "       [-0.97222841],\n",
       "       [-0.69008142],\n",
       "       [-0.98593205],\n",
       "       [-0.892479  ]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_input = Input(shape=(30,), name='input_hists_neg')\n",
    "my_fw = feed_forward(my_input)\n",
    "my_fw_model = Model(input=[my_input], output=my_fw)\n",
    "\n",
    "a = my_fw_model.predict(hists)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_input = Input(shape=(N,30,), name='input_hists_neg')\n",
    "my_output = scoring_model([input_idf,my_input])\n",
    "my_scoring_model = Model(input=[input_idf, my_input], output=my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05468409], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_scoring_model.predict([_idf, hists.reshape(1,11,30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_168:0' shape=(30,) dtype=float32>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_hists_neg[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_idf (InputLayer)           (None, 11)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_hists_neg (InputLayer)     (None, 11, 30)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_4 (Model)                  ((None, 1), 11)       161         input_idf[0][0]                  \n",
      "                                                                   input_hists_neg[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 161\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_scoring_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.66346824], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model.predict([_idf, hists.reshape(1,11,30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 11), (None, 11, 30)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05468409 -0.192092   -0.99987549 -0.99966365  0.81075352 -0.72527534\n",
      " -0.99130666 -0.99986106 -0.9802199  -0.99987501 -0.05468409]\n",
      "[ 0.00178642  0.21126346  0.01758882  0.02054912  0.05418573  0.20891611\n",
      "  0.00540922  0.12534966  0.3481935   0.00497156  0.00178642]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.66346824"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs = np.array([feed_forward.predict(hists[i].reshape((1,30)))[0][0] for i in xrange(11)])\n",
    "print zs\n",
    "\n",
    "gs = gating.predict(_idf)[0]\n",
    "print gs\n",
    "\n",
    "np.dot(gs, zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_idf = np.array([get_idf(wd) for wd in query.split()])\n",
    "_idf = np.vstack([_idf])\n",
    "def predict_score(pmcid):\n",
    "    _hist = get_query_doc_feature(query, pmcid).reshape(1,11,30)\n",
    "    return scoring_model.predict([_idf, _hist])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  4.77289008,  2.28704754,  2.44260238,  3.41220167,\n",
       "         4.76171678,  1.10788896,  4.25089115,  5.2725424 ,  1.0235182 ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score_diff( (pmcid_pos, pmcid_neg) ):\n",
    "    hist_pos = get_query_doc_feature(query, pmcid_pos).reshape((1,11,30))\n",
    "    hist_neg = get_query_doc_feature(query, pmcid_neg).reshape((1,11,30))\n",
    "    return ranking_model.predict([_idf, hist_pos, hist_neg])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.663468 -0.202128 -0.46134\n"
     ]
    }
   ],
   "source": [
    "pos_score, neg_score = predict_score('3429740'), predict_score('3921765')\n",
    "print pos_score, neg_score, pos_score-neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.89171958"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score_diff( ('3429740','3921765') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_model = Model(input=[input_idf, input_hists_pos,  input_hists_neg], output=[scores_pos, scores_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_two_scores( (pmcid_pos, pmcid_neg) ):\n",
    "    hist_pos = get_query_doc_feature(query, pmcid_pos).reshape((1,11,30))\n",
    "    hist_neg = get_query_doc_feature(query, pmcid_neg).reshape((1,11,30))\n",
    "    return scores_model.predict([_idf, hist_pos, hist_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.05468409], dtype=float32), array([ 0.83703548], dtype=float32)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_two_scores(('3429740','3921765'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.89171958,\n",
       " -1.779403,\n",
       " 0.86472356,\n",
       " 1.1238645,\n",
       " -0.096291691,\n",
       " 0.82808971,\n",
       " 1.9493514,\n",
       " 0.010176122,\n",
       " 0.90994984,\n",
       " 1.8916705]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map( predict_score_diff, zip(pos_ids[:10], neg_ids[:10]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.66346824, -0.20212805),\n",
       " (-0.49923095, -0.84202075),\n",
       " (0.15193824, -0.51340085),\n",
       " (-0.25755185, -0.33610663),\n",
       " (-0.73453307, -0.87871718),\n",
       " (-0.83638602, -0.42952284),\n",
       " (-0.89103198, -0.55013555),\n",
       " (-0.70775616, -0.73655176),\n",
       " (-0.73875976, -0.46259823),\n",
       " (-0.7495991, -0.76382387)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip( map(predict_score, pos_ids[:10]), map(predict_score, neg_ids[:10]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "import os, nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_tree = etree.parse('data/topics2016.xml')\n",
    "\n",
    "def get_topic(i):# returns the summary string of the ith topic\n",
    "    summary = topic_tree.xpath('//topic[@number=\"%d\"]/summary/text()'%i)[0]\n",
    "    return str(summary).lower()\n",
    "\n",
    "# build a mapping of article name (PMCID) to its file path\n",
    "\n",
    "PMC_PATH = '/local/XW/DATA/TREC/PMCs/'\n",
    "pmcid2fpath = {}\n",
    "\n",
    "for subdir1 in os.listdir(PMC_PATH):\n",
    "    for subdir2 in os.listdir(os.path.join(PMC_PATH, subdir1)):\n",
    "        diry = os.path.join(PMC_PATH, subdir1, subdir2)\n",
    "#         print diry, len(os.listdir(diry))\n",
    "        for fn in os.listdir(diry):\n",
    "            pmcid = fn[:-5]\n",
    "            fpath = os.path.join(diry, fn)\n",
    "            pmcid2fpath[pmcid] = fpath\n",
    "\n",
    "def get_article_abstract(pmcid):\n",
    "    fpath = pmcid2fpath[pmcid]\n",
    "    tree = etree.parse(fpath)\n",
    "    abstract = tree.xpath('//abstract')[0]\n",
    "    ret = u''+abstract.xpath('string(.)')\n",
    "    if len(ret.split())<20: raise Exception('abstraction too short:'+pmcid)\n",
    "    return ret.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37707/37707 [05:47<00:00, 108.38it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "pmcid_2relevance = [{} for i in xrange(31)] # list of dict mapping pmcid to relevance\n",
    "with open('data/qrels.txt') as f:\n",
    "    for line in tqdm(f, total=37707): \n",
    "        topicid, _, pmcid, relevance = line.split()\n",
    "        topicid = int(topicid)\n",
    "        try:\n",
    "            corpus.append(get_article_abstract(pmcid)) # !some articles don't have an abstract!\n",
    "            pmcid_2relevance[topicid][pmcid] = int(relevance)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34289 articles are retrieved\n"
     ]
    }
   ],
   "source": [
    "print '%d articles are retrieved' % len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(corpus)\n",
    "\n",
    "def get_idf(wd):\n",
    "    if wd not in vectorizer.vocabulary_: return -1e10\n",
    "    return vectorizer.idf_[ vectorizer.vocabulary_[wd] ]\n",
    "\n",
    "vocab = set(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) # to be reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2V_FPATH = '/local/XW/DATA/WORD_EMBEDDINGS/biomed-w2v-200.txt'\n",
    "GLOVE_FPATH = '/local/XW/DATA/WORD_EMBEDDINGS/glove.6B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5443657/5443657 [01:00<00:00, 89801.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 54911 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec = {} # maps word ---> embedding vector\n",
    "with open(W2V_FPATH) as f:\n",
    "    for line in tqdm(f, total=5443657): #5443657 400000\n",
    "        vals = line.split()\n",
    "        word = vals[0]\n",
    "        if word in vocab:\n",
    "            vec = np.asarray(vals[1:], dtype='float')\n",
    "            word2vec[word] = vec\n",
    "print 'found %d word vectors.' % len(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwds = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76-year-old female with personal history of diastolic congestive heart failure, atrial fibrillation on coumadin, presenting with low hematocrit and dyspnea.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_queries = [get_topic(i) for i in xrange(1,21)] # top 20 topics' queries\n",
    "QUERIES = []\n",
    "for q in _queries:\n",
    "    q2 = [wd for wd in q.split() if (wd not in stopwds) and (wd in word2vec)] # filter out stopword and words not in w2v\n",
    "    QUERIES.append(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 14, 26, 11, 12, 20, 16, 11, 13, 12, 14, 13, 23, 11, 40, 16, 11, 19, 20, 16]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(len, QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 40 # = max query length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WD_PLACEHOLDER = '</s>'\n",
    "def pad_query(q, SZ=40):\n",
    "    return q + [WD_PLACEHOLDER]*(SZ-len(q))\n",
    "QUERIES = map(pad_query, QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randvec = np.random.randn(200)\n",
    "def get_histvec(q_wd, doc):\n",
    "    if q_wd == WD_PLACEHOLDER: return np.zeros(30)\n",
    "    qvec = word2vec.get(q_wd, randvec)\n",
    "#     dvecs = np.vstack( [word2vec.get(wd, randvec) for wd in nltk.word_tokenize(doc)] )\n",
    "    words_doc = filter(lambda wd:wd in word2vec, nltk.word_tokenize(doc))\n",
    "    dvecs = np.vstack( [ word2vec[wd] for wd in words_doc ] )\n",
    "    cossims = np.dot(dvecs, qvec) / norm(qvec) / norm(dvecs, axis=1)\n",
    "    hist, _ = np.histogram( cossims[cossims<1.0], bins=29, range=(-1,1) )\n",
    "    ones = len(cossims) - sum(hist)\n",
    "    ret = np.array( list(hist) + [ones] )\n",
    "    return ret # np.reshape(ret, (-1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_doc_feature(query, pmcid): # query: list of words\n",
    "    doc = get_article_abstract(pmcid)\n",
    "    return np.array([ get_histvec(wd, doc) for wd in query])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1328/1328 [00:29<00:00, 45.50it/s]\n",
      "100%|██████████| 1187/1187 [00:41<00:00, 24.19it/s]\n",
      "100%|██████████| 1336/1336 [01:56<00:00, 11.44it/s]\n",
      "100%|██████████| 1318/1318 [01:00<00:00, 22.04it/s]\n",
      "100%|██████████| 1372/1372 [00:59<00:00, 22.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_ids, neg_ids = [], [] # pos_ids[q] is a list (positive pmcids for query `q`)\n",
    "hists_pos, hists_neg = [], [] # hists_pos[q] is a list (positive hists for query `q`)\n",
    "                              # hists_pos[q][i] is an array of size N*30 (the ith hists-feature array for query q)\n",
    "for topic in xrange(1,6):\n",
    "    query = QUERIES[topic-1]\n",
    "    pos_ids_q, neg_ids_q = [], []\n",
    "    hists_pos_q, hists_neg_q = [], []\n",
    "    relevance = pmcid_2relevance[topic]\n",
    "    for pmcid in tqdm(relevance.keys()):\n",
    "        if relevance[pmcid]==0: \n",
    "            neg_ids_q.append(pmcid)\n",
    "            hists_neg_q.append(get_query_doc_feature(query,pmcid))\n",
    "        else: \n",
    "            pos_ids_q.append(pmcid)\n",
    "            hists_pos_q.append(get_query_doc_feature(query,pmcid))\n",
    "    hists_pos_q, hists_neg_q = map(np.array, [hists_pos_q, hists_neg_q])\n",
    "    hists_pos.append(hists_pos_q); hists_neg.append(hists_neg_q)\n",
    "    pos_ids.append(pos_ids_q); neg_ids.append(neg_ids_q)\n",
    "print len(pos_ids), len(neg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VALDATION_SPLIT = 0.2\n",
    "BATCH_SZ = 128\n",
    "NB_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124, 34, 140, 18, 94]\n",
      "[1204, 1153, 1196, 1300, 1278]\n"
     ]
    }
   ],
   "source": [
    "print map(len, hists_pos)\n",
    "print map(len, hists_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399576, 3) (99894, 3)\n"
     ]
    }
   ],
   "source": [
    "idx_pairs = [] # list of tuples of form (q, pos_idx, neg_idx)\n",
    "for q in xrange(5):\n",
    "    hists_pos_q, hists_neg_q = hists_pos[q], hists_neg[q]\n",
    "    for pidx in xrange(len(hists_pos_q)):\n",
    "        for nidx in xrange(len(hists_neg_q)):\n",
    "            idx_pairs.append( (q, pidx, nidx) )\n",
    "idx_pairs = np.array(idx_pairs)\n",
    "np.random.shuffle(idx_pairs)\n",
    "val_sz = int(len(idx_pairs)*VALDATION_SPLIT)\n",
    "idx_pairs_train, idx_pairs_val = idx_pairs[val_sz:], idx_pairs[:val_sz]\n",
    "\n",
    "print idx_pairs_train.shape, idx_pairs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0, 0, 4, 2, 0, 0, 2, 2, 0),\n",
       " (6, 74, 80, 20, 40, 55, 122, 83, 26, 43),\n",
       " (1132, 812, 835, 493, 1167, 1115, 1124, 384, 701, 275)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_batch = idx_pairs_train[:10]\n",
    "zip(*idx_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDFs = [ np.array ([ get_idf(wd) for wd in query]) for query in QUERIES]\n",
    "IDFs = np.array(IDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(idx_pairs, batch_size=BATCH_SZ): \n",
    "    np.random.shuffle(idx_pairs)\n",
    "    batches_pre_epoch = len(idx_pairs) // batch_size\n",
    "    samples_per_epoch = batches_pre_epoch * batch_size # make samples_per_epoch a multiple of batch size\n",
    "    counter = 0\n",
    "    y_true_batch_dummy = np.ones((batch_size))\n",
    "    while 1:\n",
    "        idx_batch = idx_pairs[batch_size*counter: min(samples_per_epoch, batch_size*(counter+1))]\n",
    "#         q_batch, pidx_batch, nidx_batch = zip(*idx_batch)\n",
    "#         idfs_batch = IDFs[q_batch,]\n",
    "#         pos_batch = hists_pos[q_batch, pidx_batch]\n",
    "#         neg_batch = hists_neg[q_batch, nidx_batch]\n",
    "        idfs_batch, pos_batch, neg_batch = [], [], []\n",
    "        for q, pidx, nidx in idx_batch:\n",
    "            idfs_batch.append(IDFs[q])\n",
    "            pos_batch.append(hists_pos[q][pidx])\n",
    "            neg_batch.append(hists_neg[q][nidx])\n",
    "        idfs_batch, pos_batch, neg_batch = map(np.array, [idfs_batch, pos_batch, neg_batch])\n",
    "#         print idfs_batch.shape, pos_batch.shape, neg_batch.shape\n",
    "        counter += 1\n",
    "        if (counter >= batches_pre_epoch):\n",
    "            np.random.shuffle(idx_pairs)\n",
    "            counter=0\n",
    "        \n",
    "        yield [idfs_batch, pos_batch, neg_batch], y_true_batch_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Define the deep relevance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# define a function for visualization of model\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "def viz_model(model):\n",
    "    return SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct the relevance IR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, InputLayer, Flatten, Input, Merge, merge, Reshape\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 main components of the structure: feed forward network and gating\n",
    "feed_forward = Sequential(\n",
    "    [Dense(input_dim=30, output_dim=5, activation='tanh'),\n",
    "     Dense(output_dim=1, activation='tanh')], \n",
    "    name='feed_forward_nw')\n",
    "\n",
    "# ***note: have to wrap ops into Lambda layers !!***\n",
    "# cf: https://groups.google.com/forum/#!topic/keras-users/fbRS-FkZw_Q\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "input_idf = Input(shape=(N,), name='input_idf')\n",
    "def scale(x): \n",
    "    w = K.variable(1, name='w_g')\n",
    "    return K.mul(x,w)\n",
    "def scale_output_shape(input_shape): return input_shape\n",
    "\n",
    "scaled = Lambda(scale, scale_output_shape, name='softmax_scale')(input_idf)\n",
    "gs_out = Activation('softmax', name='softmax')(scaled)\n",
    "gating = Model(input=input_idf, output=gs_out, name='gating')\n",
    "\n",
    "# first input: hist vectors\n",
    "input_hists = Input(shape=(N,30), name='input_hists')\n",
    "\n",
    "def slicei(x, i): return x[:,i,:]\n",
    "def slicei_output_shape(input_shape): return (input_shape[0], input_shape[2])\n",
    "zs = [ feed_forward( Lambda(lambda x:slicei(x,i), slicei_output_shape, name='slice%d'%i)(input_hists) )\\\n",
    "          for i in xrange(N) ]\n",
    "\n",
    "def concat(x): return K.concatenate(x) \n",
    "def concat_output_shape(input_shape): return (input_shape[0][0], N)\n",
    "zs = Lambda(concat, concat_output_shape, name='concat_zs')(zs)\n",
    "\n",
    "# second input: idf scores of each query term \n",
    "input_idf = Input(shape=(N,), name='input_idf')\n",
    "gs = gating(input_idf)\n",
    "\n",
    "def innerprod(x): return K.sum( K.mul(x[0],x[1]), axis=1)\n",
    "def innerprod_output_shape(input_shape): return (input_shape[0][0],1)\n",
    "scores = Lambda(innerprod, innerprod_output_shape, name='innerprod_zs_gs')([zs, gs])\n",
    "\n",
    "scoring_model = Model(input=[input_idf, input_hists], output=[scores], name='scoring_model')\n",
    "\n",
    "# third input -- the negative hists vector \n",
    "input_hists_neg = Input(shape=(N,30), name='input_hists_neg')\n",
    "\n",
    "zs_neg = [ feed_forward( Lambda(lambda x:slicei(x,i), slicei_output_shape, name='slice%d_neg'%i)(input_hists_neg) )\\\n",
    "          for i in xrange(N) ]\n",
    "\n",
    "zs_neg = Lambda(concat, concat_output_shape, name='concat_zs_neg')(zs_neg)\n",
    "\n",
    "scores_neg = Lambda(innerprod, innerprod_output_shape, name='innerprod_zs_gs_neg')([zs_neg, gs])\n",
    "\n",
    "two_score_model = Model(input=[input_idf, input_hists, input_hists_neg], \n",
    "                        output=[scores, scores_neg], \n",
    "                        name='two_score_model')\n",
    "\n",
    "def diff(x): return tf.sub(x[0], x[1]) #x[0]-x[1]\n",
    "def diff_output_shape(input_shape): return input_shape[0]\n",
    "posneg_score_diff = Lambda(diff, diff_output_shape, name='posneg_score_diff')([scores, scores_neg])\n",
    "ranking_model = Model(input=[input_idf, input_hists,  input_hists_neg]\n",
    "                      , output=[posneg_score_diff]\n",
    "                      , name='ranking_model')\n",
    "\n",
    "# define my loss function: hinge of score_pos - score_neg\n",
    "def pairwise_hinge(y_true, y_pred): # y_pred = score_pos - score_neg, **y_true doesn't matter here**\n",
    "    return K.mean( K.maximum(1. - y_pred, y_true*0.0) )  \n",
    "\n",
    "ranking_model.compile(optimizer='adagrad', loss=pairwise_hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. train model (for topic-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model using `fit_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# self-defined metrics\n",
    "def ranking_acc(y_true, y_pred):\n",
    "    y_pred = y_pred > 0 \n",
    "    return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranking_model.compile(optimizer='adagrad', loss=pairwise_hinge, metrics=[ranking_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "399488/399488 [==============================] - 27s - loss: 0.6998 - ranking_acc: 0.7107 - val_loss: 0.7042 - val_ranking_acc: 0.7083\n",
      "Epoch 2/20\n",
      "399488/399488 [==============================] - 26s - loss: 0.6990 - ranking_acc: 0.7109 - val_loss: 0.7033 - val_ranking_acc: 0.7083\n",
      "Epoch 3/20\n",
      "399488/399488 [==============================] - 26s - loss: 0.6983 - ranking_acc: 0.7112 - val_loss: 0.7027 - val_ranking_acc: 0.7093\n",
      "Epoch 4/20\n",
      "399488/399488 [==============================] - 26s - loss: 0.6976 - ranking_acc: 0.7115 - val_loss: 0.7019 - val_ranking_acc: 0.7088\n",
      "Epoch 5/20\n",
      "399488/399488 [==============================] - 27s - loss: 0.6969 - ranking_acc: 0.7120 - val_loss: 0.7009 - val_ranking_acc: 0.7096\n",
      "Epoch 6/20\n",
      "399488/399488 [==============================] - 28s - loss: 0.6960 - ranking_acc: 0.7125 - val_loss: 0.7010 - val_ranking_acc: 0.7100\n",
      "Epoch 7/20\n",
      "399488/399488 [==============================] - 24s - loss: 0.6952 - ranking_acc: 0.7128 - val_loss: 0.6991 - val_ranking_acc: 0.7107\n",
      "Epoch 8/20\n",
      "399488/399488 [==============================] - 23s - loss: 0.6946 - ranking_acc: 0.7130 - val_loss: 0.6993 - val_ranking_acc: 0.7107\n",
      "Epoch 9/20\n",
      "399488/399488 [==============================] - 26s - loss: 0.6940 - ranking_acc: 0.7131 - val_loss: 0.6979 - val_ranking_acc: 0.7115\n",
      "Epoch 10/20\n",
      "399488/399488 [==============================] - 25s - loss: 0.6934 - ranking_acc: 0.7135 - val_loss: 0.6980 - val_ranking_acc: 0.7116\n",
      "Epoch 11/20\n",
      "399488/399488 [==============================] - 24s - loss: 0.6928 - ranking_acc: 0.7137 - val_loss: 0.6972 - val_ranking_acc: 0.7119\n",
      "Epoch 12/20\n",
      "399488/399488 [==============================] - 26s - loss: 0.6924 - ranking_acc: 0.7141 - val_loss: 0.6965 - val_ranking_acc: 0.7130\n",
      "Epoch 13/20\n",
      "399488/399488 [==============================] - 25s - loss: 0.6916 - ranking_acc: 0.7145 - val_loss: 0.6961 - val_ranking_acc: 0.7122\n",
      "Epoch 14/20\n",
      "399488/399488 [==============================] - 23s - loss: 0.6910 - ranking_acc: 0.7147 - val_loss: 0.6949 - val_ranking_acc: 0.7131\n",
      "Epoch 15/20\n",
      "399488/399488 [==============================] - 24s - loss: 0.6906 - ranking_acc: 0.7150 - val_loss: 0.6935 - val_ranking_acc: 0.7135\n",
      "Epoch 16/20\n",
      "399488/399488 [==============================] - 24s - loss: 0.6901 - ranking_acc: 0.7149 - val_loss: 0.6945 - val_ranking_acc: 0.7130\n",
      "Epoch 17/20\n",
      "399488/399488 [==============================] - 28s - loss: 0.6897 - ranking_acc: 0.7152 - val_loss: 0.6945 - val_ranking_acc: 0.7139\n",
      "Epoch 18/20\n",
      "399488/399488 [==============================] - 27s - loss: 0.6893 - ranking_acc: 0.7152 - val_loss: 0.6932 - val_ranking_acc: 0.7130\n",
      "Epoch 19/20\n",
      "399488/399488 [==============================] - 25s - loss: 0.6888 - ranking_acc: 0.7155 - val_loss: 0.6928 - val_ranking_acc: 0.7142\n",
      "Epoch 20/20\n",
      "399488/399488 [==============================] - 24s - loss: 0.6884 - ranking_acc: 0.7159 - val_loss: 0.6932 - val_ranking_acc: 0.7136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b9a1a2110>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = './log/relevance_matching'\n",
    "_callbacks = [ EarlyStopping(monitor='val_loss', patience=2),\n",
    "               TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=False) ]\n",
    "# 30-5-1 tanh\n",
    "ranking_model.fit_generator( batch_generator(idx_pairs_train), \n",
    "                    samples_per_epoch = len(idx_pairs_train)//BATCH_SZ*BATCH_SZ,\n",
    "                    nb_epoch=NB_EPOCH,\n",
    "                    validation_data=batch_generator(idx_pairs_val),\n",
    "                    nb_val_samples=len(idx_pairs_val)//BATCH_SZ*BATCH_SZ, \n",
    "                    callbacks = _callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## below are some testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3429740', '3921765'),\n",
       " ('2999735', '4085271'),\n",
       " ('3526517', '4532844'),\n",
       " ('1750992', '2769307'),\n",
       " ('3503351', '3809984'),\n",
       " ('4130891', '4685986'),\n",
       " ('4471306', '2996340'),\n",
       " ('3286730', '4395018'),\n",
       " ('4659952', '28994'),\n",
       " ('4724023', '4716452')]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(pos_ids[0][:10], neg_ids[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 40) (2, 40, 30)\n"
     ]
    }
   ],
   "source": [
    "query = QUERIES[0]\n",
    "pos_sample = get_query_doc_feature(query, '3429740')\n",
    "neg_sample = get_query_doc_feature(query, '3921765')\n",
    "pair_sample = np.array([pos_sample, neg_sample])\n",
    "_idf = np.array([get_idf(wd) for wd in query])\n",
    "idf_sample = np.vstack([_idf]*2)\n",
    "\n",
    "print idf_sample.shape, pair_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   4.,  46.,  36.,  22.,   7.,   0.,   3.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   1.,   5.,  21.,  32.,  43.,  10.,   5.,   1.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   8.,  38.,  58.,   9.,   5.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sample[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test `scoring_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64522916, -0.64596307], dtype=float32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model.predict([idf_sample,pair_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9996202 ]\n",
      " [-0.99949074]\n",
      " [-0.99962032]\n",
      " [-0.99962097]\n",
      " [ 0.9845562 ]\n",
      " [ 0.90144622]\n",
      " [ 0.99849176]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]\n",
      " [-0.86364526]]\n"
     ]
    }
   ],
   "source": [
    "a = feed_forward.predict(pos_sample)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12651604  0.00871993  0.00948967  0.02779949  0.09881964  0.07380101\n",
      "  0.65485418  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "b = gating.predict(idf_sample)[0]\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64522916], dtype=float32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.64596307]\n"
     ]
    }
   ],
   "source": [
    "c = feed_forward.predict(neg_sample)\n",
    "# print c\n",
    "print b.dot(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> the scoring model works all right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test ranking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.244481, -0.244481], dtype=float32)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_model.predict( [idf_sample, pair_sample, np.array([neg_sample, pos_sample]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24448099"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.08474284 - -0.15973815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(pmcid):\n",
    "    query = QUERIES[0]\n",
    "    _idf = np.array([get_idf(wd) for wd in query])\n",
    "    _idf = np.vstack([_idf])\n",
    "    _hist = get_query_doc_feature(query, pmcid).reshape(1,N,30)\n",
    "    return scoring_model.predict([_idf, _hist])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64522916], dtype=float32)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " query = QUERIES[0]\n",
    "_idf = np.array([get_idf(wd) for wd in query])\n",
    "_idf = np.vstack([_idf])\n",
    "# pos_sample = get_query_doc_feature(query, '3429740')\n",
    "scoring_model.predict( [_idf, pos_sample.reshape(1,N,30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64522916], dtype=float32)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score('3429740')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### see some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.64522916, -0.64596307),\n",
       " (0.58043218, -0.80223674),\n",
       " (0.43058032, -0.96593964),\n",
       " (0.65287751, 0.45643875),\n",
       " (0.34601948, -0.64428258),\n",
       " (0.14929375, -0.085226007),\n",
       " (0.29558107, -0.85025477),\n",
       " (0.33852708, -0.032222524),\n",
       " (0.62793219, -0.96636206),\n",
       " (0.64027685, -0.76521266)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip( map(predict_score, pos_ids[0][:10]), map(predict_score, neg_ids[0][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score_diff( (pmcid_pos, pmcid_neg) ):\n",
    "    query = QUERIES[0]\n",
    "    _idf = np.array([get_idf(wd) for wd in query])\n",
    "    _idf = np.vstack([_idf])\n",
    "    hist_pos = get_query_doc_feature(query, pmcid_pos).reshape((1,11,30))\n",
    "    hist_neg = get_query_doc_feature(query, pmcid_neg).reshape((1,11,30))\n",
    "    return ranking_model.predict([_idf, hist_pos, hist_neg])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the scoring model (metrics=AP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AP(pos_scores, neg_scores):\n",
    "    Q = len(pos_scores)\n",
    "    pos_tags = [1] * len(pos_scores)\n",
    "    neg_tags = [0] * len(neg_scores)\n",
    "    all_tagged = zip(pos_scores, pos_tags) + zip(neg_scores, neg_tags)\n",
    "    ranked_list = sorted(all_tagged, reverse=True)\n",
    "    print ranked_list[:20]\n",
    "    ranked_tag = zip(*ranked_list)[1]\n",
    "    print ranked_tag[:20]\n",
    "    precision_at_i = []\n",
    "    corr, total = 0.0, 0\n",
    "    while corr<Q:\n",
    "        if ranked_tag[total]==1: \n",
    "            corr += 1\n",
    "            precision_at_i.append(corr*1.0 / (total+1) )\n",
    "        total += 1\n",
    "    print precision_at_i[:20]\n",
    "    return np.mean(precision_at_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AP_of_topic(q):\n",
    "    query = QUERIES[q]\n",
    "    _idf = np.array([get_idf(wd) for wd in query])\n",
    "    _idfs = np.vstack([_idf]*len(hists_pos[q]))\n",
    "    pos_scores = scoring_model.predict( [ _idfs, hists_pos[q]])\n",
    "    _idfs = np.vstack([_idf]*len(hists_neg[q]))\n",
    "    neg_scores = scoring_model.predict( [ _idfs, hists_neg[q]])\n",
    "    print 'mean:', pos_scores.mean(), neg_scores.mean()\n",
    "    print 'max:',pos_scores.max(), neg_scores.max()\n",
    "    print 'min:',pos_scores.min(), neg_scores.min()\n",
    "    return AP(pos_scores, neg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.238764 -0.517441\n",
      "max: 0.805651 0.803635\n",
      "min: -0.939749 -0.998747\n",
      "[(0.80565107, 1), (0.8036353, 0), (0.77087092, 0), (0.74555987, 0), (0.73883641, 0), (0.72641373, 0), (0.72107649, 0), (0.71497041, 1), (0.70288318, 0), (0.69102049, 0), (0.68912357, 0), (0.67798567, 1), (0.67725968, 1), (0.67560613, 0), (0.66907352, 0), (0.66331464, 0), (0.661304, 1), (0.65667295, 0), (0.65469623, 1), (0.65364259, 0)]\n",
      "(1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0)\n",
      "[1.0, 0.25, 0.25, 0.3076923076923077, 0.29411764705882354, 0.3157894736842105, 0.3333333333333333, 0.32, 0.32142857142857145, 0.3333333333333333, 0.3333333333333333, 0.35294117647058826, 0.3170731707317073, 0.2978723404255319, 0.3125, 0.32, 0.3333333333333333, 0.34615384615384615, 0.35185185185185186, 0.36363636363636365]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35291676742918116"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_of_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.929451 -0.874651\n",
      "max: -0.833393 0.819759\n",
      "min: -0.979597 -0.99962\n",
      "[(0.81975895, 0), (0.77411568, 0), (0.75447631, 0), (0.74748838, 0), (0.7213372, 0), (0.71550083, 0), (0.67871034, 0), (0.63185596, 0), (0.62454158, 0), (0.61594874, 0), (0.5598042, 0), (0.55463445, 0), (0.547144, 0), (0.4956826, 0), (0.44292343, 0), (0.39915949, 0), (0.35278359, 0), (0.27660221, 0), (0.20339371, 0), (0.20259269, 0)]\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "[0.008928571428571428, 0.01652892561983471, 0.0234375, 0.02857142857142857, 0.03424657534246575, 0.02654867256637168, 0.03070175438596491, 0.029850746268656716, 0.03345724907063197, 0.034013605442176874, 0.03363914373088685, 0.03296703296703297, 0.0325, 0.033734939759036145, 0.033632286995515695, 0.03547671840354767, 0.03632478632478633, 0.0379746835443038, 0.0395010395010395, 0.04106776180698152]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.034055118151864051"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_of_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.288273 0.0659688\n",
      "max: 0.736521 0.78059\n",
      "min: -0.914312 -0.971865\n",
      "[(0.78059, 0), (0.7555573, 0), (0.75069457, 0), (0.74577516, 0), (0.74152535, 0), (0.73652124, 1), (0.73498589, 0), (0.73440605, 0), (0.73362786, 0), (0.73230743, 1), (0.7317878, 0), (0.73043716, 0), (0.72941667, 0), (0.72841209, 0), (0.72787756, 0), (0.72695607, 0), (0.7266326, 0), (0.72596002, 0), (0.72514492, 0), (0.72453558, 0)]\n",
      "(0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "[0.16666666666666666, 0.2, 0.12, 0.11428571428571428, 0.1282051282051282, 0.14634146341463414, 0.16279069767441862, 0.18181818181818182, 0.19148936170212766, 0.20833333333333334, 0.21568627450980393, 0.20689655172413793, 0.20967741935483872, 0.21212121212121213, 0.1595744680851064, 0.1553398058252427, 0.1588785046728972, 0.1651376146788991, 0.17272727272727273, 0.15384615384615385]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15607422336388282"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_of_topic(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.59509 0.416526\n",
      "max: 0.812807 0.886073\n",
      "min: 0.289502 -0.973874\n",
      "[(0.88607287, 0), (0.82710886, 0), (0.81280696, 1), (0.80342525, 0), (0.80238789, 0), (0.79907805, 0), (0.79476434, 0), (0.79390699, 0), (0.79306328, 1), (0.7904945, 0), (0.78551912, 0), (0.78282005, 0), (0.78264034, 0), (0.78159118, 1), (0.78129673, 0), (0.77883512, 0), (0.7717362, 0), (0.76929158, 0), (0.76877606, 0), (0.76352835, 0)]\n",
      "(0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0)\n",
      "[0.3333333333333333, 0.2222222222222222, 0.21428571428571427, 0.021164021164021163, 0.024271844660194174, 0.023166023166023165, 0.022364217252396165, 0.0196078431372549, 0.017475728155339806, 0.019083969465648856, 0.019963702359346643, 0.019077901430842606, 0.017711171662125342, 0.01629802095459837, 0.01646542261251372, 0.01737242128121607, 0.016815034619188922, 0.01637852593266606]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.058725395427480329"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_of_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.0427221 -0.189777\n",
      "max: 0.502116 0.649829\n",
      "min: -0.789292 -0.931807\n",
      "[(0.64982873, 0), (0.61350065, 0), (0.61141121, 0), (0.53826547, 0), (0.53825432, 0), (0.52572823, 0), (0.51764077, 0), (0.50696397, 0), (0.50211555, 1), (0.48248726, 0), (0.48068345, 0), (0.47728133, 1), (0.47323179, 0), (0.46977085, 0), (0.46935955, 1), (0.46806246, 1), (0.46671361, 1), (0.46537223, 0), (0.4557724, 0), (0.45570201, 0)]\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0)\n",
      "[0.1111111111111111, 0.16666666666666666, 0.2, 0.25, 0.29411764705882354, 0.1935483870967742, 0.21875, 0.23529411764705882, 0.2, 0.19607843137254902, 0.2037037037037037, 0.21428571428571427, 0.20634920634920634, 0.2028985507246377, 0.20833333333333334, 0.2191780821917808, 0.22666666666666666, 0.23076923076923078, 0.22093023255813954, 0.22727272727272727]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14501357920381305"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP_of_topic(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Prepare data (run once, then pickle to file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to be pickled: \n",
    "\n",
    "* `pmcid2fpath`    \n",
    "    mapping pmcid to the corresponding file path\n",
    "* `corpus: dict[str, str]`   \n",
    "    mapping pmcid to it's content, the content is a BOW representataion (a Counter), it is pickled into another file called `corpus.pk`\n",
    "* `QUERIES: dict[int, list<str>]`     \n",
    "    mapping qid to it's query represented as a list of words\n",
    "* `QUERIES_padded`   \n",
    "    same as `QUERIES`, but all queries are padded to the same length (=`MAX_QLEN`) with `WD_PLACEHOLDER`\n",
    "* `IDF: dict[str, float]`   \n",
    "    mapping a word to its idf\n",
    "* `relevance: dict[(int,str), int]`   \n",
    "    mapping (qid,docid) pairs to relevance (0,1,2)\n",
    "* `n_pos`    \n",
    "    mapping `qid` to its number of training positive documents\n",
    "* `candidates: dict[int, list<str>]`  \n",
    "    mapping qid to list of its candidate docids (that appeared in the qrel)\n",
    "* `qid_docid2histvec: dict[(int,str), array]`    \n",
    "    mapping from (qid, docid) to the corresponding histvec\n",
    "* `instances: dict[int, list<(str,str)>]`    \n",
    "    mapping qid to list, instances[qid] = list of (pos_docid, neg_docid) pairs for qid,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "import nltk\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pk\n",
    "np.random.seed(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2V_FPATH = '/local/XW/DATA/WORD_EMBEDDINGS/W2V_BIO/wikipedia-pubmed-and-PMC-w2v.bin'\n",
    "# GLOVE_FPATH = '/local/XW/DATA/WORD_EMBEDDINGS/glove.6B.200d.txt'\n",
    "WD_PLACEHOLDER = '</s>'\n",
    "PMC_PATH = '/local/XW/DATA/TREC/PMCs/'\n",
    "PK_FOUT = 'data/TREC-DRMM-preprocessed-0125.pk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_tree = etree.parse('data/topics2016.xml')\n",
    "\n",
    "def get_topic(i):# returns the summary string of the ith topic\n",
    "    summary = topic_tree.xpath('//topic[@number=\"%d\"]/summary/text()'%i)[0]\n",
    "    return str(summary).lower().strip()\n",
    "\n",
    "# build a mapping of article name (PMCID) to its file path\n",
    "pmcid2fpath = {}\n",
    "\n",
    "for subdir1 in os.listdir(PMC_PATH):\n",
    "    for subdir2 in os.listdir(os.path.join(PMC_PATH, subdir1)):\n",
    "        diry = os.path.join(PMC_PATH, subdir1, subdir2)\n",
    "#         print diry, len(os.listdir(diry))\n",
    "        for fn in os.listdir(diry):\n",
    "            pmcid = fn[:-5]\n",
    "            fpath = os.path.join(diry, fn)\n",
    "            pmcid2fpath[pmcid] = fpath\n",
    "\n",
    "def get_article_abstract(pmcid): # get article title and abstract\n",
    "    fpath = pmcid2fpath[pmcid]\n",
    "    tree = etree.parse(fpath)\n",
    "    ret = u'' + tree.xpath('string(//article-title)') + '\\n'\n",
    "    abstracts = tree.xpath('//abstract')\n",
    "#     abstracts = tree.xpath('//p')\n",
    "    ret += u' '.join( [abstract.xpath('string(.)') for abstract in abstracts] )\n",
    "    if len(ret.split())<20: \n",
    "        raise Exception(u'abstraction too short: '+pmcid + ret)\n",
    "    return ret.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'evaluation of a follow-up programme after curative resection for colorectal cancer\\nfrequent liver imaging can detect liver metastases from colorectal cancer at an asymptomatic stage. \\xa9 1999 cancer research campaign'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_abstract('2362203')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a 78 year old male presents with frequent stools and melena.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec = Word2Vec.load_word2vec_format(W2V_FPATH, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### queries (stopwords removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwds = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QUERIES = {} # dict[int, list<str>] mapping qid to it's query represented as a list of words\n",
    "for qid in xrange(1,31):\n",
    "    query = get_topic(qid)\n",
    "    q = [wd for wd in query.split() if wd not in stopwds]\n",
    "    QUERIES[qid] = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "MAX_QLEN = max( map(len, QUERIES.values()) ) \n",
    "print MAX_QLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# padding queries to the same length MAX_QLEN\n",
    "WD_PLACEHOLDER = '</s>'\n",
    "def pad_query(q, SZ=MAX_QLEN):\n",
    "    return q + [WD_PLACEHOLDER]*(SZ-len(q))\n",
    "QUERIES_padded = {}\n",
    "for qid in QUERIES:\n",
    "    QUERIES_padded[qid] = pad_query(QUERIES[qid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERIES = QUERIES_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37707/37707 [11:40<00:00, 71.79it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = {} # dict[str, str] mapping pmcid to it's content\n",
    "\n",
    "with open('data/qrels.txt') as f:\n",
    "    for line in tqdm(f, total=37707): \n",
    "        qid, _, pmcid, rel = line.split()\n",
    "        qid = int(qid)\n",
    "        try:\n",
    "            if pmcid not in corpus: \n",
    "                corpus[pmcid] = get_article_abstract(pmcid)\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26255 articles are retrieved\n"
     ]
    }
   ],
   "source": [
    "print '%d articles are retrieved' % len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relevance and candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "candidates = defaultdict(list) # dict[int, list<str>] mapping qid to list of its candidate docids (that appeared in the qrel)\n",
    "relevance = {} # dict[(int,str), int] mapping (qid,docid) pairs to its relevance (0,1,2)\n",
    "n_pos = defaultdict(int) # dict[int, int] mapping qid to the number of positive documents in qrel\n",
    "with open('data/qrels.txt') as f:\n",
    "    for line in f: \n",
    "        qid, _, pmcid, rel = line.split()\n",
    "        qid = int(qid); rel = int(rel)\n",
    "        if pmcid in corpus: \n",
    "            candidates[qid].append(pmcid)\n",
    "            relevance[(qid,pmcid)] = int(rel)\n",
    "            if int(rel) > 0: n_pos[qid] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1340, 1196, 1353, 1328, 1384, 825, 1065, 1127, 1101, 1098, 954, 1158, 1336, 1138, 1023, 1441, 1034, 1079, 1146, 1022, 933, 1110, 1552, 1331, 1093, 961, 928, 1570, 738, 1237]\n"
     ]
    }
   ],
   "source": [
    "print map(len, candidates.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(corpus.values())\n",
    "vocab = vectorizer.vocabulary_ # mapping word to its internal index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idf(wd):\n",
    "    if wd ==WD_PLACEHOLDER: return -10.0\n",
    "    if wd not in vectorizer.vocabulary_: \n",
    "        return 5.0 # give a high score for rare words in query... \n",
    "    return vectorizer.idf_[ vectorizer.vocabulary_[wd] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDFs = { qid:np.array([ get_idf(wd) for wd in query]) for qid,query in QUERIES.iteritems()} # mapping qid to IDFs array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similarity(wd1, wd2):\n",
    "    if wd1==wd2: return 1.0\n",
    "    if wd1 in word2vec and wd2 in word2vec: \n",
    "        return word2vec.similarity(wd1,wd2)\n",
    "    else: return None\n",
    "\n",
    "def get_histvec(q_wd, doc): # get LCH feature for qwd, doc\n",
    "    if q_wd == WD_PLACEHOLDER: \n",
    "        return np.zeros(30)\n",
    "    doc_words = doc.split()\n",
    "    hist = np.zeros(30)\n",
    "    # we'll use the same method as in NN4IR.cpp, line 774\n",
    "    for d_wd in doc_words:\n",
    "        sim = similarity(q_wd, d_wd)\n",
    "        if sim is None: continue\n",
    "        idx = (sim+1.0)/2.0 * (30-1) # position in the histogram\n",
    "        hist[int(idx)] += 1.0 \n",
    "    ret = np.log10(hist+1.0) # line 815\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_doc_feature(qid, docid):\n",
    "    query = QUERIES[qid]\n",
    "    doc = corpus[docid]\n",
    "    return np.array([ get_histvec(qwd, doc) for qwd in query])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qid, pmcid to histvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [31:40<00:00, 52.57s/it]\n"
     ]
    }
   ],
   "source": [
    "qid_docid2histvec = {} # mapping from (qid, docid) to histvec\n",
    "for qid in tqdm(QUERIES.keys()):\n",
    "    for docid in candidates[qid]:\n",
    "        _hist = get_query_doc_feature(qid, docid).reshape(1,MAX_QLEN,30)\n",
    "        qid_docid2histvec[(qid, docid)] = _hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training instances -- (posid, negid) pairs, cf `NN4IR::LoadDataSet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for each posid, use <= `pernegative` negids for making (posid, negid) pairs, \n",
    "* for each query, gen <= `num_of_instance` pairs\n",
    "* **trick**: if a query has fewer pos docids than others, then the params `pernegative` and `num_of_instance` are augmented accordingly (x5/x3/x1.5 at 25/50/75 quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22, 8), (27, 12), (4, 18), (10, 19), (2, 34), (30, 34), (18, 63), (7, 68), (21, 68), (15, 69), (5, 95), (26, 103), (12, 107), (23, 108), (9, 117), (14, 117), (29, 118), (1, 125), (13, 128), (6, 133), (3, 144), (17, 171), (16, 175), (28, 203), (19, 204), (25, 213), (11, 350), (20, 616), (24, 714), (8, 809)]\n",
      "[8, 12, 18, 19, 34, 34, 63, 68, 68, 69, 95, 103, 107, 108, 117, 117, 118, 125, 128, 133, 144, 171, 175, 203, 204, 213, 350, 616, 714, 809]\n"
     ]
    }
   ],
   "source": [
    "print sorted(n_pos.items(), key=lambda (k,v): v)\n",
    "all_pos = sorted( n_pos.values() ) \n",
    "print all_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 108 350\n"
     ]
    }
   ],
   "source": [
    "# -- quantiles of pos docid numbers\n",
    "avg_pos_80 = all_pos[len(all_pos) * 9 / 10 - 1] # x1.5\n",
    "avg_pos_50 = all_pos[len(all_pos) * 5 / 10 - 2] # x3\n",
    "avg_pos_10 = all_pos[len(all_pos) * 5 / 30] # x10\n",
    "print avg_pos_10, avg_pos_50, avg_pos_80 # quantiles of posid numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores = [2, 1, 0] total= 154789 got 3750 instances for query 1\n",
      "scores = [2, 1, 0] total= 39788 got 6800 instances for query 2\n",
      "scores = [2, 1, 0] total= 177911 got 4320 instances for query 3\n",
      "scores = [2, 1, 0] total= 23625 got 3600 instances for query 4\n",
      "scores = [2, 1, 0] total= 123781 got 5700 instances for query 5\n",
      "scores = [2, 1, 0] total= 95268 got 3990 instances for query 6\n",
      "scores = [2, 1, 0] total= 68628 got 4080 instances for query 7\n",
      "scores = [2, 1, 0] total= 397930 got 8000 instances for query 8\n",
      "scores = [2, 1, 0] total= 118530 got 3510 instances for query 9\n",
      "scores = [2, 0] total= 20501 got 3800 instances for query 10\n",
      "scores = [2, 1, 0] total= 238181 got 10500 instances for query 11\n",
      "scores = [2, 1, 0] total= 114899 got 6420 instances for query 12\n",
      "scores = [2, 1, 0] total= 158044 got 3840 instances for query 13\n",
      "scores = [2, 1, 0] total= 120987 got 3510 instances for query 14\n",
      "scores = [2, 1, 0] total= 65894 got 4140 instances for query 15\n",
      "scores = [2, 1, 0] total= 229206 got 5250 instances for query 16\n",
      "scores = [2, 1, 0] total= 154541 got 5130 instances for query 17\n",
      "scores = [2, 1, 0] total= 64538 got 3780 instances for query 18\n",
      "scores = [2, 1, 0] total= 199971 got 6120 instances for query 19\n",
      "scores = [2, 1, 0] total= 344924 got 8000 instances for query 20\n",
      "scores = [2, 1, 0] total= 59972 got 4080 instances for query 21\n",
      "scores = [2, 0] total= 8816 got 1600 instances for query 22\n",
      "scores = [2, 1, 0] total= 158724 got 6480 instances for query 23\n",
      "scores = [2, 1, 0] total= 556538 got 8000 instances for query 24\n",
      "scores = [2, 1, 0] total= 198080 got 6390 instances for query 25\n",
      "scores = [2, 1, 0] total= 90970 got 6180 instances for query 26\n",
      "scores = [2, 0] total= 10992 got 2400 instances for query 27\n",
      "scores = [2, 1, 0] total= 286321 got 6090 instances for query 28\n",
      "scores = [2, 1, 0] total= 75617 got 3540 instances for query 29\n",
      "scores = [2, 1, 0] total= 41110 got 6800 instances for query 30\n"
     ]
    }
   ],
   "source": [
    "instances = {} # mapping qid to list, instances[qid] = list (pos_docid, neg_docid) pairs for qid, \n",
    "# use pairs in instances for training\n",
    "np.random.seed(1)\n",
    "for qid in QUERIES.keys():\n",
    "    \n",
    "    pernegative = 20 # number of limited pairs per positive sample\n",
    "    num_of_instances = 8000 # number limit of pairs per query\n",
    "    \n",
    "    num_pos_currquery = n_pos[qid]\n",
    "    curr_pernegative = pernegative\n",
    "    curr_num_of_instance = num_of_instances # -- their trick: gen less pairs for queries with more pos docs\n",
    "    if(num_pos_currquery <= avg_pos_10): \n",
    "        curr_pernegative *= 10; curr_num_of_instance *= 10\n",
    "    elif(num_pos_currquery <= avg_pos_50): \n",
    "        curr_pernegative *= 3; curr_num_of_instance *= 3; \n",
    "    elif(num_pos_currquery <= avg_pos_80): \n",
    "        curr_pernegative *= 1.5; curr_num_of_instance *= 1.5; \n",
    "    \n",
    "    rel_scores = defaultdict(list) # mapping a rel score to list of docids\n",
    "    for docid in candidates[qid]:\n",
    "        rel = relevance[(qid,docid)]\n",
    "        rel_scores[rel].append(docid)\n",
    "    scores = sorted( rel_scores.keys(), reverse=True ) # scores are sorted in desc order\n",
    "    print 'scores =',scores, \n",
    "    total_instance = 0\n",
    "    for i in xrange(len(scores)): # scores[i] = pos score\n",
    "        for j in xrange(i+1, len(scores)): # scores[j] = neg score\n",
    "            total_instance += len(rel_scores[scores[i]]) * len(rel_scores[scores[j]])\n",
    "    print 'total=', total_instance, \n",
    "    total_instance = min(total_instance, curr_num_of_instance)\n",
    "    from numpy.random import choice \n",
    "    instances_for_q = []\n",
    "    for i in xrange(len(scores)):# scores are sorted in desc order\n",
    "        pos_score = scores[i]\n",
    "        cur_pos_ids = rel_scores[pos_score] # mapping a rel score to list of docids\n",
    "        cur_neg_ids = []\n",
    "        for j in xrange(i+1, len(scores)):\n",
    "            neg_score = scores[j]\n",
    "            cur_neg_ids += rel_scores[neg_score]# FOUND A BUG HERE\n",
    "        if len(cur_neg_ids)==0: break\n",
    "        for posid in cur_pos_ids:\n",
    "            for negid in choice(cur_neg_ids, min(len(cur_neg_ids),int(curr_pernegative)), replace=False):\n",
    "                instances_for_q.append( (posid,negid) )\n",
    "            if len(instances_for_q)>=total_instance: break\n",
    "        if len(instances_for_q)>=total_instance: break\n",
    "    print 'got %d instances for query %d' % (len(instances_for_q), qid)\n",
    "    instances[qid] = instances_for_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155800 training instances in total\n"
     ]
    }
   ],
   "source": [
    "print '%d training instances in total' % sum( map(len, instances.values()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## another way of negative sampling: each query having the same amount of pairs -- but works less as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " scores = [2, 1, 0] got 8000 instances out of 154789 for query 1\n",
      "scores = [2, 1, 0] got 8000 instances out of 39788 for query 2\n",
      "scores = [2, 1, 0] got 8000 instances out of 177911 for query 3\n",
      "scores = [2, 1, 0] got 8000 instances out of 23625 for query 4\n",
      "scores = [2, 1, 0] got 8000 instances out of 123781 for query 5\n",
      "scores = [2, 1, 0] got 8000 instances out of 95268 for query 6\n",
      "scores = [2, 1, 0] got 8000 instances out of 68628 for query 7\n",
      "scores = [2, 1, 0] got 8000 instances out of 397930 for query 8\n",
      "scores = [2, 1, 0] got 8000 instances out of 118530 for query 9\n",
      "scores = [2, 0] got 8000 instances out of 20501 for query 10\n",
      "scores = [2, 1, 0] got 8000 instances out of 238181 for query 11\n",
      "scores = [2, 1, 0] got 8000 instances out of 114899 for query 12\n",
      "scores = [2, 1, 0] got 8000 instances out of 158044 for query 13\n",
      "scores = [2, 1, 0] got 8000 instances out of 120987 for query 14\n",
      "scores = [2, 1, 0] got 8000 instances out of 65894 for query 15\n",
      "scores = [2, 1, 0] got 8000 instances out of 229206 for query 16\n",
      "scores = [2, 1, 0] got 8000 instances out of 154541 for query 17\n",
      "scores = [2, 1, 0] got 8000 instances out of 64538 for query 18\n",
      "scores = [2, 1, 0] got 8000 instances out of 199971 for query 19\n",
      "scores = [2, 1, 0] got 8000 instances out of 344924 for query 20\n",
      "scores = [2, 1, 0] got 8000 instances out of 59972 for query 21\n",
      "scores = [2, 0] got 8000 instances out of 8816 for query 22\n",
      "scores = [2, 1, 0] got 8000 instances out of 158724 for query 23\n",
      "scores = [2, 1, 0] got 8000 instances out of 556538 for query 24\n",
      "scores = [2, 1, 0] got 8000 instances out of 198080 for query 25\n",
      "scores = [2, 1, 0] got 8000 instances out of 90970 for query 26\n",
      "scores = [2, 0] got 8000 instances out of 10992 for query 27\n",
      "scores = [2, 1, 0] got 8000 instances out of 286321 for query 28\n",
      "scores = [2, 1, 0] got 8000 instances out of 75617 for query 29\n",
      "scores = [2, 1, 0] got 8000 instances out of 41110 for query 30\n"
     ]
    }
   ],
   "source": [
    "N_PAIRS_PER_QUERY = 8000 # the smallest query (22) have 8816 possible pairs \n",
    "from numpy.random import choice \n",
    "instances = {} # mapping qid to list, instances[qid] = list (pos_docid, neg_docid) pairs for qid, \n",
    "\n",
    "np.random.seed(1)\n",
    "for qid in QUERIES.keys():\n",
    "    rel_scores = defaultdict(list) # mapping a rel score to list of docids\n",
    "    for docid in candidates[qid]:\n",
    "        rel = relevance[(qid,docid)]\n",
    "        rel_scores[rel].append(docid)\n",
    "    scores = sorted( rel_scores.keys(), reverse=True ) # scores are sorted in desc order\n",
    "    print 'scores =',scores, \n",
    "    \n",
    "    all_instances = []\n",
    "    for i in xrange(len(scores)): \n",
    "        pos_score = scores[i]\n",
    "        for j in xrange(i+1, len(scores)): \n",
    "            neg_score = scores[j]\n",
    "            for posid in rel_scores[pos_score]:\n",
    "                for negid in rel_scores[neg_score]: \n",
    "                    all_instances.append( (posid, negid) )\n",
    "    \n",
    "    instances_for_q = []\n",
    "    for i in choice(len(all_instances), N_PAIRS_PER_QUERY, replace=False):\n",
    "        instances_for_q.append(all_instances[i])\n",
    "    \n",
    "    print 'got %d instances out of %d for query %d' % (len(instances_for_q), len(all_instances), qid)\n",
    "    instances[qid] = instances_for_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000 training instances in total\n"
     ]
    }
   ],
   "source": [
    "print '%d training instances in total' % sum( map(len, instances.values()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle to file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_to_pickle = {\n",
    "    'QUERIES': QUERIES,\n",
    "    'corpus': corpus,\n",
    "    'IDFs': IDFs, # mapping qid to its IDF input vector\n",
    "    'candidates': candidates,# mapping qid to list of docids that corresponds to qid in the qrel file \n",
    "    'n_pos': n_pos, # n_pos[qid] = number of positive \n",
    "    'relevance': relevance,  # mapping (qid,docid) pairs to relevance (0,1,2)\n",
    "    'qid_docid2histvec': qid_docid2histvec, # mapping (qid, docid) to histvec\n",
    "    'instances': instances,  # instances[qid] = list (pos_docid, neg_docid) pairs for qid\n",
    "}\n",
    "with open(PK_FOUT, 'wb') as f:\n",
    "    pk.dump(data_to_pickle, f, pk.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VALDATION_SPLIT = 0.2\n",
    "BATCH_SZ = 64\n",
    "NB_EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_pairs = []\n",
    "for qid in instances:\n",
    "    for posid, negid in instances[qid]:\n",
    "        idx_pairs.append( (qid,posid,negid) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Define DRMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# define a function for visualization of model\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "def viz_model(model):\n",
    "    return SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, InputLayer, Flatten, Input, Merge, merge, Reshape\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_3 (Dense)                  (None, 5)             155         dense_input_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             6           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2 main components of the structure: feed forward network and gating\n",
    "feed_forward = Sequential(\n",
    "    [Dense(input_dim=30, output_dim=5, activation='tanh'),\n",
    "     Dense(output_dim=1, activation='tanh'),\n",
    "     ], \n",
    "    name='feed_forward_nw')\n",
    "\n",
    "feed_forward.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_idf (InputLayer)           (None, 58)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mylayer_3 (MyLayer)              (None, 58)            1           input_idf[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax (Activation)             (None, 58)            0           mylayer_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1\n",
      "Trainable params: 1\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.engine.topology import Layer\n",
    "\n",
    "class MyLayer(Layer): # a scaled layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.output_dim = input_shape[1]\n",
    "        self.W = self.add_weight(shape=(1,), # Create a trainable weight variable for this layer.\n",
    "                                 initializer='one',\n",
    "                                 trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "    def call(self, x, mask=None):\n",
    "        return tf.mul(x, self.W)\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "input_idf = Input(shape=(MAX_QLEN,), name='input_idf')\n",
    "scaled = MyLayer()(input_idf)\n",
    "gs_out = Activation('softmax', name='softmax')(scaled)\n",
    "gating = Model(input=input_idf, output=gs_out, name='gating')\n",
    "\n",
    "gating.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda\n",
    "\n",
    "# first input: hist vectors\n",
    "input_hists = Input(shape=(MAX_QLEN,30), name='input_hists')\n",
    "\n",
    "def slicei(x, i): return x[:,i,:]\n",
    "def slicei_output_shape(input_shape): return (input_shape[0], input_shape[2])\n",
    "zs = [ feed_forward( Lambda(lambda x:slicei(x,i), slicei_output_shape, name='slice%d'%i)(input_hists) )\\\n",
    "          for i in xrange(MAX_QLEN) ]\n",
    "\n",
    "def concat(x): return K.concatenate(x) \n",
    "def concat_output_shape(input_shape): return (input_shape[0][0], MAX_QLEN)\n",
    "zs = Lambda(concat, concat_output_shape, name='concat_zs')(zs)\n",
    "\n",
    "# second input: idf scores of each query term \n",
    "input_idf = Input(shape=(MAX_QLEN,), name='input_idf')\n",
    "gs = gating(input_idf)\n",
    "\n",
    "def innerprod(x): return K.sum( tf.mul(x[0],x[1]), axis=1)\n",
    "def innerprod_output_shape(input_shape): return (input_shape[0][0],1)\n",
    "scores = Lambda(innerprod, innerprod_output_shape, name='innerprod_zs_gs')([zs, gs])\n",
    "\n",
    "scoring_model = Model(input=[input_idf, input_hists], output=[scores], name='scoring_model')\n",
    "\n",
    "# third input -- the negative hists vector \n",
    "input_hists_neg = Input(shape=(MAX_QLEN,30), name='input_hists_neg')\n",
    "\n",
    "zs_neg = [ feed_forward( Lambda(lambda x:slicei(x,i), slicei_output_shape, name='slice%d_neg'%i)(input_hists_neg) )\\\n",
    "          for i in xrange(MAX_QLEN) ]\n",
    "\n",
    "zs_neg = Lambda(concat, concat_output_shape, name='concat_zs_neg')(zs_neg)\n",
    "\n",
    "scores_neg = Lambda(innerprod, innerprod_output_shape, name='innerprod_zs_gs_neg')([zs_neg, gs])\n",
    "\n",
    "two_score_model = Model(input=[input_idf, input_hists, input_hists_neg], \n",
    "                        output=[scores, scores_neg], \n",
    "                        name='two_score_model')\n",
    "\n",
    "def diff(x): return tf.sub(x[0], x[1]) # **??? if I write `x[0]-x[1]` I get negative of the diff ???**\n",
    "def diff_output_shape(input_shape): return input_shape[0]\n",
    "posneg_score_diff = Lambda(diff, diff_output_shape, name='posneg_score_diff')([scores, scores_neg])\n",
    "ranking_model = Model(input=[input_idf, input_hists,  input_hists_neg]\n",
    "                      , output=[posneg_score_diff]\n",
    "                      , name='ranking_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define my loss function: hinge of score_pos - score_neg\n",
    "def pairwise_hinge(y_true, y_pred): # y_pred = score_pos - score_neg, **y_true doesn't matter here**\n",
    "    return K.mean( K.maximum(0.1 - y_pred, y_true*0.0) )  \n",
    "\n",
    "# self-defined metrics\n",
    "def ranking_acc(y_true, y_pred):\n",
    "    y_pred = y_pred > 0 \n",
    "    return K.mean(y_pred)\n",
    "\n",
    "ranking_model.compile(optimizer='adagrad', loss=pairwise_hinge, metrics=[ranking_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# viz_model(ranking_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.08647980e-01,   8.66970513e-03,   9.70950723e-03,\n",
       "          2.63532810e-02,   9.77671891e-02,   6.89344853e-02,\n",
       "          6.77386999e-01,   2.52833311e-03,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08,   4.22274447e-08,   4.22274447e-08,\n",
       "          4.22274447e-08]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gating.predict(IDFs[1].reshape(-1,MAX_QLEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.00318825], dtype=float32)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gating.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_weights = ranking_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(idx_pairs, batch_size=BATCH_SZ): \n",
    "    # ** parameter `idx_pairs` is list of tuple (qid, pos_docid, neg_docid)**\n",
    "    np.random.shuffle(idx_pairs)\n",
    "    batches_pre_epoch = len(idx_pairs) // batch_size\n",
    "    samples_per_epoch = batches_pre_epoch * batch_size # make samples_per_epoch a multiple of batch size\n",
    "    counter = 0\n",
    "    y_true_batch_dummy = np.ones((batch_size))\n",
    "    while 1:\n",
    "        idx_batch = idx_pairs[batch_size*counter: min(samples_per_epoch, batch_size*(counter+1))]\n",
    "        idfs_batch, pos_batch, neg_batch = [], [], []\n",
    "        for qid, pos_docid, neg_docid in idx_batch:\n",
    "            idfs_batch.append(IDFs[qid])\n",
    "            pos_batch.append(qid_docid2histvec[(qid,pos_docid)].reshape(MAX_QLEN,30))\n",
    "            neg_batch.append(qid_docid2histvec[(qid,neg_docid)].reshape(MAX_QLEN,30))\n",
    "        idfs_batch, pos_batch, neg_batch = map(np.array, [idfs_batch, pos_batch, neg_batch])\n",
    "#         print idfs_batch.shape, pos_batch.shape, neg_batch.shape\n",
    "        counter += 1\n",
    "        if (counter >= batches_pre_epoch):\n",
    "            np.random.shuffle(idx_pairs)\n",
    "            counter=0\n",
    "        yield [idfs_batch, pos_batch, neg_batch], y_true_batch_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idx_pairs(qids):\n",
    "    idx_pairs = []\n",
    "    for qid in qids:\n",
    "        for posid, negid in instances[qid]:\n",
    "            idx_pairs.append( (qid,posid, negid) )\n",
    "    return idx_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_weights(model, weights=None):\n",
    "    \"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "    This is a fast approximation of re-initializing the weights of a model.\n",
    "    Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "      (i.e., the weights have the same distribution along each dimension).\n",
    "    :param Model model: Modify the weights of the given model.\n",
    "    :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "      If `None`, permute the model's current weights.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = model.get_weights()\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "    model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TREC_output(qid, run_name = 'my_run', fpath = None):\n",
    "    res = [] # list of (score, pmcid) tuples\n",
    "    for docid in candidates[qid]:\n",
    "        input_idf = IDFs[qid].reshape((-1,MAX_QLEN))\n",
    "        input_hist = qid_docid2histvec[(qid,docid)]\n",
    "        score = scoring_model.predict([input_idf, input_hist])[0]\n",
    "        res.append( (score, docid) )\n",
    "    res = sorted(res, reverse=True)\n",
    "    fout = sys.stdout if fpath==None else open(fpath, 'a')\n",
    "    for rank, (score, docid) in enumerate(res[:2000]):\n",
    "        print >>fout, '%d  Q0  %s  %d  %f  %s' % (qid, docid, rank, score, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logdir = './logs/DRMM_0124'\n",
    "_callbacks = [ EarlyStopping(monitor='val_loss', patience=2),\n",
    "               TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=False) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KFold(fpath, K = 5, run_name = 'my_run',  batch_size=BATCH_SZ):\n",
    "    open(fpath,'w').close() # clear previous content in file \n",
    "    qids = sorted( QUERIES.keys() )\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(qids)\n",
    "    fold_sz = len(QUERIES) / K\n",
    "    for fold in xrange(K):\n",
    "        print 'fold %d' % fold, \n",
    "        val_start, val_end = fold*fold_sz, (fold+1)*fold_sz\n",
    "        qids_val = qids[val_start:val_end] # train/val queries for each fold \n",
    "        qids_train = qids[:val_start] + qids[val_end:]\n",
    "        print qids_val\n",
    "        idx_pairs_train = get_idx_pairs(qids_train)\n",
    "        idx_pairs_val = get_idx_pairs(qids_val)\n",
    "        \n",
    "        shuffle_weights(ranking_model, initial_weights) # reset model parameters\n",
    "        ranking_model.fit_generator( batch_generator(idx_pairs_train, batch_size=batch_size), # train model \n",
    "                    samples_per_epoch = len(idx_pairs_train)//batch_size*batch_size,\n",
    "                    nb_epoch=10,\n",
    "                    validation_data=batch_generator(idx_pairs_val, batch_size=batch_size),\n",
    "                    nb_val_samples=len(idx_pairs_val)//batch_size*batch_size, \n",
    "                    callbacks = _callbacks)\n",
    "        print 'fold %d complete, outputting to %s...' % (fold, fpath)\n",
    "        for qid in qids_val:\n",
    "            TREC_output(qid, run_name = run_name, fpath = fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold validation and output ranked list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 [3, 29, 14, 11, 27, 25]\n",
      "Epoch 1/10\n",
      "192000/192000 [==============================] - 25s - loss: 0.1041 - ranking_acc: 0.5197 - val_loss: 0.1005 - val_ranking_acc: 0.5194\n",
      "Epoch 2/10\n",
      "192000/192000 [==============================] - 25s - loss: 0.0982 - ranking_acc: 0.5196 - val_loss: 0.0991 - val_ranking_acc: 0.5205\n",
      "Epoch 3/10\n",
      "192000/192000 [==============================] - 24s - loss: 0.0977 - ranking_acc: 0.5198 - val_loss: 0.0987 - val_ranking_acc: 0.5206\n",
      "Epoch 4/10\n",
      "192000/192000 [==============================] - 22s - loss: 0.0976 - ranking_acc: 0.5204 - val_loss: 0.0986 - val_ranking_acc: 0.5205\n",
      "Epoch 5/10\n",
      "192000/192000 [==============================] - 24s - loss: 0.0975 - ranking_acc: 0.5213 - val_loss: 0.0984 - val_ranking_acc: 0.5215\n",
      "Epoch 6/10\n",
      "192000/192000 [==============================] - 26s - loss: 0.0974 - ranking_acc: 0.5221 - val_loss: 0.0984 - val_ranking_acc: 0.5226\n",
      "Epoch 7/10\n",
      "192000/192000 [==============================] - 24s - loss: 0.0973 - ranking_acc: 0.5231 - val_loss: 0.0983 - val_ranking_acc: 0.5227\n",
      "Epoch 8/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0973 - ranking_acc: 0.5239 - val_loss: 0.0983 - val_ranking_acc: 0.5214\n",
      "Epoch 9/10\n",
      "192000/192000 [==============================] - 22s - loss: 0.0972 - ranking_acc: 0.5246 - val_loss: 0.0983 - val_ranking_acc: 0.5246\n",
      "Epoch 10/10\n",
      "192000/192000 [==============================] - 22s - loss: 0.0971 - ranking_acc: 0.5256 - val_loss: 0.0982 - val_ranking_acc: 0.5224\n",
      "fold 1 [28, 12, 18, 23, 6, 17]\n",
      "Epoch 1/10\n",
      "192000/192000 [==============================] - 26s - loss: 0.1128 - ranking_acc: 0.4806 - val_loss: 0.1056 - val_ranking_acc: 0.4724\n",
      "Epoch 2/10\n",
      "192000/192000 [==============================] - 25s - loss: 0.1026 - ranking_acc: 0.4889 - val_loss: 0.1031 - val_ranking_acc: 0.4795\n",
      "Epoch 3/10\n",
      "192000/192000 [==============================] - 22s - loss: 0.1014 - ranking_acc: 0.4936 - val_loss: 0.1022 - val_ranking_acc: 0.4839\n",
      "Epoch 4/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.1008 - ranking_acc: 0.4981 - val_loss: 0.1018 - val_ranking_acc: 0.4878\n",
      "Epoch 5/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.1004 - ranking_acc: 0.5015 - val_loss: 0.1013 - val_ranking_acc: 0.4938\n",
      "Epoch 6/10\n",
      "192000/192000 [==============================] - 24s - loss: 0.1000 - ranking_acc: 0.5052 - val_loss: 0.1011 - val_ranking_acc: 0.4940\n",
      "Epoch 7/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0996 - ranking_acc: 0.5087 - val_loss: 0.1006 - val_ranking_acc: 0.4985\n",
      "Epoch 8/10\n",
      "192000/192000 [==============================] - 28s - loss: 0.0992 - ranking_acc: 0.5117 - val_loss: 0.1003 - val_ranking_acc: 0.5006\n",
      "Epoch 9/10\n",
      "192000/192000 [==============================] - 27s - loss: 0.0988 - ranking_acc: 0.5159 - val_loss: 0.1001 - val_ranking_acc: 0.5049\n",
      "Epoch 10/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0984 - ranking_acc: 0.5194 - val_loss: 0.0996 - val_ranking_acc: 0.5105\n",
      "fold 2 [9, 15, 24, 21, 2, 30]\n",
      "Epoch 1/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.1151 - ranking_acc: 0.5254 - val_loss: 0.1090 - val_ranking_acc: 0.5412\n",
      "Epoch 2/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.1035 - ranking_acc: 0.5294 - val_loss: 0.1013 - val_ranking_acc: 0.5445\n",
      "Epoch 3/10\n",
      "192000/192000 [==============================] - 27s - loss: 0.0982 - ranking_acc: 0.5342 - val_loss: 0.0977 - val_ranking_acc: 0.5513\n",
      "Epoch 4/10\n",
      "192000/192000 [==============================] - 28s - loss: 0.0958 - ranking_acc: 0.5412 - val_loss: 0.0956 - val_ranking_acc: 0.5600\n",
      "Epoch 5/10\n",
      "192000/192000 [==============================] - 28s - loss: 0.0944 - ranking_acc: 0.5479 - val_loss: 0.0941 - val_ranking_acc: 0.5673\n",
      "Epoch 6/10\n",
      "192000/192000 [==============================] - 28s - loss: 0.0934 - ranking_acc: 0.5538 - val_loss: 0.0930 - val_ranking_acc: 0.5745\n",
      "Epoch 7/10\n",
      "192000/192000 [==============================] - 27s - loss: 0.0926 - ranking_acc: 0.5598 - val_loss: 0.0920 - val_ranking_acc: 0.5787\n",
      "Epoch 8/10\n",
      "192000/192000 [==============================] - 24s - loss: 0.0918 - ranking_acc: 0.5653 - val_loss: 0.0908 - val_ranking_acc: 0.5866\n",
      "Epoch 9/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0911 - ranking_acc: 0.5705 - val_loss: 0.0900 - val_ranking_acc: 0.5919\n",
      "Epoch 10/10\n",
      "192000/192000 [==============================] - 25s - loss: 0.0904 - ranking_acc: 0.5756 - val_loss: 0.0889 - val_ranking_acc: 0.5987\n",
      "fold 3 [7, 5, 19, 20, 10, 8]\n",
      "Epoch 1/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.1080 - ranking_acc: 0.5066 - val_loss: 0.0964 - val_ranking_acc: 0.5350\n",
      "Epoch 2/10\n",
      "192000/192000 [==============================] - 27s - loss: 0.0992 - ranking_acc: 0.5309 - val_loss: 0.0955 - val_ranking_acc: 0.5354\n",
      "Epoch 3/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0951 - ranking_acc: 0.5528 - val_loss: 0.0952 - val_ranking_acc: 0.5358\n",
      "Epoch 4/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0923 - ranking_acc: 0.5714 - val_loss: 0.0950 - val_ranking_acc: 0.5406\n",
      "Epoch 5/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0902 - ranking_acc: 0.5867 - val_loss: 0.0947 - val_ranking_acc: 0.5447\n",
      "Epoch 6/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0886 - ranking_acc: 0.5980 - val_loss: 0.0945 - val_ranking_acc: 0.5493\n",
      "Epoch 7/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0871 - ranking_acc: 0.6076 - val_loss: 0.0942 - val_ranking_acc: 0.5541\n",
      "Epoch 8/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0858 - ranking_acc: 0.6158 - val_loss: 0.0938 - val_ranking_acc: 0.5574\n",
      "Epoch 9/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0847 - ranking_acc: 0.6221 - val_loss: 0.0935 - val_ranking_acc: 0.5607\n",
      "Epoch 10/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0836 - ranking_acc: 0.6280 - val_loss: 0.0930 - val_ranking_acc: 0.5642\n",
      "fold 4 [26, 4, 1, 22, 16, 13]\n",
      "Epoch 1/10\n",
      "192000/192000 [==============================] - 24s - loss: 0.1039 - ranking_acc: 0.5316 - val_loss: 0.1039 - val_ranking_acc: 0.5064\n",
      "Epoch 2/10\n",
      "192000/192000 [==============================] - 25s - loss: 0.0959 - ranking_acc: 0.5440 - val_loss: 0.1012 - val_ranking_acc: 0.5116\n",
      "Epoch 3/10\n",
      "192000/192000 [==============================] - 24s - loss: 0.0928 - ranking_acc: 0.5602 - val_loss: 0.1001 - val_ranking_acc: 0.5188\n",
      "Epoch 4/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0908 - ranking_acc: 0.5725 - val_loss: 0.0994 - val_ranking_acc: 0.5222\n",
      "Epoch 5/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0894 - ranking_acc: 0.5824 - val_loss: 0.0990 - val_ranking_acc: 0.5246\n",
      "Epoch 6/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0882 - ranking_acc: 0.5903 - val_loss: 0.0986 - val_ranking_acc: 0.5277\n",
      "Epoch 7/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0872 - ranking_acc: 0.5973 - val_loss: 0.0985 - val_ranking_acc: 0.5290\n",
      "Epoch 8/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0863 - ranking_acc: 0.6036 - val_loss: 0.0979 - val_ranking_acc: 0.5344\n",
      "Epoch 9/10\n",
      "192000/192000 [==============================] - 23s - loss: 0.0855 - ranking_acc: 0.6093 - val_loss: 0.0976 - val_ranking_acc: 0.5389\n",
      "Epoch 10/10\n",
      "192000/192000 [==============================] - 24s - loss: 0.0848 - ranking_acc: 0.6144 - val_loss: 0.0972 - val_ranking_acc: 0.5437\n"
     ]
    }
   ],
   "source": [
    "KFold('data/trec-output/0125_summary_5fold_uniform_sampling.rankedlist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOO run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 [3]\n",
      "Epoch 1/10\n",
      "151424/151424 [==============================] - 17s - loss: 0.0995 - ranking_acc: 0.5220 - val_loss: 0.1040 - val_ranking_acc: 0.4492\n",
      "Epoch 2/10\n",
      "151424/151424 [==============================] - 16s - loss: 0.0977 - ranking_acc: 0.5246 - val_loss: 0.1040 - val_ranking_acc: 0.4529\n",
      "Epoch 3/10\n",
      "151424/151424 [==============================] - 16s - loss: 0.0974 - ranking_acc: 0.5271 - val_loss: 0.1046 - val_ranking_acc: 0.4636\n",
      "Epoch 4/10\n",
      "151424/151424 [==============================] - 16s - loss: 0.0971 - ranking_acc: 0.5297 - val_loss: 0.1034 - val_ranking_acc: 0.4669\n",
      "Epoch 5/10\n",
      "151424/151424 [==============================] - 16s - loss: 0.0967 - ranking_acc: 0.5321 - val_loss: 0.1062 - val_ranking_acc: 0.4667\n",
      "Epoch 6/10\n",
      "151424/151424 [==============================] - 17s - loss: 0.0962 - ranking_acc: 0.5350 - val_loss: 0.1036 - val_ranking_acc: 0.4848\n",
      "Epoch 7/10\n",
      "151424/151424 [==============================] - 17s - loss: 0.0956 - ranking_acc: 0.5392 - val_loss: 0.1042 - val_ranking_acc: 0.4897\n",
      "fold 1 [29]\n",
      "Epoch 1/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.1040 - ranking_acc: 0.5077 - val_loss: 0.0902 - val_ranking_acc: 0.5824\n",
      "Epoch 2/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0952 - ranking_acc: 0.5424 - val_loss: 0.0896 - val_ranking_acc: 0.5866\n",
      "Epoch 3/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0931 - ranking_acc: 0.5610 - val_loss: 0.0879 - val_ranking_acc: 0.5977\n",
      "Epoch 4/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0909 - ranking_acc: 0.5770 - val_loss: 0.0854 - val_ranking_acc: 0.6099\n",
      "Epoch 5/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0884 - ranking_acc: 0.5930 - val_loss: 0.0810 - val_ranking_acc: 0.6483\n",
      "Epoch 6/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0858 - ranking_acc: 0.6091 - val_loss: 0.0786 - val_ranking_acc: 0.6540\n",
      "Epoch 7/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0837 - ranking_acc: 0.6218 - val_loss: 0.0727 - val_ranking_acc: 0.6872\n",
      "Epoch 8/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0824 - ranking_acc: 0.6295 - val_loss: 0.0733 - val_ranking_acc: 0.6781\n",
      "Epoch 9/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0817 - ranking_acc: 0.6335 - val_loss: 0.0716 - val_ranking_acc: 0.6935\n",
      "Epoch 10/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0813 - ranking_acc: 0.6360 - val_loss: 0.0711 - val_ranking_acc: 0.6949\n",
      "fold 2 [14]\n",
      "Epoch 1/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.1030 - ranking_acc: 0.4875 - val_loss: 0.1032 - val_ranking_acc: 0.4962\n",
      "Epoch 2/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.1000 - ranking_acc: 0.5049 - val_loss: 0.1007 - val_ranking_acc: 0.5035\n",
      "Epoch 3/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0968 - ranking_acc: 0.5373 - val_loss: 0.0981 - val_ranking_acc: 0.5243\n",
      "Epoch 4/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0938 - ranking_acc: 0.5653 - val_loss: 0.0943 - val_ranking_acc: 0.5590\n",
      "Epoch 5/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0909 - ranking_acc: 0.5869 - val_loss: 0.0872 - val_ranking_acc: 0.6108\n",
      "Epoch 6/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0880 - ranking_acc: 0.6045 - val_loss: 0.0867 - val_ranking_acc: 0.6183\n",
      "Epoch 7/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0856 - ranking_acc: 0.6172 - val_loss: 0.0821 - val_ranking_acc: 0.6348\n",
      "Epoch 8/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0840 - ranking_acc: 0.6248 - val_loss: 0.0815 - val_ranking_acc: 0.6438\n",
      "Epoch 9/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0830 - ranking_acc: 0.6295 - val_loss: 0.0791 - val_ranking_acc: 0.6609\n",
      "Epoch 10/10\n",
      "152256/152256 [==============================] - 17s - loss: 0.0823 - ranking_acc: 0.6327 - val_loss: 0.0804 - val_ranking_acc: 0.6562\n",
      "fold 3 [11]\n",
      "Epoch 1/10\n",
      "145280/145280 [==============================] - 17s - loss: 0.0964 - ranking_acc: 0.5403 - val_loss: 0.0917 - val_ranking_acc: 0.5738\n",
      "Epoch 2/10\n",
      "145280/145280 [==============================] - 18s - loss: 0.0929 - ranking_acc: 0.5623 - val_loss: 0.0929 - val_ranking_acc: 0.5624\n",
      "Epoch 3/10\n",
      "145280/145280 [==============================] - 18s - loss: 0.0904 - ranking_acc: 0.5778 - val_loss: 0.0935 - val_ranking_acc: 0.5537\n",
      "Epoch 4/10\n",
      "145280/145280 [==============================] - 18s - loss: 0.0883 - ranking_acc: 0.5901 - val_loss: 0.0945 - val_ranking_acc: 0.5447\n",
      "fold 4 [27]\n",
      "Epoch 1/10\n",
      "153344/153344 [==============================] - 19s - loss: 0.1030 - ranking_acc: 0.5061 - val_loss: 0.1054 - val_ranking_acc: 0.4561\n",
      "Epoch 2/10\n",
      "153344/153344 [==============================] - 15s - loss: 0.0948 - ranking_acc: 0.5447 - val_loss: 0.0939 - val_ranking_acc: 0.5600\n",
      "Epoch 3/10\n",
      "153344/153344 [==============================] - 16s - loss: 0.0922 - ranking_acc: 0.5636 - val_loss: 0.0846 - val_ranking_acc: 0.6220\n",
      "Epoch 4/10\n",
      "153344/153344 [==============================] - 16s - loss: 0.0903 - ranking_acc: 0.5766 - val_loss: 0.0764 - val_ranking_acc: 0.6681\n",
      "Epoch 5/10\n",
      "153344/153344 [==============================] - 15s - loss: 0.0886 - ranking_acc: 0.5884 - val_loss: 0.0698 - val_ranking_acc: 0.6921\n",
      "Epoch 6/10\n",
      "153344/153344 [==============================] - 15s - loss: 0.0870 - ranking_acc: 0.5993 - val_loss: 0.0676 - val_ranking_acc: 0.7133\n",
      "Epoch 7/10\n",
      "153344/153344 [==============================] - 15s - loss: 0.0854 - ranking_acc: 0.6094 - val_loss: 0.0634 - val_ranking_acc: 0.7251\n",
      "Epoch 8/10\n",
      "153344/153344 [==============================] - 15s - loss: 0.0840 - ranking_acc: 0.6184 - val_loss: 0.0601 - val_ranking_acc: 0.7437\n",
      "Epoch 9/10\n",
      "153344/153344 [==============================] - 16s - loss: 0.0829 - ranking_acc: 0.6265 - val_loss: 0.0597 - val_ranking_acc: 0.7542\n",
      "Epoch 10/10\n",
      "153344/153344 [==============================] - 20s - loss: 0.0820 - ranking_acc: 0.6324 - val_loss: 0.0567 - val_ranking_acc: 0.7665\n",
      "fold 5 [25]\n",
      "Epoch 1/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0988 - ranking_acc: 0.5261 - val_loss: 0.0942 - val_ranking_acc: 0.5429\n",
      "Epoch 2/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0972 - ranking_acc: 0.5312 - val_loss: 0.0941 - val_ranking_acc: 0.5402\n",
      "Epoch 3/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0967 - ranking_acc: 0.5355 - val_loss: 0.0936 - val_ranking_acc: 0.5456\n",
      "Epoch 4/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0960 - ranking_acc: 0.5393 - val_loss: 0.0935 - val_ranking_acc: 0.5472\n",
      "Epoch 5/10\n",
      "149376/149376 [==============================] - 15s - loss: 0.0953 - ranking_acc: 0.5446 - val_loss: 0.0934 - val_ranking_acc: 0.5521\n",
      "Epoch 6/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0946 - ranking_acc: 0.5483 - val_loss: 0.0939 - val_ranking_acc: 0.5432\n",
      "Epoch 7/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0938 - ranking_acc: 0.5526 - val_loss: 0.0934 - val_ranking_acc: 0.5521\n",
      "Epoch 8/10\n",
      "149376/149376 [==============================] - 15s - loss: 0.0929 - ranking_acc: 0.5587 - val_loss: 0.0931 - val_ranking_acc: 0.5559\n",
      "Epoch 9/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0919 - ranking_acc: 0.5660 - val_loss: 0.0920 - val_ranking_acc: 0.5649\n",
      "Epoch 10/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0906 - ranking_acc: 0.5749 - val_loss: 0.0906 - val_ranking_acc: 0.5800\n",
      "fold 6 [28]\n",
      "Epoch 1/10\n",
      "149696/149696 [==============================] - 16s - loss: 0.1001 - ranking_acc: 0.5268 - val_loss: 0.0901 - val_ranking_acc: 0.6038\n",
      "Epoch 2/10\n",
      "149696/149696 [==============================] - 15s - loss: 0.0971 - ranking_acc: 0.5302 - val_loss: 0.0903 - val_ranking_acc: 0.6028\n",
      "Epoch 3/10\n",
      "149696/149696 [==============================] - 14s - loss: 0.0965 - ranking_acc: 0.5346 - val_loss: 0.0903 - val_ranking_acc: 0.5967\n",
      "Epoch 4/10\n",
      "149696/149696 [==============================] - 15s - loss: 0.0960 - ranking_acc: 0.5389 - val_loss: 0.0903 - val_ranking_acc: 0.5961\n",
      "fold 7 [12]\n",
      "Epoch 1/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.1026 - ranking_acc: 0.4988 - val_loss: 0.1025 - val_ranking_acc: 0.4481\n",
      "Epoch 2/10\n",
      "149376/149376 [==============================] - 15s - loss: 0.0995 - ranking_acc: 0.5087 - val_loss: 0.1009 - val_ranking_acc: 0.4625\n",
      "Epoch 3/10\n",
      "149376/149376 [==============================] - 15s - loss: 0.0989 - ranking_acc: 0.5145 - val_loss: 0.0999 - val_ranking_acc: 0.4747\n",
      "Epoch 4/10\n",
      "149376/149376 [==============================] - 15s - loss: 0.0984 - ranking_acc: 0.5202 - val_loss: 0.0999 - val_ranking_acc: 0.4802\n",
      "Epoch 5/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0977 - ranking_acc: 0.5266 - val_loss: 0.0989 - val_ranking_acc: 0.4995\n",
      "Epoch 6/10\n",
      "149376/149376 [==============================] - 15s - loss: 0.0968 - ranking_acc: 0.5351 - val_loss: 0.0981 - val_ranking_acc: 0.5167\n",
      "Epoch 7/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0956 - ranking_acc: 0.5450 - val_loss: 0.0962 - val_ranking_acc: 0.5463\n",
      "Epoch 8/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0944 - ranking_acc: 0.5535 - val_loss: 0.0957 - val_ranking_acc: 0.5555\n",
      "Epoch 9/10\n",
      "149376/149376 [==============================] - 15s - loss: 0.0933 - ranking_acc: 0.5609 - val_loss: 0.0950 - val_ranking_acc: 0.5648\n",
      "Epoch 10/10\n",
      "149376/149376 [==============================] - 16s - loss: 0.0922 - ranking_acc: 0.5679 - val_loss: 0.0935 - val_ranking_acc: 0.5822\n",
      "fold 8 [18]\n",
      "Epoch 1/10\n",
      "152000/152000 [==============================] - 16s - loss: 0.1023 - ranking_acc: 0.5337 - val_loss: 0.1032 - val_ranking_acc: 0.4812\n",
      "Epoch 2/10\n",
      "152000/152000 [==============================] - 17s - loss: 0.0959 - ranking_acc: 0.5404 - val_loss: 0.1033 - val_ranking_acc: 0.4719\n",
      "Epoch 3/10\n",
      "152000/152000 [==============================] - 16s - loss: 0.0946 - ranking_acc: 0.5486 - val_loss: 0.1034 - val_ranking_acc: 0.4727\n",
      "Epoch 4/10\n",
      "152000/152000 [==============================] - 17s - loss: 0.0937 - ranking_acc: 0.5550 - val_loss: 0.1054 - val_ranking_acc: 0.4621\n",
      "fold 9 [23]\n",
      "Epoch 1/10\n",
      "149312/149312 [==============================] - 17s - loss: 0.1017 - ranking_acc: 0.5150 - val_loss: 0.0975 - val_ranking_acc: 0.5705\n",
      "Epoch 2/10\n",
      "149312/149312 [==============================] - 16s - loss: 0.0985 - ranking_acc: 0.5208 - val_loss: 0.0969 - val_ranking_acc: 0.5701\n",
      "Epoch 3/10\n",
      "149312/149312 [==============================] - 16s - loss: 0.0981 - ranking_acc: 0.5243 - val_loss: 0.0962 - val_ranking_acc: 0.5738\n",
      "Epoch 4/10\n",
      "149312/149312 [==============================] - 16s - loss: 0.0977 - ranking_acc: 0.5279 - val_loss: 0.0958 - val_ranking_acc: 0.5741\n",
      "Epoch 5/10\n",
      "149312/149312 [==============================] - 15s - loss: 0.0971 - ranking_acc: 0.5321 - val_loss: 0.0951 - val_ranking_acc: 0.5743\n",
      "Epoch 6/10\n",
      "149312/149312 [==============================] - 15s - loss: 0.0963 - ranking_acc: 0.5385 - val_loss: 0.0940 - val_ranking_acc: 0.5760\n",
      "Epoch 7/10\n",
      "149312/149312 [==============================] - 16s - loss: 0.0949 - ranking_acc: 0.5469 - val_loss: 0.0938 - val_ranking_acc: 0.5608\n",
      "Epoch 8/10\n",
      "149312/149312 [==============================] - 15s - loss: 0.0933 - ranking_acc: 0.5584 - val_loss: 0.0946 - val_ranking_acc: 0.5487\n",
      "Epoch 9/10\n",
      "149312/149312 [==============================] - 16s - loss: 0.0922 - ranking_acc: 0.5669 - val_loss: 0.0966 - val_ranking_acc: 0.5326\n",
      "Epoch 10/10\n",
      "149312/149312 [==============================] - 16s - loss: 0.0913 - ranking_acc: 0.5730 - val_loss: 0.0977 - val_ranking_acc: 0.5223\n",
      "fold 10 [6]\n",
      "Epoch 1/10\n",
      "151808/151808 [==============================] - 16s - loss: 0.1075 - ranking_acc: 0.4624 - val_loss: 0.1012 - val_ranking_acc: 0.5156\n",
      "Epoch 2/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1022 - ranking_acc: 0.4677 - val_loss: 0.1006 - val_ranking_acc: 0.5310\n",
      "Epoch 3/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1015 - ranking_acc: 0.4700 - val_loss: 0.1005 - val_ranking_acc: 0.5295\n",
      "Epoch 4/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1011 - ranking_acc: 0.4713 - val_loss: 0.1003 - val_ranking_acc: 0.5360\n",
      "Epoch 5/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1009 - ranking_acc: 0.4723 - val_loss: 0.1003 - val_ranking_acc: 0.5335\n",
      "Epoch 6/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1008 - ranking_acc: 0.4729 - val_loss: 0.1003 - val_ranking_acc: 0.5406\n",
      "Epoch 7/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1007 - ranking_acc: 0.4733 - val_loss: 0.1002 - val_ranking_acc: 0.5398\n",
      "Epoch 8/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1006 - ranking_acc: 0.4740 - val_loss: 0.1002 - val_ranking_acc: 0.5449\n",
      "Epoch 9/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1006 - ranking_acc: 0.4742 - val_loss: 0.1001 - val_ranking_acc: 0.5408\n",
      "Epoch 10/10\n",
      "151808/151808 [==============================] - 15s - loss: 0.1005 - ranking_acc: 0.4745 - val_loss: 0.1003 - val_ranking_acc: 0.5383\n",
      "fold 11 [17]\n",
      "Epoch 1/10\n",
      "150656/150656 [==============================] - 15s - loss: 0.0981 - ranking_acc: 0.5365 - val_loss: 0.0867 - val_ranking_acc: 0.5980\n",
      "Epoch 2/10\n",
      "150656/150656 [==============================] - 15s - loss: 0.0952 - ranking_acc: 0.5441 - val_loss: 0.0839 - val_ranking_acc: 0.6221\n",
      "Epoch 3/10\n",
      "150656/150656 [==============================] - 15s - loss: 0.0943 - ranking_acc: 0.5520 - val_loss: 0.0809 - val_ranking_acc: 0.6340\n",
      "Epoch 4/10\n",
      "150656/150656 [==============================] - 15s - loss: 0.0932 - ranking_acc: 0.5590 - val_loss: 0.0765 - val_ranking_acc: 0.6570\n",
      "Epoch 5/10\n",
      "150656/150656 [==============================] - 15s - loss: 0.0922 - ranking_acc: 0.5658 - val_loss: 0.0746 - val_ranking_acc: 0.6742\n",
      "Epoch 6/10\n",
      "150656/150656 [==============================] - 15s - loss: 0.0912 - ranking_acc: 0.5731 - val_loss: 0.0704 - val_ranking_acc: 0.7023\n",
      "Epoch 7/10\n",
      "150656/150656 [==============================] - 16s - loss: 0.0903 - ranking_acc: 0.5783 - val_loss: 0.0682 - val_ranking_acc: 0.7143\n",
      "Epoch 8/10\n",
      "150656/150656 [==============================] - 16s - loss: 0.0895 - ranking_acc: 0.5844 - val_loss: 0.0662 - val_ranking_acc: 0.7203\n",
      "Epoch 9/10\n",
      "150656/150656 [==============================] - 16s - loss: 0.0886 - ranking_acc: 0.5899 - val_loss: 0.0631 - val_ranking_acc: 0.7318\n",
      "Epoch 10/10\n",
      "150656/150656 [==============================] - 15s - loss: 0.0877 - ranking_acc: 0.5956 - val_loss: 0.0620 - val_ranking_acc: 0.7385\n",
      "fold 12 [9]\n",
      "Epoch 1/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.1023 - ranking_acc: 0.5136 - val_loss: 0.0823 - val_ranking_acc: 0.6343\n",
      "Epoch 2/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0959 - ranking_acc: 0.5405 - val_loss: 0.0781 - val_ranking_acc: 0.6525\n",
      "Epoch 3/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0930 - ranking_acc: 0.5613 - val_loss: 0.0762 - val_ranking_acc: 0.6644\n",
      "Epoch 4/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0910 - ranking_acc: 0.5750 - val_loss: 0.0758 - val_ranking_acc: 0.6629\n",
      "Epoch 5/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0894 - ranking_acc: 0.5848 - val_loss: 0.0712 - val_ranking_acc: 0.6921\n",
      "Epoch 6/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0881 - ranking_acc: 0.5928 - val_loss: 0.0724 - val_ranking_acc: 0.6806\n",
      "Epoch 7/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0871 - ranking_acc: 0.6004 - val_loss: 0.0718 - val_ranking_acc: 0.6878\n",
      "Epoch 8/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0861 - ranking_acc: 0.6069 - val_loss: 0.0702 - val_ranking_acc: 0.6887\n",
      "Epoch 9/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0852 - ranking_acc: 0.6129 - val_loss: 0.0706 - val_ranking_acc: 0.6898\n",
      "Epoch 10/10\n",
      "152256/152256 [==============================] - 15s - loss: 0.0843 - ranking_acc: 0.6178 - val_loss: 0.0695 - val_ranking_acc: 0.6924\n",
      "fold 13 [15]\n",
      "Epoch 1/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.1021 - ranking_acc: 0.5177 - val_loss: 0.1107 - val_ranking_acc: 0.4407\n",
      "Epoch 2/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0971 - ranking_acc: 0.5384 - val_loss: 0.1082 - val_ranking_acc: 0.4490\n",
      "Epoch 3/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0944 - ranking_acc: 0.5562 - val_loss: 0.1061 - val_ranking_acc: 0.4478\n",
      "Epoch 4/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0924 - ranking_acc: 0.5698 - val_loss: 0.1056 - val_ranking_acc: 0.4612\n",
      "Epoch 5/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0907 - ranking_acc: 0.5811 - val_loss: 0.1047 - val_ranking_acc: 0.4602\n",
      "Epoch 6/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0891 - ranking_acc: 0.5920 - val_loss: 0.1036 - val_ranking_acc: 0.4685\n",
      "Epoch 7/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0876 - ranking_acc: 0.6015 - val_loss: 0.1036 - val_ranking_acc: 0.4668\n",
      "Epoch 8/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0861 - ranking_acc: 0.6105 - val_loss: 0.1033 - val_ranking_acc: 0.4631\n",
      "Epoch 9/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0849 - ranking_acc: 0.6180 - val_loss: 0.1035 - val_ranking_acc: 0.4592\n",
      "Epoch 10/10\n",
      "151616/151616 [==============================] - 15s - loss: 0.0839 - ranking_acc: 0.6247 - val_loss: 0.1030 - val_ranking_acc: 0.4492\n",
      "fold 14 [24]\n",
      "Epoch 1/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0988 - ranking_acc: 0.5190 - val_loss: 0.0986 - val_ranking_acc: 0.5112\n",
      "Epoch 2/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0979 - ranking_acc: 0.5218 - val_loss: 0.0986 - val_ranking_acc: 0.5121\n",
      "Epoch 3/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0975 - ranking_acc: 0.5244 - val_loss: 0.0984 - val_ranking_acc: 0.5131\n",
      "Epoch 4/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0972 - ranking_acc: 0.5267 - val_loss: 0.0988 - val_ranking_acc: 0.5086\n",
      "Epoch 5/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0970 - ranking_acc: 0.5289 - val_loss: 0.0983 - val_ranking_acc: 0.5192\n",
      "Epoch 6/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0967 - ranking_acc: 0.5307 - val_loss: 0.0986 - val_ranking_acc: 0.5122\n",
      "Epoch 7/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0964 - ranking_acc: 0.5322 - val_loss: 0.0986 - val_ranking_acc: 0.5148\n",
      "Epoch 8/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0961 - ranking_acc: 0.5340 - val_loss: 0.0983 - val_ranking_acc: 0.5242\n",
      "Epoch 9/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0958 - ranking_acc: 0.5360 - val_loss: 0.0991 - val_ranking_acc: 0.5162\n",
      "Epoch 10/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0955 - ranking_acc: 0.5384 - val_loss: 0.0979 - val_ranking_acc: 0.5310\n",
      "fold 15 [21]\n",
      "Epoch 1/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.1006 - ranking_acc: 0.5252 - val_loss: 0.0952 - val_ranking_acc: 0.5372\n",
      "Epoch 2/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0959 - ranking_acc: 0.5461 - val_loss: 0.0949 - val_ranking_acc: 0.5454\n",
      "Epoch 3/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0928 - ranking_acc: 0.5675 - val_loss: 0.0954 - val_ranking_acc: 0.5350\n",
      "Epoch 4/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0901 - ranking_acc: 0.5850 - val_loss: 0.0970 - val_ranking_acc: 0.5221\n",
      "Epoch 5/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0877 - ranking_acc: 0.6003 - val_loss: 0.0979 - val_ranking_acc: 0.5087\n",
      "fold 16 [2]\n",
      "Epoch 1/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.1049 - ranking_acc: 0.5218 - val_loss: 0.0676 - val_ranking_acc: 0.6999\n",
      "Epoch 2/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0963 - ranking_acc: 0.5413 - val_loss: 0.0646 - val_ranking_acc: 0.7230\n",
      "Epoch 3/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0936 - ranking_acc: 0.5561 - val_loss: 0.0645 - val_ranking_acc: 0.7273\n",
      "Epoch 4/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0920 - ranking_acc: 0.5672 - val_loss: 0.0644 - val_ranking_acc: 0.7342\n",
      "Epoch 5/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0908 - ranking_acc: 0.5751 - val_loss: 0.0630 - val_ranking_acc: 0.7479\n",
      "Epoch 6/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0898 - ranking_acc: 0.5834 - val_loss: 0.0626 - val_ranking_acc: 0.7521\n",
      "Epoch 7/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0888 - ranking_acc: 0.5896 - val_loss: 0.0612 - val_ranking_acc: 0.7664\n",
      "Epoch 8/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0880 - ranking_acc: 0.5948 - val_loss: 0.0596 - val_ranking_acc: 0.7770\n",
      "Epoch 9/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0872 - ranking_acc: 0.5997 - val_loss: 0.0574 - val_ranking_acc: 0.7933\n",
      "Epoch 10/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0865 - ranking_acc: 0.6044 - val_loss: 0.0562 - val_ranking_acc: 0.7953\n",
      "fold 17 [30]\n",
      "Epoch 1/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0991 - ranking_acc: 0.5240 - val_loss: 0.1057 - val_ranking_acc: 0.5003\n",
      "Epoch 2/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0966 - ranking_acc: 0.5344 - val_loss: 0.1020 - val_ranking_acc: 0.5066\n",
      "Epoch 3/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0955 - ranking_acc: 0.5413 - val_loss: 0.0983 - val_ranking_acc: 0.5220\n",
      "Epoch 4/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0947 - ranking_acc: 0.5478 - val_loss: 0.0966 - val_ranking_acc: 0.5221\n",
      "Epoch 5/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0939 - ranking_acc: 0.5534 - val_loss: 0.0936 - val_ranking_acc: 0.5410\n",
      "Epoch 6/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0931 - ranking_acc: 0.5607 - val_loss: 0.0906 - val_ranking_acc: 0.5453\n",
      "Epoch 7/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0921 - ranking_acc: 0.5686 - val_loss: 0.0865 - val_ranking_acc: 0.5696\n",
      "Epoch 8/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0911 - ranking_acc: 0.5768 - val_loss: 0.0830 - val_ranking_acc: 0.5856\n",
      "Epoch 9/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0902 - ranking_acc: 0.5843 - val_loss: 0.0802 - val_ranking_acc: 0.6038\n",
      "Epoch 10/10\n",
      "148992/148992 [==============================] - 15s - loss: 0.0893 - ranking_acc: 0.5901 - val_loss: 0.0776 - val_ranking_acc: 0.6114\n",
      "fold 18 [7]\n",
      "Epoch 1/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.1044 - ranking_acc: 0.5060 - val_loss: 0.0972 - val_ranking_acc: 0.5139\n",
      "Epoch 2/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0994 - ranking_acc: 0.5131 - val_loss: 0.0971 - val_ranking_acc: 0.5114\n",
      "Epoch 3/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0985 - ranking_acc: 0.5166 - val_loss: 0.0971 - val_ranking_acc: 0.5181\n",
      "Epoch 4/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0982 - ranking_acc: 0.5195 - val_loss: 0.0968 - val_ranking_acc: 0.5184\n",
      "Epoch 5/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0979 - ranking_acc: 0.5219 - val_loss: 0.0961 - val_ranking_acc: 0.5226\n",
      "Epoch 6/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0976 - ranking_acc: 0.5244 - val_loss: 0.0960 - val_ranking_acc: 0.5231\n",
      "Epoch 7/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0972 - ranking_acc: 0.5270 - val_loss: 0.0955 - val_ranking_acc: 0.5265\n",
      "Epoch 8/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0968 - ranking_acc: 0.5297 - val_loss: 0.0942 - val_ranking_acc: 0.5397\n",
      "Epoch 9/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0963 - ranking_acc: 0.5324 - val_loss: 0.0936 - val_ranking_acc: 0.5456\n",
      "Epoch 10/10\n",
      "151680/151680 [==============================] - 15s - loss: 0.0958 - ranking_acc: 0.5365 - val_loss: 0.0923 - val_ranking_acc: 0.5578\n",
      "fold 19 [5]\n",
      "Epoch 1/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.1003 - ranking_acc: 0.5211 - val_loss: 0.0975 - val_ranking_acc: 0.5413\n",
      "Epoch 2/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0981 - ranking_acc: 0.5230 - val_loss: 0.0964 - val_ranking_acc: 0.5502\n",
      "Epoch 3/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0977 - ranking_acc: 0.5248 - val_loss: 0.0968 - val_ranking_acc: 0.5476\n",
      "Epoch 4/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0975 - ranking_acc: 0.5265 - val_loss: 0.0966 - val_ranking_acc: 0.5435\n",
      "Epoch 5/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0972 - ranking_acc: 0.5285 - val_loss: 0.0962 - val_ranking_acc: 0.5581\n",
      "Epoch 6/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0970 - ranking_acc: 0.5301 - val_loss: 0.0953 - val_ranking_acc: 0.5600\n",
      "Epoch 7/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0968 - ranking_acc: 0.5313 - val_loss: 0.0953 - val_ranking_acc: 0.5665\n",
      "Epoch 8/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0966 - ranking_acc: 0.5325 - val_loss: 0.0951 - val_ranking_acc: 0.5632\n",
      "Epoch 9/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0964 - ranking_acc: 0.5339 - val_loss: 0.0948 - val_ranking_acc: 0.5720\n",
      "Epoch 10/10\n",
      "150080/150080 [==============================] - 15s - loss: 0.0962 - ranking_acc: 0.5349 - val_loss: 0.0941 - val_ranking_acc: 0.5815\n",
      "fold 20 [19]\n",
      "Epoch 1/10\n",
      "149632/149632 [==============================] - 15s - loss: 0.1066 - ranking_acc: 0.5045 - val_loss: 0.0903 - val_ranking_acc: 0.5836\n",
      "Epoch 2/10\n",
      "149632/149632 [==============================] - 15s - loss: 0.0994 - ranking_acc: 0.5140 - val_loss: 0.0928 - val_ranking_acc: 0.5714\n",
      "Epoch 3/10\n",
      "149632/149632 [==============================] - 15s - loss: 0.0986 - ranking_acc: 0.5195 - val_loss: 0.0938 - val_ranking_acc: 0.5531\n",
      "Epoch 4/10\n",
      "149632/149632 [==============================] - 15s - loss: 0.0981 - ranking_acc: 0.5228 - val_loss: 0.0938 - val_ranking_acc: 0.5586\n",
      "fold 21 [20]\n",
      "Epoch 1/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.1086 - ranking_acc: 0.5186 - val_loss: 0.1039 - val_ranking_acc: 0.5124\n",
      "Epoch 2/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0989 - ranking_acc: 0.5397 - val_loss: 0.1009 - val_ranking_acc: 0.5118\n",
      "Epoch 3/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0957 - ranking_acc: 0.5499 - val_loss: 0.0993 - val_ranking_acc: 0.5195\n",
      "Epoch 4/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0937 - ranking_acc: 0.5572 - val_loss: 0.0986 - val_ranking_acc: 0.5182\n",
      "Epoch 5/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0923 - ranking_acc: 0.5644 - val_loss: 0.0987 - val_ranking_acc: 0.5222\n",
      "Epoch 6/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0911 - ranking_acc: 0.5714 - val_loss: 0.0986 - val_ranking_acc: 0.5216\n",
      "Epoch 7/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0901 - ranking_acc: 0.5767 - val_loss: 0.0980 - val_ranking_acc: 0.5249\n",
      "Epoch 8/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0892 - ranking_acc: 0.5825 - val_loss: 0.0976 - val_ranking_acc: 0.5258\n",
      "Epoch 9/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0883 - ranking_acc: 0.5880 - val_loss: 0.0986 - val_ranking_acc: 0.5159\n",
      "Epoch 10/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0874 - ranking_acc: 0.5926 - val_loss: 0.0982 - val_ranking_acc: 0.5260\n",
      "fold 22 [10]\n",
      "Epoch 1/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0973 - ranking_acc: 0.5479 - val_loss: 0.0973 - val_ranking_acc: 0.5252\n",
      "Epoch 2/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0919 - ranking_acc: 0.5743 - val_loss: 0.0930 - val_ranking_acc: 0.5508\n",
      "Epoch 3/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0899 - ranking_acc: 0.5850 - val_loss: 0.0901 - val_ranking_acc: 0.5622\n",
      "Epoch 4/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0887 - ranking_acc: 0.5915 - val_loss: 0.0888 - val_ranking_acc: 0.5829\n",
      "Epoch 5/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0877 - ranking_acc: 0.5968 - val_loss: 0.0876 - val_ranking_acc: 0.5842\n",
      "Epoch 6/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0870 - ranking_acc: 0.6016 - val_loss: 0.0863 - val_ranking_acc: 0.6006\n",
      "Epoch 7/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0863 - ranking_acc: 0.6054 - val_loss: 0.0850 - val_ranking_acc: 0.5945\n",
      "Epoch 8/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0856 - ranking_acc: 0.6095 - val_loss: 0.0843 - val_ranking_acc: 0.6088\n",
      "Epoch 9/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0850 - ranking_acc: 0.6138 - val_loss: 0.0843 - val_ranking_acc: 0.6112\n",
      "Epoch 10/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0843 - ranking_acc: 0.6176 - val_loss: 0.0828 - val_ranking_acc: 0.6176\n",
      "fold 23 [8]\n",
      "Epoch 1/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.1135 - ranking_acc: 0.5025 - val_loss: 0.1002 - val_ranking_acc: 0.5370\n",
      "Epoch 2/10\n",
      "147776/147776 [==============================] - 16s - loss: 0.1009 - ranking_acc: 0.5121 - val_loss: 0.0962 - val_ranking_acc: 0.5465\n",
      "Epoch 3/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0972 - ranking_acc: 0.5275 - val_loss: 0.0949 - val_ranking_acc: 0.5471\n",
      "Epoch 4/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0945 - ranking_acc: 0.5447 - val_loss: 0.0943 - val_ranking_acc: 0.5546\n",
      "Epoch 5/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0922 - ranking_acc: 0.5607 - val_loss: 0.0948 - val_ranking_acc: 0.5580\n",
      "Epoch 6/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0902 - ranking_acc: 0.5751 - val_loss: 0.0939 - val_ranking_acc: 0.5619\n",
      "Epoch 7/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0885 - ranking_acc: 0.5866 - val_loss: 0.0945 - val_ranking_acc: 0.5627\n",
      "Epoch 8/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0870 - ranking_acc: 0.5970 - val_loss: 0.0935 - val_ranking_acc: 0.5730\n",
      "Epoch 9/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0857 - ranking_acc: 0.6062 - val_loss: 0.0946 - val_ranking_acc: 0.5589\n",
      "Epoch 10/10\n",
      "147776/147776 [==============================] - 15s - loss: 0.0847 - ranking_acc: 0.6140 - val_loss: 0.0940 - val_ranking_acc: 0.5615\n",
      "fold 24 [26]\n",
      "Epoch 1/10\n",
      "149568/149568 [==============================] - 15s - loss: 0.1020 - ranking_acc: 0.4832 - val_loss: 0.1041 - val_ranking_acc: 0.4154\n",
      "Epoch 2/10\n",
      "149568/149568 [==============================] - 15s - loss: 0.1015 - ranking_acc: 0.4866 - val_loss: 0.1037 - val_ranking_acc: 0.4129\n",
      "Epoch 3/10\n",
      "149568/149568 [==============================] - 15s - loss: 0.1011 - ranking_acc: 0.4904 - val_loss: 0.1035 - val_ranking_acc: 0.4084\n",
      "Epoch 4/10\n",
      "149568/149568 [==============================] - 15s - loss: 0.1009 - ranking_acc: 0.4945 - val_loss: 0.1033 - val_ranking_acc: 0.4038\n",
      "Epoch 5/10\n",
      "149568/149568 [==============================] - 15s - loss: 0.1006 - ranking_acc: 0.4982 - val_loss: 0.1036 - val_ranking_acc: 0.3968\n",
      "Epoch 6/10\n",
      "149568/149568 [==============================] - 15s - loss: 0.1004 - ranking_acc: 0.5024 - val_loss: 0.1033 - val_ranking_acc: 0.4098\n",
      "Epoch 7/10\n",
      "149568/149568 [==============================] - 15s - loss: 0.1001 - ranking_acc: 0.5064 - val_loss: 0.1040 - val_ranking_acc: 0.3931\n",
      "fold 25 [4]\n",
      "Epoch 1/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.1023 - ranking_acc: 0.5093 - val_loss: 0.0991 - val_ranking_acc: 0.5257\n",
      "Epoch 2/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0983 - ranking_acc: 0.5289 - val_loss: 0.0918 - val_ranking_acc: 0.5600\n",
      "Epoch 3/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0955 - ranking_acc: 0.5479 - val_loss: 0.0840 - val_ranking_acc: 0.6124\n",
      "Epoch 4/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0932 - ranking_acc: 0.5652 - val_loss: 0.0789 - val_ranking_acc: 0.6638\n",
      "Epoch 5/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0912 - ranking_acc: 0.5786 - val_loss: 0.0760 - val_ranking_acc: 0.6777\n",
      "Epoch 6/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0895 - ranking_acc: 0.5886 - val_loss: 0.0734 - val_ranking_acc: 0.6897\n",
      "Epoch 7/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0880 - ranking_acc: 0.5976 - val_loss: 0.0709 - val_ranking_acc: 0.7068\n",
      "Epoch 8/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0867 - ranking_acc: 0.6064 - val_loss: 0.0698 - val_ranking_acc: 0.7137\n",
      "Epoch 9/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0855 - ranking_acc: 0.6142 - val_loss: 0.0684 - val_ranking_acc: 0.7252\n",
      "Epoch 10/10\n",
      "152192/152192 [==============================] - 15s - loss: 0.0844 - ranking_acc: 0.6208 - val_loss: 0.0673 - val_ranking_acc: 0.7377\n",
      "fold 26 [1]\n",
      "Epoch 1/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0983 - ranking_acc: 0.5263 - val_loss: 0.0864 - val_ranking_acc: 0.6115\n",
      "Epoch 2/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0977 - ranking_acc: 0.5274 - val_loss: 0.0874 - val_ranking_acc: 0.6070\n",
      "Epoch 3/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0975 - ranking_acc: 0.5285 - val_loss: 0.0880 - val_ranking_acc: 0.6048\n",
      "Epoch 4/10\n",
      "152000/152000 [==============================] - 15s - loss: 0.0973 - ranking_acc: 0.5295 - val_loss: 0.0869 - val_ranking_acc: 0.6121\n",
      "fold 27 [22]\n",
      "Epoch 1/10\n",
      "154176/154176 [==============================] - 15s - loss: 0.1047 - ranking_acc: 0.5081 - val_loss: 0.0882 - val_ranking_acc: 0.5875\n",
      "Epoch 2/10\n",
      "154176/154176 [==============================] - 15s - loss: 0.0997 - ranking_acc: 0.5197 - val_loss: 0.0896 - val_ranking_acc: 0.5813\n",
      "Epoch 3/10\n",
      "154176/154176 [==============================] - 15s - loss: 0.0975 - ranking_acc: 0.5310 - val_loss: 0.0877 - val_ranking_acc: 0.5875\n",
      "Epoch 4/10\n",
      "154176/154176 [==============================] - 15s - loss: 0.0960 - ranking_acc: 0.5399 - val_loss: 0.0901 - val_ranking_acc: 0.5844\n",
      "Epoch 5/10\n",
      "154176/154176 [==============================] - 15s - loss: 0.0950 - ranking_acc: 0.5468 - val_loss: 0.0900 - val_ranking_acc: 0.5756\n",
      "Epoch 6/10\n",
      "154176/154176 [==============================] - 15s - loss: 0.0941 - ranking_acc: 0.5520 - val_loss: 0.0911 - val_ranking_acc: 0.5763\n",
      "fold 28 [16]\n",
      "Epoch 1/10\n",
      "150528/150528 [==============================] - 15s - loss: 0.1044 - ranking_acc: 0.5409 - val_loss: 0.0934 - val_ranking_acc: 0.5652\n",
      "Epoch 2/10\n",
      "150528/150528 [==============================] - 15s - loss: 0.0962 - ranking_acc: 0.5455 - val_loss: 0.0945 - val_ranking_acc: 0.5526\n",
      "Epoch 3/10\n",
      "150528/150528 [==============================] - 15s - loss: 0.0951 - ranking_acc: 0.5492 - val_loss: 0.0953 - val_ranking_acc: 0.5433\n",
      "Epoch 4/10\n",
      "150528/150528 [==============================] - 15s - loss: 0.0945 - ranking_acc: 0.5531 - val_loss: 0.0964 - val_ranking_acc: 0.5282\n",
      "fold 29 [13]\n",
      "Epoch 1/10\n",
      "151936/151936 [==============================] - 15s - loss: 0.0987 - ranking_acc: 0.5214 - val_loss: 0.0953 - val_ranking_acc: 0.5654\n",
      "Epoch 2/10\n",
      "151936/151936 [==============================] - 15s - loss: 0.0985 - ranking_acc: 0.5234 - val_loss: 0.0954 - val_ranking_acc: 0.5648\n",
      "Epoch 3/10\n",
      "151936/151936 [==============================] - 15s - loss: 0.0983 - ranking_acc: 0.5259 - val_loss: 0.0954 - val_ranking_acc: 0.5641\n",
      "Epoch 4/10\n",
      "151936/151936 [==============================] - 15s - loss: 0.0981 - ranking_acc: 0.5286 - val_loss: 0.0955 - val_ranking_acc: 0.5513\n"
     ]
    }
   ],
   "source": [
    "KFold('data/trec-output/0125_summary_LOO.rankedlist', K=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To evaluate:\n",
    "\n",
    "trec_eval -q -M1000 official_qrels submitted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 125),\n",
       " (2, 34),\n",
       " (3, 144),\n",
       " (4, 18),\n",
       " (5, 95),\n",
       " (6, 133),\n",
       " (7, 68),\n",
       " (8, 809),\n",
       " (9, 117),\n",
       " (10, 19),\n",
       " (11, 350),\n",
       " (12, 107),\n",
       " (13, 128),\n",
       " (14, 117),\n",
       " (15, 69),\n",
       " (16, 175),\n",
       " (17, 171),\n",
       " (18, 63),\n",
       " (19, 204),\n",
       " (20, 616),\n",
       " (21, 68),\n",
       " (22, 8),\n",
       " (23, 108),\n",
       " (24, 714),\n",
       " (25, 213),\n",
       " (26, 103),\n",
       " (27, 12),\n",
       " (28, 203),\n",
       " (29, 118),\n",
       " (30, 34)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted( n_pos.items()) # 10 15 18 2 21 22 23 27 3 4 5 7 "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
